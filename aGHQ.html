<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Embrace Uncertainty - Appendix C — GLMM log-likelihood</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./linalg.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./datatables.html">Appendices</a></li><li class="breadcrumb-item"><a href="./aGHQ.html"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">GLMM log-likelihood</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Embrace Uncertainty</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">A Simple, Linear, Mixed-Effects Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Models With Multiple Random-effects Terms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./longitudinal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Models for Longitudinal Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./largescaledesigned.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">A large-scale designed experiment</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./largescaleobserved.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">A large-scale observational study</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glmmbernoulli.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Generalized Linear Mixed Models for Binary Responses</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datatables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Working with data tables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Linear Algebra for Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./aGHQ.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">GLMM log-likelihood</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-bernoulli-glmm" id="toc-the-bernoulli-glmm" class="nav-link active" data-scroll-target="#the-bernoulli-glmm"><span class="header-section-number">C.1</span> The Bernoulli GLMM</a>
  <ul class="collapse">
  <li><a href="#log-likelihood-for-a-bernoulli-glmm" id="toc-log-likelihood-for-a-bernoulli-glmm" class="nav-link" data-scroll-target="#log-likelihood-for-a-bernoulli-glmm"><span class="header-section-number">C.1.1</span> Log-likelihood for a Bernoulli GLMM</a></li>
  </ul></li>
  <li><a href="#sec-BernoulliGLM" id="toc-sec-BernoulliGLM" class="nav-link" data-scroll-target="#sec-BernoulliGLM"><span class="header-section-number">C.2</span> Generalized linear models for binary data</a>
  <ul class="collapse">
  <li><a href="#an-example-fixed-effects-only-from-com05" id="toc-an-example-fixed-effects-only-from-com05" class="nav-link" data-scroll-target="#an-example-fixed-effects-only-from-com05"><span class="header-section-number">C.2.1</span> An example: fixed-effects only from com05</a></li>
  <li><a href="#encapsulating-the-model-in-a-struct" id="toc-encapsulating-the-model-in-a-struct" class="nav-link" data-scroll-target="#encapsulating-the-model-in-a-struct"><span class="header-section-number">C.2.2</span> Encapsulating the model in a struct</a></li>
  <li><a href="#fit-the-glm-using-a-general-optimizer" id="toc-fit-the-glm-using-a-general-optimizer" class="nav-link" data-scroll-target="#fit-the-glm-using-a-general-optimizer"><span class="header-section-number">C.2.3</span> Fit the GLM using a general optimizer</a></li>
  </ul></li>
  <li><a href="#sec-IRLS" id="toc-sec-IRLS" class="nav-link" data-scroll-target="#sec-IRLS"><span class="header-section-number">C.3</span> The IRLS algorithm</a>
  <ul class="collapse">
  <li><a href="#implementation-of-irls-for-bernoulli-logit" id="toc-implementation-of-irls-for-bernoulli-logit" class="nav-link" data-scroll-target="#implementation-of-irls-for-bernoulli-logit"><span class="header-section-number">C.3.1</span> Implementation of IRLS for Bernoulli-Logit</a></li>
  </ul></li>
  <li><a href="#sec-PIRLS" id="toc-sec-PIRLS" class="nav-link" data-scroll-target="#sec-PIRLS"><span class="header-section-number">C.4</span> GLMMs and the PIRLS algorithm</a>
  <ul class="collapse">
  <li><a href="#pirls-for-com05" id="toc-pirls-for-com05" class="nav-link" data-scroll-target="#pirls-for-com05"><span class="header-section-number">C.4.1</span> PIRLS for com05</a></li>
  </ul></li>
  <li><a href="#sec-GLMMLaplace" id="toc-sec-GLMMLaplace" class="nav-link" data-scroll-target="#sec-GLMMLaplace"><span class="header-section-number">C.5</span> Laplace’s approximation to the log-likelihood</a>
  <ul class="collapse">
  <li><a href="#generalizations-to-more-complex-structure" id="toc-generalizations-to-more-complex-structure" class="nav-link" data-scroll-target="#generalizations-to-more-complex-structure"><span class="header-section-number">C.5.1</span> Generalizations to more complex structure</a></li>
  </ul></li>
  <li><a href="#sec-aGHQ" id="toc-sec-aGHQ" class="nav-link" data-scroll-target="#sec-aGHQ"><span class="header-section-number">C.6</span> Adaptive Gauss-Hermite quadrature</a>
  <ul class="collapse">
  <li><a href="#sec-NGHQ" id="toc-sec-NGHQ" class="nav-link" data-scroll-target="#sec-NGHQ"><span class="header-section-number">C.6.1</span> Normalized Gauss-Hermite quadrature rules</a></li>
  <li><a href="#illustration-of-contributions-to-the-objective" id="toc-illustration-of-contributions-to-the-objective" class="nav-link" data-scroll-target="#illustration-of-contributions-to-the-objective"><span class="header-section-number">C.6.2</span> Illustration of contributions to the objective</a></li>
  </ul></li>
  <li><a href="#optimization-of-the-aghq-objective" id="toc-optimization-of-the-aghq-objective" class="nav-link" data-scroll-target="#optimization-of-the-aghq-objective"><span class="header-section-number">C.7</span> Optimization of the aGHQ objective</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-GLMMdeviance" class="quarto-section-identifier">Appendix C — GLMM log-likelihood</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The log-likelihood for a linear mixed model (LMM) was derived in <a href="linalg.html#sec-lmmtheory"><span>Section&nbsp;B.7</span></a>, where some computational methods for fitting such models with <a href="https://github.com/JuliaStats/MixedModels.jl">MixedModels.jl</a>, by optimizing a <em>profiled log-likelihood</em>, were illustrated.</p>
<p>In this appendix we outline the evaluation of the log-likelihood for a generalized linear mixed model (GLMM) with a binary response, which is modelled using the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a>.</p>
<section id="the-bernoulli-glmm" class="level2" data-number="C.1">
<h2 data-number="C.1" class="anchored" data-anchor-id="the-bernoulli-glmm"><span class="header-section-number">C.1</span> The Bernoulli GLMM</h2>
<p>The Bernoulli GLMM model defines the conditional distribution <span class="math inline">\(({{\mathcal{Y}}}|{{\mathcal{B}}}={{\mathbf{b}}})\)</span> as independent Bernoulli random variables with expected values <span class="math inline">\({{\boldsymbol{\mu}}}={{\mathbf{g}}}^{-1}({{\boldsymbol{\eta}}})\)</span>, where <span class="math inline">\({{\boldsymbol{\eta}}}={{\mathbf{X}}}{{\boldsymbol{\beta}}}+{{\mathbf{Z}}}{{\mathbf{b}}}\)</span> is the <em>linear predictor</em> and <span class="math inline">\({\mathbf{g}}^{-1}\)</span> is an <em>inverse link function</em>.</p>
<p>We will use the <em>logit link function</em>, <span class="math inline">\({\boldsymbol{\eta}}={\mathbf{g}}({\boldsymbol{\mu}})\)</span>, defined component-wise from the scalar logit link, <span class="math inline">\(g\)</span>, as <span class="math display">\[
\eta_i=g(\mu_i)=\mathrm{logit}(\mu_i)=\log\left(\frac{\mu_i}{1-\mu_i}\right)\quad i=1,\dots,n .
\]</span> The inverse link, <span class="math inline">\({\boldsymbol{\mu}}={\mathbf{g}}^{-1}({\boldsymbol{\eta}})\)</span>, is similarly defined component-wise from the inverse of the scalar logit, which is the scalar <em>logistic</em> function, <span id="eq-scalarlogistic"><span class="math display">\[
\mu_i=g^{-1}(\eta_i)=\mathrm{logistic}(\eta_i)=\frac{1}{1+e^{-\eta_i}}\quad i=1,\dots,n .
\tag{C.1}\]</span></span> The logit is the <em>canonical link function</em> (<a href="glmmbernoulli.html#sec-logitlink"><span>Section&nbsp;6.2.2</span></a>) for the Bernoulli distribution.</p>
<p>As in the linear mixed model discussed in <a href="linalg.html#sec-lmmtheory"><span>Section&nbsp;B.7</span></a>, the <span class="math inline">\(q\)</span>-dimensional random effects, <span class="math inline">\({\mathcal{B}}\)</span>, are expressed as <span class="math inline">\({\mathcal{B}}={\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}\,{\mathcal{U}}\)</span> where <span class="math inline">\({\mathcal{U}}\)</span> has a standard, multivariate Gaussian distribution (<a href="linalg.html#sec-multivariateGaussian"><span>Section&nbsp;B.2</span></a>) <span id="eq-MVNUdistGLMM"><span class="math display">\[
{\mathcal{U}}\sim{\mathcal{N}}({\mathbf{0}},{\mathbf{I}}_q) ,
\tag{C.2}\]</span></span> with probability density function <span id="eq-uunconddense"><span class="math display">\[
f_{{\mathcal{U}}}({\mathbf{u}})=\frac{1}{\sqrt{2\pi}^q}e^{-\|{\mathbf{u}}\|^2/2} .
\tag{C.3}\]</span></span></p>
<p>For a linear mixed model the distribution of these <em>spherical random effects</em> was given as <span class="math inline">\({\mathcal{U}}\sim({\mathbf{0}},\sigma^2{\mathbf{I}}_q)\)</span> (<a href="linalg.html#eq-sphericalre">Equation&nbsp;<span>B.35</span></a>). A dispersion parameter like <span class="math inline">\(\sigma^2\)</span> is not present in <a href="#eq-MVNUdistGLMM">Equation&nbsp;<span>C.2</span></a> because the Bernoulli distribution does not have a separate dispersion parameter — it is entirely determined by its mean.</p>
<p>As is the case for the linear mixed model, the <em>covariance factor</em>, <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}\)</span>, is sparse and patterned. It is not uncommon in practical examples, such as the one in <a href="#sec-PIRLS"><span>Section&nbsp;C.4</span></a>, for <span class="math inline">\({\boldsymbol{\theta}}\)</span> to be one-dimensional and <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}=\theta\,{\mathbf{I}}_q\)</span>, to be a scalar multiple of the <span class="math inline">\(q\times q\)</span> identity matrix.</p>
<section id="log-likelihood-for-a-bernoulli-glmm" class="level3" data-number="C.1.1">
<h3 data-number="C.1.1" class="anchored" data-anchor-id="log-likelihood-for-a-bernoulli-glmm"><span class="header-section-number">C.1.1</span> Log-likelihood for a Bernoulli GLMM</h3>
<p>The likelihood for the parameters, <span class="math inline">\({\boldsymbol{\theta}}\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span>, given the observed data, <span class="math inline">\({\mathbf{y}}\)</span>, is the value of the marginal probability mass function for the response, <span class="math inline">\({\mathcal{Y}}\)</span>, evaluated at <span class="math inline">\({\mathbf{y}}\)</span>, the observed vector of {0,1} responses. We obtain this value by integrating the product of the probability mass function for the conditional distribution, <span class="math inline">\(({\mathcal{Y}}|{\mathcal{U}}={\mathbf{u}})\)</span>, and unconditional density of <span class="math inline">\({\mathcal{U}}\)</span> (<a href="#eq-uunconddense">Equation&nbsp;<span>C.3</span></a>), with respect to <span class="math inline">\({\mathbf{u}}\)</span>.</p>
<p>Recall that the probability mass for a single Bernoulli response can be written as <span class="math inline">\((1-\mu)^{1-y}\mu^y\)</span>, which is the specialization to <span class="math inline">\(n=1\)</span> of the probability mass function for the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a> <span class="math display">\[
\binom{n}{y}(1-\mu)^{n-y}\mu^y ,\quad 0\le\mu\le 1, \quad y\in\{0,\dots,n\} .
\]</span> Because the components of the vector-valued conditional distribution, <span class="math inline">\(({\mathcal{Y}}|{\mathcal{U}}={\mathbf{u}})\)</span>, are assumed to be independent, its probability mass function can be written as the product of the probability masses for each component <span class="math display">\[
f_{{\mathcal{Y}}|{\mathcal{U}}={\mathbf{u}}}({\mathbf{y}}|{\mathbf{u}})=\prod_{i=1}^n \left[(1-\mu_i)^{1-y_i}\mu_i^{y_i}\right]
\quad\mathrm{where}\quad
{\boldsymbol{\mu}}={\mathbf{g}}^{-1}({\mathbf{X}}{\boldsymbol{\beta}}+{\mathbf{Z}}{\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}{\mathbf{u}}) ,
\]</span> providing the likelihood as <span id="eq-GLMMlikelihood"><span class="math display">\[
\begin{aligned}
L({\boldsymbol{\eta}},{\boldsymbol{\theta}}|{\mathbf{y}})&amp;=
\int_{{\mathbf{u}}}f_{{\mathcal{Y}},{\mathcal{U}}={\mathbf{u}}}({\mathbf{y}},{\mathbf{u}})f_{{\mathcal{U}}}({\mathbf{u}})\,d{\mathbf{u}}\\
&amp;=\int_{{\mathbf{u}}}\frac{1}{\sqrt{2\pi}^q}e^{\sum_{i=1}^n(1-y_i)\log(1-\mu_i)+y_i\,\log(\mu_i)}
e^{-\left\|{\mathbf{u}}\right\|^2/2}\,d{\mathbf{u}}\\
&amp;=\int_{{\mathbf{u}}}\frac{1}{\sqrt{2\pi}^q}\exp\left(\frac{\left\|{\mathbf{u}}\right\|^2+\sum_{i=1}^n d(y_i,\mu_i)}{-2}\right)\,d{\mathbf{u}}
\end{aligned}
\tag{C.4}\]</span></span> where the <em>unit deviances</em>, <span class="math inline">\(d(y_i,\mu_i)\)</span>, are <span id="eq-unitdeviances"><span class="math display">\[
d(y_i,\mu_i)=-2\left[(1-y_i)\log(1-\mu_i)+y_i\log(\mu_i)\right]\quad i=1,\dots,n .
\tag{C.5}\]</span></span></p>
<p>By converting from the logarithm of the probability mass function to the <a href="https://en.wikipedia.org/wiki/Deviance_(statistics)">deviance</a> scale, which is negative twice the log-probability, we get a quantity, <span class="math inline">\(\sum_{i=1}^n d(y_i,\mu_i)\)</span>, which is on the same scale as the squared length, <span class="math inline">\(\|{\mathbf{u}}\|^2\)</span>, of a standard multivariate Gaussian. The sum of the unit deviances is analogous to the sum of squared residuals, <span class="math inline">\(\|{\mathbf{y}}-{\mathbf{X}}{\boldsymbol{\beta}}\|^2\)</span>, in a linear model.</p>
<p>In <a href="linalg.html#sec-lmmtheory"><span>Section&nbsp;B.7</span></a> we showed that the integral defining the likelihood for a linear mixed model, <a href="linalg.html#eq-likelihood-integral">Equation&nbsp;<span>B.43</span></a>, has an analytic solution. In general, the integral in <a href="#eq-GLMMlikelihood">Equation&nbsp;<span>C.4</span></a> does not. We will approximate the value of this integral using a quadratic approximation to the argument of the exponential function in <a href="#eq-GLMMlikelihood">Equation&nbsp;<span>C.4</span></a> at the value of <span class="math inline">\({\mathbf{u}}\)</span> that maximizes the integrand, which is the density of the conditional distribution, <span class="math inline">\(({\mathcal{U}}|{\mathcal{Y}}={\mathbf{y}})\)</span>, up to a scale factor. Because the scale factor does not affect the location of the maximum, the value of <span class="math inline">\({\mathbf{u}}\)</span> that maximizes the integrand, <span id="eq-condmode"><span class="math display">\[
\begin{aligned}
\tilde{{\mathbf{u}}}({\mathbf{y}}|{\boldsymbol{\theta}},{\boldsymbol{\beta}})
&amp;=\arg\max_{{\mathbf{u}}}\exp\left(\frac{\left\|{\mathbf{u}}\right\|^2 + \sum_{i=1}^n d(y_i,\mu_i)}{-2}\right)\\
&amp;=\arg\min_{{\mathbf{u}}}\left(\left\|{\mathbf{u}}\right\|^2 + \sum_{i=1}^n d(y_i,\mu_i)\right)
\end{aligned} ,
\tag{C.6}\]</span></span> is also the <em>conditional mode</em> — the value of <span class="math inline">\({\mathbf{u}}\)</span> that maximizes the conditional density. The expression being minimized in <a href="#eq-condmode">Equation&nbsp;<span>C.6</span></a>, <span class="math inline">\(\left\|{\mathbf{u}}\right\|^2 + \sum_{i=1}^n d(y_i,\mu_i)\)</span>, is called the <em>penalized deviance</em>.</p>
<p>Using a quadratic approximation to the penalized deviance at this conditional mode (i.e.&nbsp;the mode of the conditional distribution of <span class="math inline">\({\mathcal{U}}\)</span> given <span class="math inline">\({\mathcal{Y}}={\mathbf{y}}\)</span>) is equivalent to using a multivariate Gaussian approximation to this conditional distribution. Approximating an integral like <a href="#eq-GLMMlikelihood">Equation&nbsp;<span>C.4</span></a> by approximating the integrand as a scaled multivariate Gaussian distribution at its mode is called <a href="https://en.wikipedia.org/wiki/Laplace%27s_approximation">Laplace’s approximation</a> (<span class="citation" data-cites="TierneyKadane1986">Tierney &amp; Kadane (<a href="references.html#ref-TierneyKadane1986" role="doc-biblioref">1986</a>)</span>).</p>
<p>The <em>penalized iteratively re-weighted least squares</em> (PIRLS) algorithm (<a href="#sec-PIRLS"><span>Section&nbsp;C.4</span></a>) provides a fast and stable method of determining the conditional mode, <span class="math inline">\(\tilde{{\mathbf{u}}}({\mathbf{y}}|{\boldsymbol{\theta}},{\boldsymbol{\beta}})\)</span> (<a href="#eq-condmode">Equation&nbsp;<span>C.6</span></a>), thereby making it feasible to use Laplace’s approximation at scale.</p>
<p>Before discussing PIRLS, however, we will describe generalized linear models (GLMs) without random effects (<a href="#sec-BernoulliGLM"><span>Section&nbsp;C.2</span></a>), for which the <em>deviance</em> is defined as the sum of the unit deviances and the maximum likelihood estimate of the coefficient vector, <span class="math inline">\(\widehat{{\boldsymbol{\beta}}}\)</span>, is the value that minimizes the deviance. In <a href="#sec-IRLS"><span>Section&nbsp;C.3</span></a> we describe the <em>iteratively re-weighted least squares</em> (IRLS) algorithm, which is a stable, fast algorithm to minimize the deviance.</p>
<p>We will illustrate the IRLS algorithm with the <code>contra</code> data discussed in <a href="glmmbernoulli.html"><span>Chapter&nbsp;6</span></a> and a model like <code>com05</code>, which was fit in that chapter, but without the random effects. Later we will use the full <code>com05</code> model to illustrate some of the computations for GLMMs.</p>
<p>Although 0/1 responses and the Bernoulli distribution are easy to describe, the theory of the generalized linear mixed model (GLMM) and the details of the implementation are not. Readers who wish to focus on practical applications more than on the theory should feel free to skim this appendix.</p>
<p>Load the packages to be used</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">AlgebraOfGraphics</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">BenchmarkTools</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CairoMakie</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">FreqTables</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">LinearAlgebra</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">MixedModels</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">MixedModelsMakie</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">NLopt</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">PooledArrays</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">ProgressMeter</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">StatsAPI</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># showcompact prints a vector compactly</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(x) <span class="op">=</span> <span class="fu">show</span>(<span class="fu">IOContext</span>(<span class="cn">stdout</span>, <span class="op">:</span>compact <span class="op">=&gt;</span> <span class="cn">true</span>), x)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>ProgressMeter.<span class="fu">ijulia_behavior</span>(<span class="op">:</span>clear)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>CairoMakie.<span class="fu">activate!</span>(; <span class="kw">type</span><span class="op">=</span><span class="st">"svg"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="sec-BernoulliGLM" class="level2" data-number="C.2">
<h2 data-number="C.2" class="anchored" data-anchor-id="sec-BernoulliGLM"><span class="header-section-number">C.2</span> Generalized linear models for binary data</h2>
<p>To introduce some terms and workflows we first consider the generalized linear model (GLM) for the Bernoulli distribution and the logit link. The linear predictor for a GLM - a model without random effects - is simply <span class="math display">\[
{{\boldsymbol{\eta}}}= {{\mathbf{X}}}{{\boldsymbol{\beta}}} ,
\]</span> and the mean response vector, <span class="math inline">\({{\boldsymbol{\mu}}}={\mathbf{g}}^{-1}({\boldsymbol{\eta}})\)</span>, is obtained by component-wise application of the scalar logistic function (<a href="#eq-scalarlogistic">Equation&nbsp;<span>C.1</span></a>).</p>
<p>The probability mass function for the Bernoulli distribution is <span class="math display">\[
f_{{\mathcal{Y}}}(y|\mu) = \mu^y\,(1-\mu)^{(1-y)}\quad\mathrm{for}\quad y\in\{0,1\} .
\]</span></p>
<p>Because the elements of <span class="math inline">\({{\mathcal{Y}}}|{{\boldsymbol{\mu}}}\)</span> are assumed to be independent, the log-likelihood is simply the sum of contributions from each element, which, on the deviance scale, can be written in terms of the <em>unit deviances</em> <span id="eq-Bernoulliloglik"><span class="math display">\[
\begin{aligned}
-2\,\ell({{\boldsymbol{\mu}}}|{\mathbf{y}})&amp;= -2\,\log(L({{\boldsymbol{\mu}}}|{\mathbf{y}}))\\
&amp;=-2\,\sum_{i=1}^n y_i\log(\mu_i)+(1-y_i)\log(1-\mu_i) .
\end{aligned}
\tag{C.7}\]</span></span></p>
<p>As described above, it is customary when working with GLMs to convert the log-likelihood to a <a href="https://en.wikipedia.org/wiki/Deviance_(statistics)">deviance</a>, which, for the Bernoulli distribution, is negative twice the log-likelihood. (For other distributions, the deviance may incorporate an additional term that depends only on <span class="math inline">\({\mathbf{y}}\)</span>.)</p>
<p>One reason for preferring the deviance scale is that the change in deviance for nested models has approximately a <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom determined by the number of independent constraints on the parameters in the simpler model. Especially for GLMs, the deviance plays a role similar to the sum of squared residuals in linear models.</p>
<p>For greater numerical precision we avoid calculating <span class="math inline">\(1-\mu\)</span> directly when evaluating expressions like <a href="#eq-Bernoulliloglik">Equation&nbsp;<span>C.7</span></a> and instead use <span class="math display">\[
1 - \mu = 1 - \frac{1}{1+e^{-\eta}}=\frac{e^{-\eta}}{1+e^{-\eta}} .
\]</span> Evaluation of the last expression provides greater precision for large negative values of <span class="math inline">\(\eta\)</span> (corresponding to small values of <span class="math inline">\(\mu\)</span>) than does first evaluating <span class="math inline">\(\mu\)</span> followed by <span class="math inline">\(1 - \mu\)</span>.</p>
<p>After some algebra, we write the <em>unit deviance</em>, <span class="math inline">\(d(y_i,\eta_i)\)</span>, which is the contribution to the deviance from the <span class="math inline">\(i\)</span>th observation, as <span class="math display">\[
\begin{aligned}
d(y_i, \eta_i)&amp;=-2\left[y_i\log(\mu_i)+(1-y_i)\log(1-\mu_i)\right]\\
&amp;=2\left[(1-y_i)\eta_i-\log(1+e^{-\eta_i})\right]
\end{aligned}
\quad i=1,\dots,n
\]</span></p>
<p>A Julia function to evaluate both the mean and the unit deviance can be written as</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">meanunitdev</span>(y<span class="op">::</span><span class="dt">T</span>, η<span class="op">::</span><span class="dt">T</span>) <span class="kw">where</span> {T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  expmη <span class="op">=</span> <span class="fu">exp</span>(<span class="op">-</span>η)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (; μ<span class="op">=</span><span class="fu">inv</span>(<span class="fl">1</span> <span class="op">+</span> expmη), dev<span class="op">=</span><span class="fl">2</span> <span class="op">*</span> ((<span class="fl">1</span> <span class="op">-</span> y) <span class="op">*</span> η <span class="op">+</span> <span class="fu">log1p</span>(expmη)))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
log1p
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Mathematically <code>log1p</code>, read <em>log of 1 plus</em>, is defined as <span class="math inline">\(\mathrm{log1p}(x)=\log(1+x)\)</span> but it is implemented in such a way as to provide greater accuracy when <span class="math inline">\(x\)</span> is small. For example,</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> small <span class="op">=</span> <span class="fu">eps</span>() <span class="op">/</span> <span class="fl">10</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@show</span> small</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@show</span> <span class="fl">1</span> <span class="op">+</span> small</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@show</span> <span class="fu">log</span>(<span class="fl">1</span> <span class="op">+</span> small)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@show</span> <span class="fu">log1p</span>(small)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span>;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>small = 2.2204460492503132e-17
1 + small = 1.0
log(1 + small) = 0.0
log1p(small) = 2.2204460492503132e-17</code></pre>
</div>
</div>
<p><code>1 + small</code> evaluates to <code>1.0</code> in floating point arithmetic because of round-off, producing 0 for the expression <code>log(1 + small)</code>, whereas <code>log1p(small) ≈ small</code>, as it should be.</p>
</div>
</div>
</div>
<p>This function returns a <code>NamedTuple</code> of values from scalar arguments. For example,</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">meanunitdev</span>(<span class="fl">0.0</span>, <span class="fl">0.21</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(μ = 0.5523079095743253, dev = 1.6072991620435673)</code></pre>
</div>
</div>
<p>A <code>Vector</code> of such <code>NamedTuple</code>s is a <em>row-table</em> (<a href="datatables.html#sec-Tablesjl"><span>Section&nbsp;A.2</span></a>), which can be updated in place by <a href="https://docs.julialang.org/en/v1/manual/functions/#man-vectorized">dot-vectorization</a> of the scalar <code>meanunitdev</code> function, as shown below.</p>
<section id="an-example-fixed-effects-only-from-com05" class="level3" data-number="C.2.1">
<h3 data-number="C.2.1" class="anchored" data-anchor-id="an-example-fixed-effects-only-from-com05"><span class="header-section-number">C.2.1</span> An example: fixed-effects only from com05</h3>
<p>We illustrate some of these computations using only the fixed-effects specification for <code>com05</code>, a GLMM fit to the <code>contra</code> data set in <a href="glmmbernoulli.html"><span>Chapter&nbsp;6</span></a>. Because we will use the full GLMM later we reproduce <code>com05</code> by loading the data, creating the binary <code>ch</code> variable indicating children/no-children, defining the contrasts and formula to be used, and fitting the model as in <a href="glmmbernoulli.html"><span>Chapter&nbsp;6</span></a>.</p>
<div class="cell" data-execution_count="5">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>contra <span class="op">=</span> <span class="kw">let</span> tbl <span class="op">=</span> MixedModels.<span class="fu">dataset</span>(<span class="op">:</span>contra)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Table</span>(tbl; ch<span class="op">=</span>tbl.livch <span class="op">.≠</span> <span class="st">"0"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>contrasts <span class="op">=</span> <span class="fu">Dict</span><span class="dt">{Symbol,Any}</span>(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">:</span>urban <span class="op">=&gt;</span> <span class="fu">HelmertCoding</span>(),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">:</span>ch <span class="op">=&gt;</span> <span class="fu">HelmertCoding</span>(),</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="op">:</span>dist <span class="op">=&gt;</span> <span class="fu">Grouping</span>(),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>com05 <span class="op">=</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> form <span class="op">=</span> <span class="pp">@formula</span> use <span class="op">~</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>      <span class="fl">1</span> <span class="op">+</span> urban <span class="op">+</span> ch <span class="op">*</span> age <span class="op">+</span> age <span class="op">&amp;</span> age <span class="op">+</span> (<span class="fl">1</span> <span class="op">|</span> dist <span class="op">&amp;</span> urban)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(MixedModel, form, contra, <span class="fu">Bernoulli</span>(); contrasts, nAGQ<span class="op">=</span><span class="fl">9</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Extract the fixed-effects model matrix, <span class="math inline">\({\mathbf{X}}\)</span>, and initialize the coefficient vector, <span class="math inline">\({\boldsymbol{\beta}}\)</span>, to a copy (in case we modify it) of the estimated fixed-effects.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>βm05 <span class="op">=</span> <span class="fu">copy</span>(com05.β)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(βm05)   <span class="co"># showcompact is defined in the first code block</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-0.341475, 0.393592, 0.606449, -0.0129098, 0.0332106, -0.00562463]</code></pre>
</div>
</div>
<p>As stated above, the <code>meanunitdev</code> function can be applied to the vectors, <span class="math inline">\({\mathbf{y}}\)</span> and <span class="math inline">\({{\boldsymbol{\eta}}}\)</span>, via dot-vectorization to produce a <code>Vector{NamedTuple}</code>, which is the typical form of a row-table.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>rowtbl <span class="op">=</span> <span class="fu">meanunitdev</span>.(com05.y, com05.X <span class="op">*</span> βm05)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">typeof</span>(rowtbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div class="ansi-escaped-output">
<pre>Vector{NamedTuple{(:μ, :dev), Tuple{Float64, Float64}}}<span class="ansi-bright-black-fg"> (alias for </span><span class="ansi-bright-black-fg">Array{NamedTuple{(:μ, :dev), Tuple{Float64, Float64}}, 1}</span><span class="ansi-bright-black-fg">)</span></pre>
</div>
</div>
</div>
<p>For display we convert the row-table to a column-table and prepend another column-table consisting of <span class="math inline">\({\mathbf{y}}\)</span> and <span class="math inline">\({\boldsymbol{\eta}}\)</span>.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Table</span>((; y<span class="op">=</span>com05.y, η<span class="op">=</span>com05.X <span class="op">*</span> βm05), rowtbl)  <span class="co"># display as a Table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>Table with 4 columns and 1934 rows:
      y    η          μ         dev
    ┌───────────────────────────────────
 1  │ 0.0  -0.87965   0.29325   0.694158
 2  │ 0.0  -0.471779  0.384195  0.96965
 3  │ 0.0  0.676137   0.662876  2.17461
 4  │ 0.0  0.429243   0.605693  1.86125
 5  │ 0.0  -0.96316   0.276246  0.646607
 6  │ 0.0  -0.772819  0.31587   0.759213
 7  │ 0.0  -0.87965   0.29325   0.694158
 8  │ 0.0  0.515012   0.625981  1.9669
 9  │ 0.0  0.371817   0.591898  1.79248
 10 │ 0.0  0.676137   0.662876  2.17461
 11 │ 1.0  -0.772819  0.31587   2.30485
 12 │ 0.0  -0.473125  0.383877  0.968617
 13 │ 0.0  0.449039   0.610411  1.88532
 14 │ 0.0  0.60255    0.64624   2.07827
 15 │ 0.0  0.645435   0.655981  2.13412
 16 │ 1.0  0.637821   0.654261  0.848499
 17 │ 0.0  -0.471779  0.384195  0.96965
 18 │ 1.0  0.645435   0.655981  0.843247
 19 │ 1.0  0.283345   0.570366  1.12295
 20 │ 0.0  0.515012   0.625981  1.9669
 21 │ 0.0  -0.460979  0.386754  0.977977
 22 │ 0.0  -0.627476  0.348083  0.855677
 23 │ 0.0  0.674614   0.662536  2.17259
 ⋮  │  ⋮       ⋮         ⋮         ⋮</code></pre>
</div>
</div>
<p>The deviance for this value of <span class="math inline">\({{\boldsymbol{\beta}}}\)</span> in this model is the sum of the unit deviances, which we write as <code>sum</code> applied to a <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">generator expression</a>. (In general we extract columns of a row-table with generator expressions that produce <a href="https://docs.julialang.org/en/v1/base/collections/#lib-collections-iteration">iterators</a>.)</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(r.dev <span class="cf">for</span> r <span class="kw">in</span> rowtbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>2411.1935798730165</code></pre>
</div>
</div>
</section>
<section id="encapsulating-the-model-in-a-struct" class="level3" data-number="C.2.2">
<h3 data-number="C.2.2" class="anchored" data-anchor-id="encapsulating-the-model-in-a-struct"><span class="header-section-number">C.2.2</span> Encapsulating the model in a struct</h3>
<p>When minimizing the deviance it is convenient to have the different components of the model encapsulated in a user-created <code>struct</code> type so we can update the parameter values and evaluate the deviance without needing to keep track of all the pieces of the model.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">struct</span> BernoulliGLM{T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  β<span class="op">::</span><span class="dt">Vector{T}</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  ytbl<span class="op">::</span><span class="dt">NamedTuple{(:y, :η),NTuple{2,Vector{T}}}</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  rtbl<span class="op">::</span><span class="dt">Vector{NamedTuple{(:μ, :dev),NTuple{2,T}}}</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We also create an <em>external constructor</em>, which is a function defined outside the struct and of the same name as the struct, that constructs and returns an object of that type. In this case the external constructor creates a <code>BernoulliGLM</code> from the model matrix and the response vector, after some consistency checks on the arguments passed to it.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">BernoulliGLM</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  y<span class="op">::</span><span class="dt">Vector{T}</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>) <span class="kw">where</span> {T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># check consistency of arguments</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> <span class="fu">size</span>(X, <span class="fl">1</span>)                  <span class="co"># number of rows in X</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="fu">length</span>(y) <span class="op">≠</span> n <span class="op">||</span> <span class="fu">any</span>(!<span class="fu">in</span>([<span class="fl">0</span>, <span class="fl">1</span>]), y)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"y is not an </span><span class="sc">$</span>n<span class="st">-vector of 0's and 1's"</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial β from linear regression of y in {-1,1} coding</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  β <span class="op">=</span> X <span class="op">\</span> <span class="fu">replace</span>(y, <span class="fl">0</span> <span class="op">=&gt;</span> <span class="op">-</span><span class="fl">1</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  η <span class="op">=</span> X <span class="op">*</span> β</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">BernoulliGLM</span>(X, β, (; y, η), <span class="fu">meanunitdev</span>.(y, η))</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To optimize the deviance we define an <em>extractor</em> method that returns the deviance</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>StatsAPI.<span class="fu">deviance</span>(m<span class="op">::</span><span class="dt">BernoulliGLM</span>) <span class="op">=</span> <span class="fu">sum</span>(r.dev <span class="cf">for</span> r <span class="kw">in</span> m.rtbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why StatsAPI.deviance and not just deviance?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This extractor is written as a method for the generic <code>deviance</code> function defined in the <code>StatsAPI</code> package. Doing so allows us to use the <code>deviance</code> name for the extractor without interfering with <code>deviance</code> methods defined for other model types.</p>
</div>
</div>
</div>
<p>We also define a mutating function, <code>setβ!</code>, that installs a new value of <code>β</code> then updates <code>η</code> and <code>rtbl</code> in place.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">setβ!</span>(m<span class="op">::</span><span class="dt">BernoulliGLM</span>, newβ)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  (; y, η) <span class="op">=</span> m.ytbl                <span class="co"># destructure ytbl</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mul!</span>(η, m.X, <span class="fu">copyto!</span>(m.β, newβ)) <span class="co"># η = X * newβ in place</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  m.rtbl <span class="op">.=</span> <span class="fu">meanunitdev</span>.(y, η)     <span class="co"># update rtbl in place</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create such a struct from <code>X</code> and <code>y</code> for model <code>com05</code>.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>com05fe <span class="op">=</span> <span class="fu">BernoulliGLM</span>(com05.X, com05.y)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>β₀ <span class="op">=</span> <span class="fu">copy</span>(com05fe.β)          <span class="co"># keep a copy of the initial values</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(β₀)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-0.107533, 0.175966, 0.219448, -0.00285474, 0.0101399, -0.00216183]</code></pre>
</div>
</div>
<p>These initial values of <span class="math inline">\({\boldsymbol{\beta}}\)</span> are from a least squares fit of <span class="math inline">\({\mathbf{y}}\)</span>, converted from <code>{0,1}</code> coding to <code>{-1,1}</code> coding, on the model matrix, <span class="math inline">\({\mathbf{X}}\)</span>.</p>
<p>As a simple test of the <code>setβ!</code> and <code>deviance</code> methods we can check that <code>com05fe</code> produces the same deviance value for <code>βm05</code> as was evaluated above.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(<span class="fu">setβ!</span>(com05fe, βm05))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>2411.1935798730165</code></pre>
</div>
</div>
<p>For fairness in later comparisons we restore the initial values <code>β₀</code> to the model. These are rough starting estimates with a deviance that is considerably greater than that at <code>βm05</code>.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(<span class="fu">setβ!</span>(com05fe, β₀))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>2491.151439053724</code></pre>
</div>
</div>
</section>
<section id="fit-the-glm-using-a-general-optimizer" class="level3" data-number="C.2.3">
<h3 data-number="C.2.3" class="anchored" data-anchor-id="fit-the-glm-using-a-general-optimizer"><span class="header-section-number">C.2.3</span> Fit the GLM using a general optimizer</h3>
<p>We can use a general optimizer like those available in <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a> to minimize the deviance. Following the instructions given at that package’s repository, we create an <code>Opt</code> object specifying the algorithm to be used, BOBYQA (<span class="citation" data-cites="powell2009bobyqa">Powell (<a href="references.html#ref-powell2009bobyqa" role="doc-biblioref">2009</a>)</span>), and the dimension of the problem, then define and assign the objective function in the required form, and call <code>optimize</code></p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> StatsAPI.<span class="fu">fit!</span>(m<span class="op">::</span><span class="dt">BernoulliGLM{T}</span>) <span class="kw">where</span> {T}</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  opt <span class="op">=</span> <span class="fu">Opt</span>(<span class="op">:</span>LN_BOBYQA, <span class="fu">length</span>(m.β))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">objective</span>(x<span class="op">::</span><span class="dt">Vector{T}</span>, g<span class="op">::</span><span class="dt">Vector{T}</span>) <span class="kw">where</span> {T}</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">isempty</span>(g) <span class="op">||</span> <span class="fu">throw</span>(</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ArgumentError</span>(<span class="st">"Gradient not available, g must be empty"</span>),</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">deviance</span>(<span class="fu">setβ!</span>(m, x))</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  opt.min_objective <span class="op">=</span> objective</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  minf, minx, ret <span class="op">=</span> <span class="fu">optimize</span>(opt, <span class="fu">copy</span>(m.β))</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@info</span> (; code<span class="op">=</span>ret, nevals<span class="op">=</span>opt.numevals, minf)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit!</span>(com05fe);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: (code = :ROUNDOFF_LIMITED, nevals = 545, minf = 2409.377428160019)</code></pre>
</div>
</div>
<p>The optimizer has determined a coefficient vector that reduces the deviance to 2409.38, at which point convergence was declared because changes in the objective are limited by round-off. This required about 500 evaluations of the deviance at candidate values of <span class="math inline">\({\boldsymbol{\beta}}\)</span>.</p>
<p>Each evaluation of the deviance is fast, requiring only a fraction of a millisecond on a laptop computer,</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>βopt <span class="op">=</span> <span class="fu">copy</span>(com05fe.β)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="pp">@benchmark</span> <span class="fu">deviance</span>(<span class="fu">setβ!</span>(m, β)) seconds <span class="op">=</span> <span class="fl">1</span> setup <span class="op">=</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  (m <span class="op">=</span> com05fe; β <span class="op">=</span> βopt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div class="ansi-escaped-output">
<pre>BenchmarkTools.Trial: 10000 samples with 1 evaluation.
 Range <span class="ansi-bright-black-fg">(</span><span class="ansi-cyan-fg ansi-bold">min</span> … <span class="ansi-magenta-fg">max</span><span class="ansi-bright-black-fg">):  </span><span class="ansi-cyan-fg ansi-bold">27.125 μs</span> … <span class="ansi-magenta-fg">83.708 μs</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>min … max<span class="ansi-bright-black-fg">): </span>0.00% … 0.00%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-blue-fg ansi-bold">median</span><span class="ansi-bright-black-fg">):     </span><span class="ansi-blue-fg ansi-bold">33.459 μs              </span><span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>median<span class="ansi-bright-black-fg">):    </span>0.00%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-green-fg ansi-bold">mean</span> ± <span class="ansi-green-fg">σ</span><span class="ansi-bright-black-fg">):   </span><span class="ansi-green-fg ansi-bold">31.968 μs</span> ± <span class="ansi-green-fg"> 3.005 μs</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>mean ± σ<span class="ansi-bright-black-fg">):  </span>0.00% ± 0.00%
    ▄▆▄                                <span class="ansi-green-fg"> </span>         ▄<span class="ansi-blue-fg">█</span>▆▁   ▁▄▃    
  ▂▆███▆▃▂▂▂▁▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂<span class="ansi-green-fg">▂</span>▂▂▂▂▂▂▂▃▇█<span class="ansi-blue-fg">█</span>██▆▄▆███▇▄ ▃
  27.1 μs<span class="ansi-bright-black-fg">         Histogram: frequency by time</span>        34.8 μs <span class="ansi-bold">&lt;</span>
 Memory estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">16 bytes</span>, allocs estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">1</span>.</pre>
</div>
</div>
</div>
<p>but the already large number of evaluations for these six coefficients would not scale well as this dimension increases.</p>
<p>Fortunately there is an algorithm, called <em>iteratively reweighted least squares</em> (IRLS), that uses the special structure of the GLM to provide fast and stable convergence to estimates of the coefficients, even for models with a large number of coefficients. This will be important to us in fitting GLMMs where we must optimize with respect to the random effects, whose dimension can be large.</p>
</section>
</section>
<section id="sec-IRLS" class="level2" data-number="C.3">
<h2 data-number="C.3" class="anchored" data-anchor-id="sec-IRLS"><span class="header-section-number">C.3</span> The IRLS algorithm</h2>
<p>As we have seen, in a GLM we are modeling the responses and the predicted values on two scales — the <em>linear predictor scale</em>, for <span class="math inline">\({\boldsymbol{\eta}}\)</span>, and the <em>response scale</em>, for <span class="math inline">\({\mathbf{y}}\)</span> and <span class="math inline">\({\boldsymbol{\mu}}\)</span>. The scalar link function, <span class="math inline">\(\eta=g(\mu)\)</span>, and the inverse link, <span class="math inline">\(\mu=g^{-1}(\eta)\)</span>, map vectors component-wise between these two scales.</p>
<p>For operations like determining a new candidate value of <span class="math inline">\({\boldsymbol{\beta}}\)</span>, the linear predictor scale is preferred, because, on that scale, <span class="math inline">\({\boldsymbol{\eta}}={\mathbf{X}}{\boldsymbol{\beta}}\)</span> is a linear function of <span class="math inline">\({\boldsymbol{\beta}}\)</span>. Thus it would be convenient if we could transform the response, <span class="math inline">\({\mathbf{y}}\)</span>, to the linear predictor scale where we could define a residual and use some form of minimizing a sum of squared residuals to evaluate a new coefficient vector (or, alternatively, evaluate an increment that will be added to the current coefficient vector). Unfortunately, a naive approach of transforming <span class="math inline">\({\mathbf{y}}\)</span> to the linear predictor scale won’t work because the elements of <span class="math inline">\({\mathbf{y}}\)</span> are all <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> and the logit link function maps these values to <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(\infty\)</span>, respectively.</p>
<p>For an iterative algorithm, however, we can use a local linear approximation to the link function to define a <em>working residual</em>, from which to evaluate an increment to the coefficient vector, or a <em>working response</em>, from which we evaluate the new coefficient vector directly. Because the link and inverse link functions are defined component-wise we will define the approximation for scalars <span class="math inline">\(y_i\)</span>, <span class="math inline">\(\mu_i\)</span>, and <span class="math inline">\(\eta_i\)</span> and for the scalar link function, <span class="math inline">\(g\)</span>, with the understanding that these definitions apply component-wise to the vectors.</p>
<p>The <em>working residual</em> is evaluated by mapping the residual on the response scale, <span class="math inline">\(y_i-\mu_i\)</span>, through the linear approximation to the link, <span class="math inline">\(g(\mu)\)</span>, at <span class="math inline">\(\mu_i\)</span>. That is, <span class="math display">\[
\tilde{r_i}=(y_i-\mu_i)g'(\mu_i)\quad i=1,\dots,n .
\]</span> Because the derivative, <span class="math inline">\(g'(\mu_i)\)</span>, for the logit link function is <span class="math inline">\(1/[\mu_i(1-\mu_i)]\)</span>, these working residuals are <span class="math display">\[
\tilde{r}_i = (y_i-\mu_i)g'(\mu_i) = \frac{y_i - \mu_i}{\mu_i(1-\mu_i)}\quad i=1,\dots,n .
\]</span> Similarly, the <em>working response</em> on the linear predictor scale, is defined by adding the working residual to the current linear predictor value, <span class="math display">\[
\tilde{y_i}=\eta_i + \tilde{r_i}=\eta_i +(y_i-\mu_i)g'(\mu_i)=
\eta_i + \frac{y_i - \mu_i}{\mu_i(1-\mu_i)}\quad i=1,\dots,n .
\]</span></p>
<p>On the linear predictor scale we can fit a linear model to the working response to obtain a new parameter vector, but we must take into account that the variances of the <em>noise terms</em> in this linear model, which are the working residuals, are not constant. We use <em>weighted least squares</em> where the weights are inversely proportional to the variance of the working residual. The variance of the random variable <span class="math inline">\({\mathcal{Y}}_i\)</span> is <span class="math inline">\(\mu_i(1-\mu_i)\)</span>, hence the variance of the working residual is <span class="math display">\[
\mathrm{Var}(\tilde{r_i})=g'(\mu_i)^2 \mathrm{Var}({\mathcal{Y}}_i)=\frac{\mu_i(1-\mu_i)}{\left[\mu_i(1-\mu_i)\right]^2}=\frac{1}{\mu_i(1-\mu_i)}
\quad i=1,\dots,n .
\]</span></p>
<p>Thus the working weights are <span class="math display">\[
\begin{aligned}
w_i&amp;=\mu_i(1-\mu_i)\\
&amp;=\frac{1}{1+e^{-\eta_i}}\frac{e^{-\eta_i}}{1+e^{-\eta_i}}
\end{aligned}
,\quad i=1,\dots,n.
\]</span></p>
<p>In practice we will use the square roots of the working weights, evaluated as <span class="math display">\[
\sqrt{w_i}=\frac{\sqrt{e^{-\eta_i}}}{1+e^{-\eta_i}}=\frac{e^{-\eta_i/2}}{1+e^{-\eta_i}}\quad i=1,\dots,n .
\]</span></p>
<p>Note that <span class="math inline">\(\mathrm{Var}({\mathcal{Y}}_i)\)</span> happens to be the inverse of <span class="math inline">\(g'(\mu_i)\)</span> for a Bernoulli response and the logit link function. This will always be true for distributions in the <a href="https://en.wikipedia.org/wiki/Exponential_family">exponential family</a> and their canonial links.</p>
<p>At the <span class="math inline">\(k\)</span>th iteration the IRLS algorithm updates the coefficient vector to <span class="math inline">\({\boldsymbol{\beta}}^{(k)}\)</span>, which is a weighted least squares solution that could be written as <span class="math display">\[
{\boldsymbol{\beta}}^{(k)}= \left({\mathbf{X}}'{\mathbf{W}}{\mathbf{X}}\right)^{-1}\left({\mathbf{X}}'{\mathbf{W}}\tilde{{\mathbf{y}}}\right) ,
\]</span> where <span class="math inline">\({\mathbf{W}}\)</span> is an <span class="math inline">\(n\times n\)</span> diagonal matrix of the working weights and <span class="math inline">\(\tilde{{\mathbf{y}}}\)</span> is the working response, both evaluated at <span class="math inline">\({\boldsymbol{\beta}}^{(k-1)}\)</span>, the coefficient vector from the previous iteration.</p>
<p>In practice we use the square roots of the working weights, which we write as a diagonal matrix, <span class="math inline">\({\mathbf{W}}^{1/2}\)</span>, and a QR decomposition (<a href="linalg.html#sec-matrixdecomp"><span>Section&nbsp;B.6</span></a>) of a weighted model matrix, <span class="math inline">\({\mathbf{W}}^{1/2}{\mathbf{X}}\)</span>, to solve for the updated coefficient vector from the weighted working response, <span class="math inline">\({\mathbf{W}}^{1/2}\tilde{{\mathbf{y}}}\)</span>, with elements <span class="math display">\[
\begin{aligned}
\sqrt{w_i}(\eta_i+\tilde{r}_i)&amp;=\sqrt{\mu_i(1-\mu_i)}(\eta_i+\tilde{r}_i)\\
&amp;=\sqrt{w_i}\eta_i +\frac{(y_i-\mu_i)\sqrt{\mu_i(1-\mu_i)}}{\mu_i(1-\mu_i)}\\
&amp;=\sqrt{w_i}\eta_i +\frac{y_i-\mu_i}{\sqrt{w_i}}
\end{aligned},\quad i=1,\dots,n
\]</span></p>
<p>It is possible to write the IRLS algorithm using a weighted least squares fit of the working residuals on the model matrix to determine a parameter increment. However, in the PIRLS algorithm it is necessary to use the working response, not the working residual, so we define the IRLS algorithm in those terms too.</p>
<p>Furthermore, in the PIRLS algorithm we will need to allow for an <em>offset</em> when calculating the working response. In the presence of an offset, <span class="math inline">\({\mathbf{o}}\)</span>, a constant vector of length <span class="math inline">\(n\)</span>, the linear predictor is defined as <span class="math display">\[
{\boldsymbol{\eta}}= {\mathbf{o}}+ {\mathbf{X}}{\boldsymbol{\beta}}.
\]</span> The mean, <span class="math inline">\({\boldsymbol{\mu}}\)</span>, the working weights and the working residuals are defined as before but the working response becomes <span class="math display">\[
\tilde{{\mathbf{y}}}=\tilde{{\mathbf{r}}} + {\boldsymbol{\eta}}- {\mathbf{o}}.
\]</span></p>
<p>For a linear model there is rarely a reason for using an offset. Instead we can simply subtract the constant vector, <span class="math inline">\({\mathbf{o}}\)</span>, from the response, <span class="math inline">\({\mathbf{y}}\)</span>, because the response and the linear predictor are on the same scale. However, this is not the case for a GLM where we must deal with the effects of the constant offset on the linear predictor scale, not on the response scale.</p>
<section id="implementation-of-irls-for-bernoulli-logit" class="level3" data-number="C.3.1">
<h3 data-number="C.3.1" class="anchored" data-anchor-id="implementation-of-irls-for-bernoulli-logit"><span class="header-section-number">C.3.1</span> Implementation of IRLS for Bernoulli-Logit</h3>
<p>We define a <code>BernoulliIRLS</code> struct with three additional elements in the rowtable: the square roots of the working weights, <code>rtwwt</code>, the weighted working residuals, <code>wwres</code>, and the weighted working response, <code>wwresp</code>. In the discussion above, <code>rtwwt</code> is the diagonal of <span class="math inline">\({\mathbf{W}}^{1/2}\)</span>, <code>wwres</code> is <span class="math inline">\({\mathbf{W}}^{1/2}\tilde{{\mathbf{r}}}\)</span> and <code>wwresp</code> is <span class="math inline">\({\mathbf{W}}^{1/2}\tilde{{\mathbf{y}}}\)</span>.</p>
<p>We also add fields <code>Xqr</code>, in which the weighted model matrix, <span class="math inline">\({\mathbf{W}}^{1/2}{\mathbf{X}}\)</span>, is formed followed by its QR decomposition, and <code>βcp</code>, which holds a copy of the previous coefficient vector.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">struct</span> BernoulliIRLS{T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  Xqr<span class="op">::</span><span class="dt">Matrix{T}                </span><span class="co"># copy of X used in the QR decomp</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  β<span class="op">::</span><span class="dt">Vector{T}</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  βcp<span class="op">::</span><span class="dt">Vector{T}                </span><span class="co"># copy of previous β</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  Whalf<span class="op">::</span><span class="dt">Diagonal{T,Vector{T}}  </span><span class="co"># rtwwt as a Diagonal matrix</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  ytbl<span class="op">::</span><span class="dt">NamedTuple{(:y, :η),NTuple{2,Vector{T}}}</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  rtbl<span class="op">::</span><span class="dt">Vector{</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="dt">    NamedTuple{(:μ, :dev, :rtwwt, :wwres, :wwresp),NTuple{5,T}},</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="dt">  }</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>with constructor</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">BernoulliIRLS</span>(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span>,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  y<span class="op">::</span><span class="dt">Vector{T}</span>,</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>) <span class="kw">where</span> {T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> <span class="fu">size</span>(X, <span class="fl">1</span>)          <span class="co"># number of rows of X</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="fu">length</span>(y) <span class="op">≠</span> n <span class="op">||</span> !<span class="fu">all</span>(v <span class="op">-&gt;</span> (<span class="fu">iszero</span>(v) <span class="op">||</span> <span class="fu">isone</span>(v)), y)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"y is not an </span><span class="sc">$</span>n<span class="st">-vector of 0's and 1's"</span>))</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial β from linear least squares fit of y in {-1,1} coding</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  Xqr <span class="op">=</span> <span class="fu">copy</span>(X)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>  β <span class="op">=</span> <span class="fu">qr!</span>(Xqr) <span class="op">\</span> <span class="fu">replace</span>(y, <span class="fl">0</span> <span class="op">=&gt;</span> <span class="op">-</span><span class="fl">1</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>  βcp <span class="op">=</span> <span class="fu">copy</span>(β)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>  η <span class="op">=</span> X <span class="op">*</span> β</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  rtbl <span class="op">=</span> <span class="fu">tblrow</span>.(y, η)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  Whalf <span class="op">=</span> <span class="fu">Diagonal</span>([r.rtwwt for r <span class="kw">in</span> rtbl])</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">BernoulliIRLS</span>(X, Xqr, β, βcp, Whalf, (; y, η), rtbl)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>tblrow</code> function evaluates the mean, unit deviance, square root of the weight, and the weighted, working residual and weighted, working response for scalar <span class="math inline">\(y\)</span> and <span class="math inline">\(\eta\)</span>. The <code>offset</code> argument, which defaults to zero, is not used in calls for <code>BernoulliIRLS</code> models, but will be used in <a href="#sec-PIRLS"><span>Section&nbsp;C.4</span></a> when we discuss the PIRLS algorithm.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">tblrow</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  y<span class="op">::</span><span class="dt">T</span>,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  η<span class="op">::</span><span class="dt">T</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  offset<span class="op">::</span><span class="dt">T</span>=<span class="fu">zero</span>(T),</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>) <span class="kw">where</span> {T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>}</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  rtexpmη <span class="op">=</span> <span class="fu">exp</span>(<span class="op">-</span>η <span class="op">/</span> <span class="fl">2</span>)      <span class="co"># square root of exp(-η)</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  expmη <span class="op">=</span> <span class="fu">abs2</span>(rtexpmη)      <span class="co"># exp(-η)</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  denom <span class="op">=</span> <span class="fl">1</span> <span class="op">+</span> expmη</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  μ <span class="op">=</span> <span class="fu">inv</span>(denom)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  dev <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> ((<span class="fl">1</span> <span class="op">-</span> y) <span class="op">*</span> η <span class="op">+</span> <span class="fu">log1p</span>(expmη))</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  rtwwt <span class="op">=</span> rtexpmη <span class="op">/</span> denom    <span class="co"># sqrt of working wt</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>  wwres <span class="op">=</span> (y <span class="op">-</span> μ) <span class="op">/</span> rtwwt    <span class="co"># weighted working resid</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  wwresp <span class="op">=</span> wwres <span class="op">+</span> rtwwt <span class="op">*</span> (η <span class="op">-</span> offset)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (; μ, dev, rtwwt, wwres, wwresp)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>StatsAPI.<span class="fu">deviance</span>(m<span class="op">::</span><span class="dt">BernoulliIRLS</span>) <span class="op">=</span> <span class="fu">sum</span>(r.dev <span class="cf">for</span> r <span class="kw">in</span> m.rtbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next we define a mutating function, <code>updateβ!</code>, that evaluates <span class="math inline">\({\boldsymbol{\beta}}^{(k)}\)</span>, the updated coefficient vector at iteration <span class="math inline">\(k\)</span>, in place by weighted least squares then updates the response table.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">updateβ!</span>(m<span class="op">::</span><span class="dt">BernoulliIRLS</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  (; X, Xqr, β, βcp, Whalf, ytbl, rtbl) <span class="op">=</span> m  <span class="co"># destructure m &amp; ytbl</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  (; y, η) <span class="op">=</span> ytbl</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(βcp, β)                            <span class="co"># keep a copy of β</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(Whalf.diag, r.rtwwt <span class="cf">for</span> r <span class="kw">in</span> rtbl) <span class="co"># rtwwt -&gt; Whalf</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mul!</span>(Xqr, Whalf, X)                        <span class="co"># weighted model matrix</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(η, r.wwresp <span class="cf">for</span> r <span class="kw">in</span> rtbl)         <span class="co"># use η as temp storage</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ldiv!</span>(β, <span class="fu">qr!</span>(Xqr), η)                      <span class="co"># weighted least squares</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>  rtbl <span class="op">.=</span> <span class="fu">tblrow</span>.(y, <span class="fu">mul!</span>(η, X, β))          <span class="co"># update η and rtbl</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For our example, we start at the same coefficient vector as we did with the general optimizer.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>com05fe <span class="op">=</span> <span class="fu">BernoulliIRLS</span>(com05.X, com05.y)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(com05fe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>2491.151439053725</code></pre>
</div>
</div>
<p>The first IRLS iteration</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(<span class="fu">updateβ!</span>(com05fe))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>2411.165742459925</code></pre>
</div>
</div>
<p>reduces the deviance substantially.</p>
<p>We create a <code>fit!</code> method to iterate to convergence.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> StatsAPI.<span class="fu">fit!</span>(m<span class="op">::</span><span class="dt">BernoulliIRLS</span>, β₀<span class="op">=</span>m.β; verbose<span class="op">::</span><span class="dt">Bool</span>=<span class="cn">true</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  (; X, β, βcp, ytbl, rtbl) <span class="op">=</span> m</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  (; y, η) <span class="op">=</span> ytbl</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  rtbl <span class="op">.=</span> <span class="fu">tblrow</span>.(y, <span class="fu">mul!</span>(η, X, <span class="fu">copyto!</span>(β, β₀)))</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  olddev <span class="op">=</span> <span class="fu">deviance</span>(m)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  verbose <span class="op">&amp;&amp;</span> <span class="pp">@info</span> <span class="fl">0</span>, olddev   <span class="co"># record the deviance at initial β</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span>               <span class="co"># perform at most 100 iterations</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    newdev <span class="op">=</span> <span class="fu">deviance</span>(<span class="fu">updateβ!</span>(m))</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">&amp;&amp;</span> <span class="pp">@info</span> i, newdev <span class="co"># iteration number and deviance</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> newdev <span class="op">&gt;</span> olddev</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>      <span class="pp">@warn</span> <span class="st">"failure to decrease deviance"</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">copyto!</span>(β, βcp)          <span class="co"># roll back changes to β, η, and rtbl</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>      rtbl <span class="op">=</span> <span class="fu">tblrow</span>.(y, <span class="fu">mul!</span>(η, X, β))</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elseif</span> (olddev <span class="op">-</span> newdev) <span class="op">&lt;</span> (<span class="fl">1.0e-10</span> <span class="op">*</span> olddev)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span>                    <span class="co"># exit loop if deviance is stable</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>      olddev <span class="op">=</span> newdev</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit!</span>(com05fe, β₀);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: (0, 2491.151439053724)
[ Info: (1, 2411.1657424599252)
[ Info: (2, 2409.3824513371324)
[ Info: (3, 2409.3774282835834)
[ Info: (4, 2409.3774281600413)</code></pre>
</div>
</div>
<p>The IRLS algorithm has converged in 4 iterations to essentially the same deviance as the general optimizer achieved after around 500 function evaluations. Each iteration of the IRLS algorithm takes more time than a deviance evaluation, but still only a fraction of a millisecond on a laptop computer.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="pp">@benchmark</span> <span class="fu">deviance</span>(<span class="fu">updateβ!</span>(m)) seconds <span class="op">=</span> <span class="fl">1</span> setup <span class="op">=</span> (m <span class="op">=</span> com05fe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<div class="ansi-escaped-output">
<pre>BenchmarkTools.Trial: 8220 samples with 1 evaluation.
 Range <span class="ansi-bright-black-fg">(</span><span class="ansi-cyan-fg ansi-bold">min</span> … <span class="ansi-magenta-fg">max</span><span class="ansi-bright-black-fg">):  </span><span class="ansi-cyan-fg ansi-bold">114.667 μs</span> … <span class="ansi-magenta-fg"> 2.608 ms</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>min … max<span class="ansi-bright-black-fg">): </span>0.00% … 94.45%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-blue-fg ansi-bold">median</span><span class="ansi-bright-black-fg">):     </span><span class="ansi-blue-fg ansi-bold">119.125 μs              </span><span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>median<span class="ansi-bright-black-fg">):    </span>0.00%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-green-fg ansi-bold">mean</span> ± <span class="ansi-green-fg">σ</span><span class="ansi-bright-black-fg">):   </span><span class="ansi-green-fg ansi-bold">120.368 μs</span> ± <span class="ansi-green-fg">43.096 μs</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>mean ± σ<span class="ansi-bright-black-fg">):  </span>0.67% ±  1.80%
                   ▂▂▅▇█▆<span class="ansi-blue-fg">█</span>█▃   <span class="ansi-green-fg"> </span>                                
  ▂▁▂▂▂▂▂▂▂▃▃▃▄▄▆▆███████<span class="ansi-blue-fg">█</span>███▇▅<span class="ansi-green-fg">▄</span>▃▃▄▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂ ▄
  115 μs<span class="ansi-bright-black-fg">          Histogram: frequency by time</span>          126 μs <span class="ansi-bold">&lt;</span>
 Memory estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">16.09 KiB</span>, allocs estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">5</span>.</pre>
</div>
</div>
</div>
</section>
</section>
<section id="sec-PIRLS" class="level2" data-number="C.4">
<h2 data-number="C.4" class="anchored" data-anchor-id="sec-PIRLS"><span class="header-section-number">C.4</span> GLMMs and the PIRLS algorithm</h2>
<p>In <a href="linalg.html#sec-lmmtheory"><span>Section&nbsp;B.7</span></a> we showed that, given a value of <span class="math inline">\({\boldsymbol{\theta}}\)</span>, which determines the relative covariance factor, <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}\)</span>, of the random effects, <span class="math inline">\({\mathcal{B}}\)</span>, the <em>conditional mode</em>, <span class="math inline">\(\tilde{{\mathbf{b}}}\)</span>, of the random effects can be evaluated as the solution to a <em>penalized least squares</em> (PLS) problem. It is convenient to write the PLS problem in terms of the <em>spherical random effects</em>, <span class="math inline">\({\mathcal{U}}\sim{\mathcal{N}}({\mathbf{0}},\sigma^2{\mathbf{I}})\)</span>, with the defining relationship <span class="math inline">\({\mathcal{B}}={\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}{\mathcal{U}}\)</span>, as in <a href="linalg.html#eq-penalized-rss">Equation&nbsp;<span>B.38</span></a> <span class="math display">\[
\tilde{{\mathbf{u}}}=\arg\min_{{\mathbf{u}}}\left(
\left\|{\mathbf{y}}-{\mathbf{X}}{\boldsymbol{\beta}}-{\mathbf{Z}}{\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}{\mathbf{u}}\right\|^2 +
\left\|{\mathbf{u}}\right\|^2
\right) .
\]</span></p>
<p>We wrote <a href="linalg.html#eq-penalized-rss">Equation&nbsp;<span>B.38</span></a> for the LMM case as minimizing the penalized sum of squared residuals with respect to both <span class="math inline">\({\boldsymbol{\beta}}\)</span> and <span class="math inline">\({\mathbf{u}}\)</span>. Here, and in <a href="#eq-condmodeu">Equation&nbsp;<span>C.8</span></a> below, we minimize with respect to <span class="math inline">\({\mathbf{u}}\)</span> only while holding <span class="math inline">\({\boldsymbol{\beta}}\)</span> fixed.</p>
<p>The solution of this PLS problem, <span class="math inline">\(\tilde{\mathbf{u}}\)</span>, is the <em>conditional mode</em> of <span class="math inline">\({\mathcal{U}}\)</span>, in that it maximizes the density of the conditional distribution, <span class="math inline">\(({\mathcal{U}}|{\mathcal{Y}}={\mathbf{y}})\)</span>, at the observed <span class="math inline">\({\mathbf{y}}\)</span>. (In the case of a LMM, where the conditional distributions, <span class="math inline">\(({\mathcal{B}}|{\mathcal{Y}}={\mathbf{y}})\)</span> and <span class="math inline">\(({\mathcal{U}}|{\mathcal{Y}}={\mathbf{y}})\)</span>, are multivariate Gaussian, the solution of the PLS problem is also the <em>mean</em> of the conditional distribution, but this property doesn’t carry over to GLMMs.)</p>
<p>In a Bernoulli generalized linear mixed model (GLMM) the mode of the conditional distribution, <span class="math inline">\(({\mathcal{U}}|{\mathcal{Y}}={\mathbf{y}})\)</span>, minimizes the <em>penalized GLM deviance</em>, <span id="eq-condmodeu"><span class="math display">\[
\tilde{{\mathbf{u}}}=\arg\min_{{\mathbf{u}}}\left(
\left\|{\mathbf{u}}\right\|^2+\sum_{i-1}^n d(y_i,\eta_i({\mathbf{u}}))
\right) ,
\tag{C.8}\]</span></span> where <span class="math inline">\(d(y_i,\eta_i),\,i=1,\dots,n\)</span> are the unit deviances defined in <a href="#sec-BernoulliGLM"><span>Section&nbsp;C.2</span></a>. We modify the IRLS algorithm as <em>penalized iteratively re-weighted least squares</em> (PIRLS) to determine these values.</p>
<p>As with IRLS, each iteration of the PIRLS algorithm involves using the current linear predictor, <span class="math inline">\({\boldsymbol{\eta}}({\mathbf{u}})={\mathbf{X}}{\boldsymbol{\beta}}+{\mathbf{Z}}{\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}{\mathbf{u}}\)</span>, (<span class="math inline">\({\boldsymbol{\beta}}\)</span> and <span class="math inline">\({\boldsymbol{\theta}}\)</span> are assumed known and fixed, and <span class="math inline">\({\mathbf{X}}{\boldsymbol{\beta}}\)</span> is an offset) to evaluate the mean, <span class="math inline">\({\boldsymbol{\mu}}={\mathbf{g}}^{-1}({\boldsymbol{\eta}})\)</span>, of the conditional distribution, <span class="math inline">\(({\mathcal{Y}}|{\mathcal{U}}={\mathbf{u}})\)</span>, as well as the unit deviances, <span class="math inline">\(d(y_i,\eta_i)\)</span>, the square roots of the working weights, which are on the diagonal of <span class="math inline">\({\mathbf{W}}^{1/2}\)</span>, and the weighted, working response, <span class="math inline">\({\mathbf{W}}^{1/2}\tilde{{\mathbf{y}}}\)</span>. The updated spherical random effects vector, <span class="math inline">\({\mathbf{u}}\)</span>, is the solution to <span class="math display">\[
({\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}+{\mathbf{I}}){\mathbf{u}}={\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}\tilde{{\mathbf{y}}}
\]</span> and is evaluated using the Cholesky factor, <span class="math inline">\({\mathbf{L}}\)</span>, of <span class="math inline">\({\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}+{\mathbf{I}}\)</span>.</p>
<p>As in the solution of the PLS problem in <a href="linalg.html#sec-lmmtheory"><span>Section&nbsp;B.7</span></a>, the fact that <span class="math inline">\({\mathbf{Z}}\)</span> is sparse and that the sparsity is also present in <span class="math inline">\({\mathbf{L}}\)</span>, makes it feasible to solve for <span class="math inline">\({\mathbf{u}}\)</span> even when its dimension is large.</p>
<section id="pirls-for-com05" class="level3" data-number="C.4.1">
<h3 data-number="C.4.1" class="anchored" data-anchor-id="pirls-for-com05"><span class="header-section-number">C.4.1</span> PIRLS for com05</h3>
<p>To illustrate the calculations we again use the <code>com05</code> model, which has a single, scalar random-effects term, <code>(1 | dist &amp; urban)</code>, in its formula. The matrix <span class="math inline">\({\mathbf{Z}}\)</span> is displayed as</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>com05re <span class="op">=</span> <span class="fu">only</span>(com05.reterms)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Int</span>.(<span class="fu">collect</span>(com05re))  <span class="co"># Int values for compact printing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>1934×102 Matrix{Int64}:
 1  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0
 ⋮              ⋮              ⋮        ⋱  ⋮              ⋮              ⋮  
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1
 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1</code></pre>
</div>
</div>
<p>but internally it is stored much more compactly because it is an <em>indicator matrix</em> (also called <em>one-hot</em> encoding), which means that all <span class="math inline">\(Z_{i,j}\in\{0,1\}\)</span> and in each row there is exactly one value that is one (and all the others are zero). The column in which the non-zero element of each row occurs is given as an integer vector in the <code>refs</code> property of <code>com05re</code>.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>com05re.refs<span class="op">'</span>      <span class="co"># transpose for compact printing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>1×1934 adjoint(::Vector{Int32}) with eltype Int32:
 1  1  1  1  1  1  1  1  1  1  1  1  1  …  102  102  102  102  102  102  102</code></pre>
</div>
</div>
<p>We define a struct</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">struct</span> BernoulliPIRLS{T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>,S<span class="op">&lt;:</span><span class="dt">Integer</span>}</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  θβ<span class="op">::</span><span class="dt">Vector{T}</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  ytbl<span class="op">::</span><span class="dt">NamedTuple{                     # column-table</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="dt">    (:refs, :y, :η, :offset),</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="dt">    Tuple{Vector{S},Vector{T},Vector{T},Vector{T}},</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="dt">  }</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  utbl<span class="op">::</span><span class="dt">NamedTuple{                     # column-table</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="dt">    (:u, :u0, :Ldiag, :pdev, :pdev0, :aGHQ),</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="dt">    NTuple{6,Vector{T}},</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="dt">  }</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>  rtbl<span class="op">::</span><span class="dt">Vector{                         # row-table</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="dt">    NamedTuple{(:μ, :dev, :rtwwt, :wwres, :wwresp),NTuple{5,T}},</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="dt">  }</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>with an external constructor</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">BernoulliPIRLS</span>(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  X<span class="op">::</span><span class="dt">Matrix{T}</span>,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  y<span class="op">::</span><span class="dt">Vector{T}</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  refs<span class="op">::</span><span class="dt">Vector{S}</span>,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>) <span class="kw">where</span> {T<span class="op">&lt;:</span><span class="dt">AbstractFloat</span>,S<span class="op">&lt;:</span><span class="dt">Integer</span>}</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># use IRLS to check X and y, obtain initial β, and establish rtbl</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>  irls <span class="op">=</span> <span class="fu">fit!</span>(<span class="fu">BernoulliIRLS</span>(X, y); verbose<span class="op">=</span><span class="cn">false</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>  β <span class="op">=</span> irls.β</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>  θβ <span class="op">=</span> <span class="fu">append!</span>(<span class="fu">ones</span>(T, <span class="fl">1</span>), β)       <span class="co"># initial θ = 1</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>  η <span class="op">=</span> X <span class="op">*</span> β</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># refs should contain all values from 1 to maximum(refs)</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>  refvals <span class="op">=</span> <span class="fu">sort!</span>(<span class="fu">unique</span>(refs))</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>  q <span class="op">=</span> <span class="fu">length</span>(refvals)</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> refvals <span class="op">≠</span> <span class="fl">1</span><span class="op">:</span>q</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"sort!(unique(refs)) must be 1:</span><span class="sc">$</span>q<span class="st">"</span>))</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">length</span>(refs) <span class="op">==</span> <span class="fu">length</span>(y) <span class="op">||</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"lengths of y and refs aren't equal"</span>))</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>  ytbl <span class="op">=</span> (; refs, y, η, offset<span class="op">=</span><span class="fu">copy</span>(η))</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>  utbl <span class="op">=</span> <span class="fu">NamedTuple</span>(</span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>    nm <span class="op">=&gt;</span> <span class="fu">zeros</span>(T, q) <span class="cf">for</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>    nm <span class="kw">in</span> (<span class="op">:</span>u, <span class="op">:</span>u0, <span class="op">:</span>Ldiag, <span class="op">:</span>pdev, <span class="op">:</span>pdev0, <span class="op">:</span>aGHQ)</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">updatetbl!</span>(<span class="fu">BernoulliPIRLS</span>(X, θβ, ytbl, utbl, irls.rtbl))</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why are θ and β stored in a single vector?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The reason for storing both <span class="math inline">\({\boldsymbol{\theta}}\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span> in a single vector is to provide for their simultaneous optimization with an optimizer such as those in <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a>.</p>
</div>
</div>
</div>
<p>The <code>utbl</code> field in a <code>BernoulliPIRLS</code> struct contains vectors named <code>u0</code>, <code>pdev</code>, <code>pdev0</code>, and <code>aGHQ</code>, in addition to <code>u</code> and <code>Ldiag</code>. These are not used in the PIRLS algorithm (other than for keeping a copy of the previous <span class="math inline">\({\mathbf{u}}\)</span>) or for optimizing Laplace’s approximation to the objective. However, they will be used in adaptive Gauss-Hermite quadrature evaluation of the objective (<a href="#sec-aGHQ"><span>Section&nbsp;C.6</span></a>), so we keep them in the struct throughout.</p>
<p>The <code>updatetbl!</code> method for this type first evaluates <span class="math inline">\({\boldsymbol{\eta}}\)</span> via a “virtual” multiplication that forms <span class="math inline">\({\mathbf{Z}}{\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}{\mathbf{u}}\)</span> plus the stored <code>offset</code>, which is <span class="math inline">\({\mathbf{X}}{\boldsymbol{\beta}}\)</span>, then updates the rowtable from <span class="math inline">\({\mathbf{y}}\)</span>, <span class="math inline">\({\boldsymbol{\eta}}\)</span>, and the offset. For this model <span class="math inline">\({\boldsymbol{\theta}}\)</span> is one-dimensional and <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}\)</span> is a scalar multiple of <span class="math inline">\({\mathbf{I}}_q\)</span>, the identity matrix of size <span class="math inline">\(q\)</span>, and thus the matrix multiplication by <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}\)</span> can be expressed as scalar products.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">updatetbl!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  (; refs, y, η, offset) <span class="op">=</span> m.ytbl</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  u <span class="op">=</span> m.utbl.u</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  θ <span class="op">=</span> <span class="fu">first</span>(m.θβ)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># evaluate η = offset + ZΛu where Λ is θ * I and Z is one-hot</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fill!</span>(η, <span class="fl">0</span>)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@inbounds</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="fu">eachindex</span>(η, refs, offset)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    η[i] <span class="op">+=</span> offset[i] <span class="op">+</span> u[refs[i]] <span class="op">*</span> θ</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>  m.rtbl <span class="op">.=</span> <span class="fu">tblrow</span>.(y, η, offset)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>pdeviance</code> method returns the deviance for the GLM model plus the penalty on the squared length of <code>u</code>.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">pdeviance</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">sum</span>(r.dev <span class="cf">for</span> r <span class="kw">in</span> m.rtbl) <span class="op">+</span> <span class="fu">sum</span>(abs2, m.utbl.u)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>updateu!</code> method is similar to <code>updateβ!</code> for the <code>BernoulliIRLS</code> type except that it is based on the diagonal matrix <span class="math inline">\({\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}+ {\mathbf{I}}\)</span>. Only the diagonal elements of this matrix are constructed and used to solve for the updated <span class="math inline">\({\mathbf{u}}\)</span> vector. At convergence of the PIRLS algorithm the elements of <code>Ldiag</code> are replaced by their square roots.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">updateu!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  (; u, u0, Ldiag) <span class="op">=</span> m.utbl</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(u0, u)              <span class="co"># keep a copy of u</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  θ <span class="op">=</span> <span class="fu">first</span>(m.θβ)             <span class="co"># extract the scalar θ</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fill!</span>(u, <span class="fl">0</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="fu">iszero</span>(θ)                <span class="co"># skip the update if θ == 0</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fill!</span>(Ldiag, <span class="fl">1</span>)           <span class="co"># L is the identity if θ == 0</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">updatetbl!</span>(m)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fill!</span>(Ldiag, <span class="fl">0</span>)</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@inbounds</span> <span class="cf">for</span> (ri, ti) <span class="kw">in</span> <span class="fu">zip</span>(m.ytbl.refs, m.rtbl)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    rtWΛ <span class="op">=</span> θ <span class="op">*</span> ti.rtwwt       <span class="co"># non-zero in i'th row of √WZΛ</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    Ldiag[ri] <span class="op">+=</span> <span class="fu">abs2</span>(rtWΛ)   <span class="co"># accumulate Λ'Z'WZΛ</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    u[ri] <span class="op">+=</span> rtWΛ <span class="op">*</span> ti.wwresp <span class="co"># accumulate Λ'Z'Wỹ</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>  Ldiag <span class="op">.+=</span> <span class="fl">1</span>                 <span class="co"># form diagonal of Λ'Z'WZΛ + I = LL'</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>  u <span class="op">./=</span> Ldiag                 <span class="co"># solve for u with diagonal LL'</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">updatetbl!</span>(m)        <span class="co"># and update η and rtbl</span></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a <code>BernoulliPIRLS</code> struct for the <code>com05</code> model and check the penalized deviance at the initial values</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="fu">BernoulliPIRLS</span>(com05.X, com05.y, <span class="fu">only</span>(com05.reterms).refs)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pdeviance</span>(m)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>2409.3774281600413</code></pre>
</div>
</div>
<p>As with IRLS, the first iteration of PIRLS reduces the objective, which is the penalized deviance in this case, substantially.</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pdeviance</span>(<span class="fu">updateu!</span>(m))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>2233.120947635784</code></pre>
</div>
</div>
<p>Create a <code>pirls!</code> method for this struct.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">pirls!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>; verbose<span class="op">::</span><span class="dt">Bool</span>=<span class="cn">false</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>  (; u, u0, Ldiag) <span class="op">=</span> m.utbl</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fill!</span>(u, <span class="fl">0</span>)                  <span class="co"># start from u == 0</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(u0, u)               <span class="co"># keep a copy of u</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>  oldpdev <span class="op">=</span> <span class="fu">pdeviance</span>(<span class="fu">updatetbl!</span>(m))</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>  verbose <span class="op">&amp;&amp;</span> <span class="pp">@info</span> <span class="fl">0</span>, oldpdev</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span>                <span class="co"># maximum of 10 PIRLS iterations</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>    newpdev <span class="op">=</span> <span class="fu">pdeviance</span>(<span class="fu">updateu!</span>(m))</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">&amp;&amp;</span> <span class="pp">@info</span> i, newpdev</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> newpdev <span class="op">&gt;</span> oldpdev       <span class="co"># PIRLS iteration failed</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>      <span class="pp">@warn</span> <span class="st">"PIRLS iteration did not reduce penalized deviance"</span></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">copyto!</span>(u, u0)           <span class="co"># restore previous u</span></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">updatetbl!</span>(m)            <span class="co"># restore η and rtbl</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elseif</span> (oldpdev <span class="op">-</span> newpdev) <span class="op">&lt;</span> (<span class="fl">1.0e-8</span> <span class="op">*</span> oldpdev)</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">copyto!</span>(u0, u)           <span class="co"># keep a copy of u</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">copyto!</span>(u0, u)           <span class="co"># keep a copy of u</span></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>      oldpdev <span class="op">=</span> newpdev</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map!</span>(sqrt, Ldiag, Ldiag)     <span class="co"># replace diag(LL') by diag(L)</span></span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The PIRLS iterations always start from <span class="math inline">\({\mathbf{u}}=\mathbf{0}\)</span> so that the converged value of the penalized deviance is reproducible for given values of <span class="math inline">\(\theta\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span>. If we allowed the algorithm to start at whatever values are currently stored in <span class="math inline">\({\mathbf{u}}\)</span> then there could be slight differences in the value of the penalized deviance at convergence of PIRLS, which can cause problems when trying to optimize with respect to <span class="math inline">\(\theta\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span>.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pirls!</span>(m; verbose<span class="op">=</span><span class="cn">true</span>);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: (0, 2409.3774281600413)
[ Info: (1, 2233.120947635784)
[ Info: (2, 2231.6059352797056)
[ Info: (3, 2231.600219832158)
[ Info: (4, 2231.6002194065604)</code></pre>
</div>
</div>
<p>As with IRLS, PIRLS is a fast and stable algorithm for determining the mode of the conditional distribution <span class="math inline">\(({\mathcal{U}}|{\mathcal{Y}}={\mathbf{y}})\)</span> with <span class="math inline">\({\boldsymbol{\theta}}\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span> held fixed.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="pp">@benchmark</span> <span class="fu">pirls!</span>(mm) seconds <span class="op">=</span> <span class="fl">1</span> setup <span class="op">=</span> (mm <span class="op">=</span> m)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<div class="ansi-escaped-output">
<pre>BenchmarkTools.Trial: 5312 samples with 1 evaluation.
 Range <span class="ansi-bright-black-fg">(</span><span class="ansi-cyan-fg ansi-bold">min</span> … <span class="ansi-magenta-fg">max</span><span class="ansi-bright-black-fg">):  </span><span class="ansi-cyan-fg ansi-bold">182.458 μs</span> … <span class="ansi-magenta-fg">212.500 μs</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>min … max<span class="ansi-bright-black-fg">): </span>0.00% … 0.00%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-blue-fg ansi-bold">median</span><span class="ansi-bright-black-fg">):     </span><span class="ansi-blue-fg ansi-bold">186.916 μs               </span><span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>median<span class="ansi-bright-black-fg">):    </span>0.00%
 Time  <span class="ansi-bright-black-fg">(</span><span class="ansi-green-fg ansi-bold">mean</span> ± <span class="ansi-green-fg">σ</span><span class="ansi-bright-black-fg">):   </span><span class="ansi-green-fg ansi-bold">186.895 μs</span> ± <span class="ansi-green-fg">  2.138 μs</span>  <span class="ansi-bright-black-fg">┊</span> GC <span class="ansi-bright-black-fg">(</span>mean ± σ<span class="ansi-bright-black-fg">):  </span>0.00% ± 0.00%
                          ▇█<span class="ansi-blue-fg">▇</span>▃                                   
  ▁▁▂▃▄▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▂▃▆██<span class="ansi-blue-fg">█</span>█▇▅▄▃▃▂▂▂▂▂▁▂▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂
  182 μs<span class="ansi-bright-black-fg">           Histogram: frequency by time</span>          193 μs <span class="ansi-bold">&lt;</span>
 Memory estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">112 bytes</span>, allocs estimate<span class="ansi-bright-black-fg">: </span><span class="ansi-yellow-fg">1</span>.</pre>
</div>
</div>
</div>
<p>The time taken for the four iterations to determine the conditional mode of <span class="math inline">\({\mathbf{u}}\)</span> is comparable to the time taken for a single call to <code>updateβ!</code>. Most of the time in <code>updateβ!</code> is spent in the QR factorization to solve the weighted least squares problem, whereas in <code>updateu!</code>and thus in <code>pirls!</code>, we take advantage of the fact that the solution of the penalized, weighted least squares problem is based on a diagonal matrix.</p>
</section>
</section>
<section id="sec-GLMMLaplace" class="level2" data-number="C.5">
<h2 data-number="C.5" class="anchored" data-anchor-id="sec-GLMMLaplace"><span class="header-section-number">C.5</span> Laplace’s approximation to the log-likelihood</h2>
<p>The PIRLS algorithm determines the value of <span class="math inline">\({\mathbf{u}}\)</span> that minimizes the penalized deviance <span class="math display">\[
\tilde{{\mathbf{u}}}=\arg\min_{{\mathbf{u}}}\left(\left\|{\mathbf{u}}\right\|^2+\sum_{i=1}^n d(y_i,\eta_i)\right) ,
\]</span> where <span class="math inline">\(\eta_i, i=1,\dots,n\)</span> is the <span class="math inline">\(i\)</span>th component of <span class="math inline">\({\boldsymbol{\eta}}={\mathbf{X}}{\boldsymbol{\beta}}+{\mathbf{Z}}{\boldsymbol{\Lambda}}{\mathbf{u}}\)</span>. A quadratic approximation to the penalized deviance at <span class="math inline">\(\tilde{{\mathbf{u}}}\)</span> is <span id="eq-pdevquad"><span class="math display">\[
\begin{aligned}
\tilde{d}({\mathbf{y}},{\mathbf{u}})&amp;=\|{\mathbf{u}}\|^2+\sum_{i=1}^n d(y_i,\eta_i)\\
&amp;\approx\|\tilde{{\mathbf{u}}}\|^2+\sum_{i=1}^n d(y_i,\tilde{\eta}_i)+
({\mathbf{u}}-\tilde{{\mathbf{u}}})'({\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}+{\mathbf{I}})({\mathbf{u}}-\tilde{{\mathbf{u}}})\\
&amp;=\|\tilde{{\mathbf{u}}}\|^2+\sum_{i=1}^n d(y_i,\tilde{\eta}_i)+
({\mathbf{u}}-\tilde{{\mathbf{u}}})'{\mathbf{L}}{\mathbf{L}}'({\mathbf{u}}-\tilde{{\mathbf{u}}})\\
&amp;=\tilde{d}({\mathbf{y}},\tilde{{\mathbf{u}}})+
({\mathbf{u}}-\tilde{{\mathbf{u}}})'{\mathbf{L}}{\mathbf{L}}'({\mathbf{u}}-\tilde{{\mathbf{u}}})
\end{aligned}
\tag{C.9}\]</span></span> where <span class="math inline">\({\mathbf{L}}\)</span> is the lower Cholesky factor of <span class="math inline">\({\boldsymbol{\Lambda}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}+{\mathbf{I}}\)</span>. (In <a href="#eq-pdevquad">Equation&nbsp;<span>C.9</span></a> the linear term in <span class="math inline">\(({\mathbf{u}}-\tilde{{\mathbf{u}}})\)</span> that would normally occur in such an expression is omitted because the gradient of <span class="math inline">\(\tilde{d}({\mathbf{y}},{\mathbf{u}})\)</span> is zero at <span class="math inline">\(\tilde{{\mathbf{u}}}\)</span>.)</p>
<p><a href="https://en.wikipedia.org/wiki/Laplace%27s_approximation">Laplace’s approximation</a> to the log-likelihood uses this quadratic approximation to the penalized deviance, which is negative one-half the logarithm of the integrand, to approximate the value of the integral.</p>
<p>On the deviance scale, which is negative twice the log-likelihood, the approximation is <span class="math display">\[
\begin{aligned}
-2\,\ell({\mathbf{u}}|{\mathbf{y}},{\boldsymbol{\theta}},{\boldsymbol{\beta}})&amp;=-2\,\log\left(L({\mathbf{u}}|{\mathbf{y}},{\boldsymbol{\theta}},{\boldsymbol{\beta}})\right)\\
&amp;=-2\,\log\left(\int_{{\mathbf{u}}}\frac{1}{\sqrt{2\pi}^q}\exp\left(\frac{\left\|{\mathbf{u}}\right\|^2+\sum_{i=1}^n d(y_i,\mu_i)}{-2}\right)\,d{\mathbf{u}}\right)\\
&amp;\approx\tilde{d}({\mathbf{y}},\tilde{{\mathbf{u}}})-2\,\log\left(
\int_{\mathbf{u}}\frac{1}{\sqrt{2\pi}^q}\exp\left(\frac{[{\mathbf{u}}-\tilde{{\mathbf{u}}}]'{\mathbf{L}}{\mathbf{L}}'[{\mathbf{u}}-\tilde{{\mathbf{u}}}]}{-2}\right)\,d{\mathbf{u}}
\right)\\
&amp;=\tilde{d}({\mathbf{y}},\tilde{{\mathbf{u}}})-2\,\log\left(
\int_{\mathbf{u}}\frac{1}{\sqrt{2\pi}^q}\exp\left(\frac{\left\|{\mathbf{L}}'[{\mathbf{u}}-\tilde{{\mathbf{u}}}\right\|^2}{-2}\right)\,d{\mathbf{u}}
\right)\\
&amp;=\tilde{d}({\mathbf{y}},\tilde{{\mathbf{u}}})-2\,\log\left(|{\mathbf{L}}|^{-1}\right)\\
&amp;=\tilde{d}({\mathbf{y}},\tilde{{\mathbf{u}}})+\log\left(|{\mathbf{L}}|^2\right)
\end{aligned}
\]</span></p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">laplaceapprox</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">pdeviance</span>(m) <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu">sum</span>(log, m.utbl.Ldiag)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">laplaceapprox</span>(<span class="fu">pirls!</span>(m))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>2373.5180527521634</code></pre>
</div>
</div>
<p>The remaining step is to optimize Laplace’s approximation to the GLMM deviance with respect to <span class="math inline">\(\theta\)</span> and <span class="math inline">\({\boldsymbol{\beta}}\)</span>, which we do using the BOBYQA optimizer from <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a></p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> StatsAPI.<span class="fu">fit!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  θβ <span class="op">=</span> m.θβ</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  pp1 <span class="op">=</span> <span class="fu">length</span>(θβ)                <span class="co"># length(β) = p and length(θ) = 1</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>  opt <span class="op">=</span> <span class="fu">Opt</span>(<span class="op">:</span>LN_BOBYQA, pp1)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>  mβ <span class="op">=</span> <span class="fu">view</span>(θβ, <span class="fl">2</span><span class="op">:</span>pp1)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">obj</span>(x, g)</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> !<span class="fu">isempty</span>(g)</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"gradient not provided, g must be empty"</span>))</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">copyto!</span>(θβ, x)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mul!</span>(m.ytbl.offset, m.X, mβ)</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">laplaceapprox</span>(<span class="fu">pirls!</span>(m))</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end</span></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>  opt.min_objective <span class="op">=</span> obj</span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>  lb <span class="op">=</span> <span class="fu">fill!</span>(<span class="fu">similar</span>(θβ), <span class="op">-</span><span class="cn">Inf</span>)   <span class="co"># vector of lower bounds</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>  lb[<span class="fl">1</span>] <span class="op">=</span> <span class="fl">0</span>                       <span class="co"># scalar θ must be non-negative</span></span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>  NLopt.<span class="fu">lower_bounds!</span>(opt, lb)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>  minf, minx, ret <span class="op">=</span> <span class="fu">optimize</span>(opt, <span class="fu">copy</span>(θβ))</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@info</span> (; ret, fevals<span class="op">=</span>opt.numevals, minf)</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit!</span>(m);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: (ret = :ROUNDOFF_LIMITED, fevals = 567, minf = 2354.474481568814)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Converged to θ = "</span>, <span class="fu">first</span>(m.θβ), <span class="st">" and β ="</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(<span class="fu">view</span>(m.θβ, <span class="fl">2</span><span class="op">:</span><span class="fu">lastindex</span>(m.θβ)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Converged to θ = 0.5683043987329829 and β =
[-0.340978, 0.39338, 0.606486, -0.0129262, 0.0332348, -0.00562619]</code></pre>
</div>
</div>
<p>These estimates differ somewhat from those for model <code>com05</code>.</p>
<div class="cell" data-execution_count="47">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Estimates for com05: θ = "</span>,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">only</span>(com05.θ),</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">", fmin = "</span>,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">deviance</span>(com05),</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">", and β ="</span>,</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(com05.β)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Estimates for com05: θ = 0.576131809145932, fmin = 2353.8241975678648, and β =
[-0.341475, 0.393592, 0.606449, -0.0129098, 0.0332106, -0.00562463]</code></pre>
</div>
</div>
<p>The discrepancy in the results is because the <code>com05</code> results are based on a more accurate approximation to the integral called <em>adaptive Gauss-Hermite Quadrature</em>, which is discussed in <a href="#sec-aGHQ"><span>Section&nbsp;C.6</span></a>.</p>
<section id="generalizations-to-more-complex-structure" class="level3" data-number="C.5.1">
<h3 data-number="C.5.1" class="anchored" data-anchor-id="generalizations-to-more-complex-structure"><span class="header-section-number">C.5.1</span> Generalizations to more complex structure</h3>
<p>There is an implicit assumption in the <code>BernoulliPIRLS</code> structure that random effects in the model are simple, scalar random effects associated with a single grouping factor, which is represented by <code>m.ytbl.refs</code>. For such models the random effects model matrix, <span class="math inline">\({\mathbf{Z}}\)</span>, is an <span class="math inline">\(n\times q\)</span> indicator matrix, the covariance parameter, <span class="math inline">\({\boldsymbol{\theta}}\)</span>, is one-dimensional and the covariance factor, <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}=\theta\,{\mathbf{I}}_q\)</span> is a scalar multiple of the <span class="math inline">\(q\times q\)</span> identity matrix, <span class="math inline">\({\mathbf{I}}_q\)</span>. Furthermore, <span class="math inline">\({\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}'{\mathbf{Z}}'{\mathbf{W}}{\mathbf{Z}}{\boldsymbol{\Lambda}}_{{\boldsymbol{\theta}}}+{\mathbf{I}}_q\)</span> is also diagonal, as is its Cholesky factor, <span class="math inline">\({\mathbf{L}}\)</span>.</p>
<p>We have taken advantage of the special structure of these matrices both in representations — storing <span class="math inline">\({\mathbf{L}}\)</span> by storing only the diagonal values in the vector <code>m.utbl.Ldiag</code> — and in some algorithms for the PIRLS iterative step.</p>
<p>The PIRLS algorithm to determine the conditional mode, <span class="math inline">\(\tilde{{\mathbf{u}}}\)</span>, of the random effects, <span class="math inline">\({\mathcal{U}}\)</span>, and Laplace’s approximation to the log-likelihood for GLMMs can be generalized to models with vector-valued random effects, or with random effects associated with more than one grouping factor, or with both. The more general representation of <span class="math inline">\({\mathbf{Z}}\)</span> and <span class="math inline">\({\mathbf{L}}\)</span> used with linear mixed models can be adapted for GLMMs as well.</p>
<p>We chose to specialize the representation of GLMMs in this appendix to this specific type of random effects to be able to demonstrate adaptive Gauss-Hermite quadrature in <a href="#sec-aGHQ"><span>Section&nbsp;C.6</span></a>, which, at present, is restricted to models with a single, simple, scalar, random effects term.</p>
</section>
</section>
<section id="sec-aGHQ" class="level2" data-number="C.6">
<h2 data-number="C.6" class="anchored" data-anchor-id="sec-aGHQ"><span class="header-section-number">C.6</span> Adaptive Gauss-Hermite quadrature</h2>
<p>Recall from <a href="#eq-pdevquad">Equation&nbsp;<span>C.9</span></a> that Laplace’s approximation to the likelihood is based on a quadratic approximation to the penalized (GLM) deviance, <span class="math inline">\(\tilde{d}({\mathbf{y}},{\mathbf{u}})\)</span>, at the conditional mode <span class="math inline">\(\tilde{{\mathbf{u}}}\)</span>. In the case of a model with a single, scalar, random effects term, like the model <code>com05</code>, each linear predictor value, <span class="math inline">\(\eta_i,\,i=1,\dots,n\)</span> depends on only one element of <span class="math inline">\({\mathbf{u}}\)</span>. Writing the set of indices <span class="math inline">\(i\)</span> for which <code>refs[i] == j</code> as <span class="math inline">\({\mathcal{I}}(j)\)</span>, we can express the penalized deviance, and its quadratic approximation, as sums of scalar contributions, <span class="math display">\[
\begin{aligned}
\tilde{d}({\mathbf{y}},{\mathbf{u}})&amp;=\|{\mathbf{u}}\|^2+\sum_{i=1}^n d(y_i,\mu_i)\\
&amp;=\sum_{j=1}^q\left(u_j^2+\sum_{i\in{\mathcal{I}}(j)}d(y_i,\mu_i)\right)\\
&amp;\approx\sum_{j=1}^q \left(\tilde{u}_j^2+\sum_{i\in{\mathcal{I}}(j)}\left(d(y_i,\tilde{\mu}_i)+\ell_j^2(u_j-\tilde{u}_j)^2\right)\right)
\end{aligned}
\]</span> where <span class="math inline">\(\ell_j\)</span> is the <span class="math inline">\(j\)</span>th diagonal element of <span class="math inline">\({\mathbf{L}}\)</span> and <span class="math inline">\(\tilde{\mu}_i\)</span> is the value of <span class="math inline">\(\mu_i\)</span> when <span class="math inline">\(u_j=\tilde{u}_j\)</span>.</p>
<p>Extending the notation of <a href="#eq-pdevquad">Equation&nbsp;<span>C.9</span></a> we write the contribution from <span class="math inline">\(u_j\)</span> to the penalized (GLM) deviance, and to its quadratic approximation, as <span class="math display">\[
\begin{aligned}
\tilde{d}_j(u_j)&amp;= u_j+\sum_{i\in{\mathcal{I}}(j)}d(y_i,\mu_i)\\
&amp;\approx \tilde{u_j} + \sum_{i\in{\mathcal{I}}(j)}\left(d(y_i,\tilde{\mu}_i)+\ell_j^2(u_j-\tilde{u}_j)\right)\\
&amp;=\tilde{d}_j(\tilde{u}_j)+\ell_j^2(u_j-\tilde{u}_j)\quad j=1,\dots,q ,
\end{aligned}
\]</span> giving Laplace’s approximation to the scalar integral defining the contribution of <span class="math inline">\(u_j\)</span> to negative twice the log-likelihood as <span id="eq-scalarlaplace"><span class="math display">\[
\begin{aligned}
-2\log\int_{u_j}\frac{e^{-\tilde{d}_j(u_j)/2}}{\sqrt{2\pi}}\,du_j&amp;\approx
-2\log\int_{u_j}\frac{e^{\left((-\tilde{d}_j(\tilde{u_j})-\ell_j^2(u_j-\tilde{u}_j)^2)/2\right)}}{\sqrt{2\pi}}\,du_j\\
&amp;=\tilde{d}_j(\tilde{u}_j)-2\log\int_{u_j}\frac{e^{-\ell_j^2(u_j-\tilde{u}_j)/2}}{\sqrt{2\pi}}\,du_j\\
&amp;=\tilde{d}_j(\tilde{u}_j)-2\log\int_{z_j}\frac{e^{-z_j^2/2}}{\sqrt{2\pi}}\,\frac{dz_j}{\ell_j}\\
&amp;=\tilde{d}_j(\tilde{u}_j)+2\log(\ell_j)-2\log\int_{z_j}\frac{e^{-z_j^2/2}}{\sqrt{2\pi}}\,dz_j\\
&amp;=\tilde{d}_j(\tilde{u}_j)+2\log(\ell_j)-2\log(1)\\
&amp;=\tilde{d}_j(\tilde{u}_j)+2\log(\ell_j)
\end{aligned}
\tag{C.10}\]</span></span> using the change of variable <span id="eq-ujtozj"><span class="math display">\[
z_j=\ell_j(u_j-\tilde{u}_j)\quad j=1,\dots,q
\tag{C.11}\]</span></span> with inverse <span id="eq-zjtouj"><span class="math display">\[
u_j=\frac{z_j}{\ell_j}+\tilde{u}_j\quad j=1,\dots,q
\tag{C.12}\]</span></span> and derivative <span class="math display">\[
\frac{du_j}{dz_j}=\frac{1}{\ell_j} .
\]</span></p>
<p>The change of variable <a href="#eq-ujtozj">Equation&nbsp;<span>C.11</span></a> allows us to express the contribution from <span class="math inline">\(u_j\)</span> to Laplace’s approximation as a constant, <span class="math inline">\(\tilde{d}_j(\tilde{u}_j)\)</span>, plus the integral of a multiple, <span class="math inline">\(1/\ell_j\)</span>, of the density of a standard normal distribution <span class="math display">\[
\phi(z)=\frac{e^{-z^2/2}}{\sqrt{2\pi}} .
\]</span></p>
<p>The <span class="math inline">\(K\)</span>th-order normalized Gauss-Hermite quadrature rule allows us to extend this approach to evaluate integrals of the form <span id="eq-normalizedGaussHermite"><span class="math display">\[
\int_z f(z)\frac{e^{-z^2/2}}{\sqrt{2\pi}}\, dz \approx \sum_{k=1}^K w_k f(z_k)
\tag{C.13}\]</span></span> where the weights, <span class="math inline">\(w_k,\,k=1,\dots,K\)</span>, and the absiccae, <span class="math inline">\(z_k,\,k=1,\dots,K\)</span> are evaluated as described in <a href="#sec-NGHQ"><span>Section&nbsp;C.6.1</span></a>. The approximation <a href="#eq-normalizedGaussHermite">Equation&nbsp;<span>C.13</span></a> is exact when <span class="math inline">\(f(z)\)</span> is a polynomial of order <span class="math inline">\(2K-1\)</span> or less.</p>
<p>We will apply a rule like <a href="#eq-normalizedGaussHermite">Equation&nbsp;<span>C.13</span></a> where <span class="math inline">\(f\)</span> is the exponential of negative half the difference between the penalized deviance, <span class="math inline">\(\tilde{d}_j(z_j/\ell_j+\tilde{u}_j)\)</span>, and its quadratic approximation at the conditional mode, <span class="math inline">\(\tilde{u}_j\)</span>. That is, we will center the standard normal density at the conditional mode, <span class="math inline">\(\tilde{u}_j,\,j=1,\dots,q\)</span>, and scale it by the inverse of the quadratic term, <span class="math inline">\(\ell_j,\,j=1,\dots,q\)</span>, in the quadratic approximation at that value of <span class="math inline">\(u\)</span>. This is said to be an <em>adaptive</em> quadrature rule because we are shifting and scaling the evaluation points according to the current conditions in the iterative algorithm.</p>
<p>In other words we will first apply PIRLS to determine the conditional modes and the quadratic terms, then use a normalized Gauss-Hermite quadrature rule.</p>
<section id="sec-NGHQ" class="level3" data-number="C.6.1">
<h3 data-number="C.6.1" class="anchored" data-anchor-id="sec-NGHQ"><span class="header-section-number">C.6.1</span> Normalized Gauss-Hermite quadrature rules</h3>
<p><a href="https://en.wikipedia.org/wiki/Gaussian_quadrature"><em>Gaussian Quadrature rules</em></a> provide sets of <code>x</code> values, called <em>abscissae</em>, and corresponding weights, <code>w</code>, to approximate an integral with respect to a <em>weight function</em>, <span class="math inline">\(g(x)\)</span>. For a <span class="math inline">\(K\)</span>th order rule the approximation is <span class="math display">\[
\int f(x)g(x)\,dx \approx \sum_{k=1}^K w_k f(x_k)
\]</span></p>
<p>For the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Hermite_quadrature">Gauss-Hermite</a> rule the weight function is <span class="math display">\[
g(x) = e^{-x^2}
\]</span> and the domain of integration is <span class="math inline">\((-\infty, \infty)\)</span>. A slight variation of this is the <em>normalized Gauss-Hermite</em> rule for which the weight function is the standard normal density <span class="math display">\[
g(z) = \phi(z) = \frac{e^{-z^2/2}}{\sqrt{2\pi}} .
\]</span></p>
<p>Thus, the expected value of <span class="math inline">\(f(z)\)</span>, where <span class="math inline">\(\mathcal{Z}\sim\mathscr{N}(0,1)\)</span>, is approximated as <span class="math display">\[
\mathbb{E}[f]=\int_{-\infty}^{\infty} f(z) \phi(z)\,dz\approx\sum_{k=1}^K w_k\,f(z_k) .
\]</span></p>
<p>Naturally, there is a caveat. For the approximation to be accurate the function <span class="math inline">\(f(z)\)</span> must behave like a low-order polynomial over the range of interest. More formally, a <span class="math inline">\(K\)</span>th order rule is exact when <span class="math inline">\(f\)</span> is a polynomial of order <span class="math inline">\(2K-1\)</span> or less.</p>
<section id="evaluating-the-weights-and-abscissae" class="level4" data-number="C.6.1.1">
<h4 data-number="C.6.1.1" class="anchored" data-anchor-id="evaluating-the-weights-and-abscissae"><span class="header-section-number">C.6.1.1</span> Evaluating the weights and abscissae</h4>
<p>In the <a href="https://en.wikipedia.org/wiki/Gaussian_quadrature#The_Golub-Welsch_algorithm"><em>Golub-Welsch algorithm</em></a> the abscissae for a particular Gaussian quadrature rule are determined as the eigenvalues of a symmetric tri-diagonal matrix and the weights are derived from the squares of the first row of the matrix of eigenvectors. For a <span class="math inline">\(K\)</span>th order normalized Gauss-Hermite rule the tridiagonal matrix has zeros on the diagonal and the square roots of <code>1:k-1</code> on the super- and sub-diagonal, e.g.</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>sym5 <span class="op">=</span> <span class="fu">SymTridiagonal</span>(<span class="fu">zeros</span>(<span class="fl">5</span>), <span class="fu">sqrt</span>.(<span class="fl">1</span><span class="op">:</span><span class="fl">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>5×5 SymTridiagonal{Float64, Vector{Float64}}:
 0.0  1.0       ⋅        ⋅        ⋅ 
 1.0  0.0      1.41421   ⋅        ⋅ 
  ⋅   1.41421  0.0      1.73205   ⋅ 
  ⋅    ⋅       1.73205  0.0      2.0
  ⋅    ⋅        ⋅       2.0      0.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>ev <span class="op">=</span> <span class="fu">eigen</span>(sym5);</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(ev.values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-2.85697, -1.35563, 8.88178e-16, 1.35563, 2.85697]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(<span class="fu">abs2</span>.(ev.vectors[<span class="fl">1</span>, <span class="op">:</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.0112574, 0.222076, 0.533333, 0.222076, 0.0112574]</code></pre>
</div>
</div>
<p>A function of <code>k</code> to evaluate the abscissae and weights is</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">gausshermitenorm</span>(k)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>  ev <span class="op">=</span> <span class="fu">eigen</span>(<span class="fu">SymTridiagonal</span>(<span class="fu">zeros</span>(k), <span class="fu">sqrt</span>.(<span class="fl">1</span><span class="op">:</span>(k <span class="op">-</span> <span class="fl">1</span>))))</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">Table</span>((;</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    abscissae<span class="op">=</span>ev.values,</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span><span class="fu">abs2</span>.(ev.vectors[<span class="fl">1</span>, <span class="op">:</span>]),</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>providing</p>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gausshermitenorm</span>(<span class="fl">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>Table with 2 columns and 5 rows:
     abscissae    weights
   ┌───────────────────────
 1 │ -2.85697     0.0112574
 2 │ -1.35563     0.222076
 3 │ 8.88178e-16  0.533333
 4 │ 1.35563      0.222076
 5 │ 2.85697      0.0112574</code></pre>
</div>
</div>
<p>The weights and positions for the 9th order rule are shown in <a href="#fig-ghnine">Figure&nbsp;<span>C.1</span></a>.</p>
<div class="cell" data-execution_count="53">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">draw</span>(</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data</span>(<span class="fu">gausshermitenorm</span>(<span class="fl">9</span>)) <span class="op">*</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapping</span>(<span class="op">:</span>abscissae <span class="op">=&gt;</span> <span class="st">"Positions"</span>, <span class="op">:</span>weights),</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="54">
<div id="fig-ghnine" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-ghnine-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.1: Weights and positions for the 9th order normalized Gauss-Hermite quadrature rule</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice that the magnitudes of the weights drop quite dramatically away from zero, even on a logarithmic scale (<a href="#fig-ghninelog">Figure&nbsp;<span>C.2</span></a>)</p>
<div class="cell" data-execution_count="54">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">draw</span>(</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data</span>(<span class="fu">gausshermitenorm</span>(<span class="fl">9</span>)) <span class="op">*</span> <span class="fu">mapping</span>(</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">:</span>abscissae <span class="op">=&gt;</span> <span class="st">"Positions"</span>,</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">:</span>weights <span class="op">=&gt;</span> log2 <span class="op">=&gt;</span> <span class="st">"log₂(weight)"</span>,</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="55">
<div id="fig-ghninelog" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-ghninelog-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.2: Weights (logarithm base 2) and positions for the 9th order normalized Gauss-Hermite quadrature rule</figcaption>
</figure>
</div>
</div>
</div>
<p>The definition of <code>MixedModels.GHnorm</code> is similar to the <code>gausshermitenorm</code> function with some extra provisions for ensuring symmetry of the abscissae and of the weights and for caching values once they have been calculated.</p>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> tbl <span class="op">=</span> <span class="fu">GHnorm</span>(<span class="fl">9</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Table</span>(abscissae<span class="op">=</span>tbl.z, weights<span class="op">=</span>tbl.w)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>Table with 2 columns and 9 rows:
     abscissae  weights
   ┌──────────────────────
 1 │ -4.51275   2.23458e-5
 2 │ -3.20543   0.00278914
 3 │ -2.07685   0.0499164
 4 │ -1.02326   0.244098
 5 │ 0.0        0.406349
 6 │ 1.02326    0.244098
 7 │ 2.07685    0.0499164
 8 │ 3.20543    0.00278914
 9 │ 4.51275    2.23458e-5</code></pre>
</div>
</div>
<p>In particular, when <span class="math inline">\(K\)</span> is odd the middle abscissa, at index <span class="math inline">\((K+1)/2\)</span>, is exactly zero.</p>
<p>As an example of evaluation using these weights and abscissae, we consider <span class="math display">\[
\mathbb{E}[g(x)] \approx \sum_{i=1}^k g(\mu + \sigma z_i)\,w_i
\]</span> where <span class="math inline">\(\mathcal{X}\sim\mathscr{N}(\mu, \sigma^2)\)</span>.</p>
<p>For example, <span class="math inline">\(\mathbb{E}[\mathcal{X}^2]\)</span> where <span class="math inline">\(\mathcal{X}\sim\mathcal{N}(2, 3^2)\)</span> is</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> μ <span class="op">=</span> <span class="fl">2</span>, σ <span class="op">=</span> <span class="fl">3</span>, ghn3 <span class="op">=</span> <span class="fu">GHnorm</span>(<span class="fl">3</span>)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(@. ghn3.w <span class="op">*</span> <span class="fu">abs2</span>(μ <span class="op">+</span> σ <span class="op">*</span> ghn3.z))  <span class="co"># should be μ² + σ² = 13</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>13.0</code></pre>
</div>
</div>
<p>(In general a dot, ‘<code>.</code>’, after the function name in a function call, as in <code>abs2.(...)</code>, or before an operator creates a <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#More-dots:-Fuse-vectorized-operations"><em>fused vectorized</em></a> evaluation in Julia. The macro <code>@.</code> has the effect of vectorizing all operations in the subsequent expression.)</p>
</section>
</section>
<section id="illustration-of-contributions-to-the-objective" class="level3" data-number="C.6.2">
<h3 data-number="C.6.2" class="anchored" data-anchor-id="illustration-of-contributions-to-the-objective"><span class="header-section-number">C.6.2</span> Illustration of contributions to the objective</h3>
<p>We have provided a <code>pdev</code> vector in the <code>utbl</code> field of a <code>BernoulliPIRLS</code> object to allow for accumulation of the penalized deviance contributions for each component of <span class="math inline">\({\mathbf{u}}\)</span> in the model.</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">pdevcomps!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>  (; u, pdev) <span class="op">=</span> m.utbl</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>  pdev <span class="op">.=</span> <span class="fu">abs2</span>.(u)        <span class="co"># initialize pdevj to square of uj</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@inbounds</span> <span class="cf">for</span> (ri, ti) <span class="kw">in</span> <span class="fu">zip</span>(m.ytbl.refs, m.rtbl)</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    pdev[ri] <span class="op">+=</span> ti.dev</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After PIRLS has converged, we evaluate <code>pdevcomps!</code> and copy the <code>pdev</code> column of the <code>utbl</code> field to its <code>pdev0</code> column, which will be the baseline evaluation of the penalized deviance at the conditional modes. Other evaluations of the penalized deviance components are plotted as differences from <code>pdev0</code>.</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pdevcomps!</span>(<span class="fu">pirls!</span>(m))</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">copyto!</span>(m.utbl.pdev0, m.utbl.pdev)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="fu">Table</span>(m.utbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>Table with 6 columns and 102 rows:
      u           u0          Ldiag    pdev     pdev0    aGHQ
    ┌────────────────────────────────────────────────────────
 1  │ -1.02425    -1.02425    2.3596   78.2322  78.2322  0.0
 2  │ -1.6554     -1.6554     1.87894  41.917   41.917   0.0
 3  │ -0.0432084  -0.0432084  1.54253  21.8681  21.8681  0.0
 4  │ 0.500796    0.500796    1.07154  2.68642  2.68642  0.0
 5  │ 1.10928     1.10928     1.29471  8.58305  8.58305  0.0
 6  │ -0.415844   -0.415844   1.49343  18.6901  18.6901  0.0
 7  │ 0.0305151   0.0305151   1.06624  1.46897  1.46897  0.0
 8  │ 0.216409    0.216409    1.87125  46.1746  46.1746  0.0
 9  │ 0.433361    0.433361    1.2297   9.7717   9.7717   0.0
 10 │ -0.648279   -0.648279   2.10967  58.417   58.417   0.0
 11 │ -0.328134   -0.328134   1.47521  23.5301  23.5301  0.0
 12 │ 0.499976    0.499976    1.06882  2.74129  2.74129  0.0
 13 │ 0.139717    0.139717    1.82727  43.6776  43.6776  0.0
 14 │ 0.176548    0.176548    1.10663  2.77502  2.77502  0.0
 15 │ -0.471723   -0.471723   1.51184  21.2797  21.2797  0.0
 16 │ -0.757145   -0.757145   1.25035  7.09335  7.09335  0.0
 17 │ -1.59799    -1.59799    1.32299  8.74912  8.74912  0.0
 18 │ -0.2873     -0.2873     1.19599  8.65057  8.65057  0.0
 19 │ -0.095961   -0.095961   1.61545  34.1614  34.1614  0.0
 20 │ -0.227454   -0.227454   1.26232  8.98806  8.98806  0.0
 21 │ 0.447541    0.447541    1.44906  17.716   17.716   0.0
 22 │ 1.22259     1.22259     2.80768  128.155  128.155  0.0
 23 │ 0.123348    0.123348    1.46632  23.0924  23.0924  0.0
 ⋮  │     ⋮           ⋮          ⋮        ⋮        ⋮      ⋮</code></pre>
</div>
</div>
<p>Consider the change in the penalized deviance from that at the conditional mode for a selection of groups, which, by default, we choose to be the first 5 groups.</p>
<div class="cell" data-execution_count="59">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">pdevdiff</span>(</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>  m<span class="op">::</span><span class="dt">BernoulliPIRLS{T}</span>;</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>  zvals<span class="op">=</span><span class="fu">collect</span>(<span class="op">-</span><span class="fl">3.5</span><span class="op">:</span><span class="fu">inv</span>(<span class="fl">32</span>)<span class="op">:</span><span class="fl">3.5</span>),</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>  inds<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>) <span class="kw">where</span> {T}</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>  (; u, u0, Ldiag, pdev, pdev0) <span class="op">=</span> m.utbl</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pdevcomps!</span>(<span class="fu">pirls!</span>(m))             <span class="co"># assign u0</span></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(pdev0, pdev)              <span class="co"># and pdev0</span></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>  ni <span class="op">=</span> <span class="fu">length</span>(inds)</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>  nz <span class="op">=</span> <span class="fu">length</span>(zvals)</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>  uvals <span class="op">=</span> <span class="fu">Array</span><span class="dt">{T}</span>(<span class="cn">undef</span>, ni, nz)</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>  exact <span class="op">=</span> <span class="fu">Array</span><span class="dt">{T}</span>(<span class="cn">undef</span>, ni, nz)</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j, z) <span class="kw">in</span> <span class="fu">enumerate</span>(zvals)</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>    u <span class="op">.=</span> u0 <span class="op">.+</span> z <span class="op">./</span> Ldiag           <span class="co"># evaluate u from z</span></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pdevcomps!</span>(<span class="fu">updatetbl!</span>(m))       <span class="co"># evaluate pdev</span></span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i, ind) <span class="kw">in</span> <span class="fu">enumerate</span>(inds) <span class="co"># store selected u and pdev</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>      uvals[i, j] <span class="op">=</span> u[ind]</span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a>      exact[i, j] <span class="op">=</span> pdev[ind] <span class="op">-</span> pdev0[ind]</span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb87-21"><a href="#cb87-21" aria-hidden="true" tabindex="-1"></a>  uvals <span class="op">=</span> <span class="fu">collect</span>(uvals<span class="op">'</span>)           <span class="co"># transpose uvals</span></span>
<span id="cb87-22"><a href="#cb87-22" aria-hidden="true" tabindex="-1"></a>  exact <span class="op">=</span> <span class="fu">collect</span>(exact<span class="op">'</span>)           <span class="co"># and exact</span></span>
<span id="cb87-23"><a href="#cb87-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (; zvals, inds, uvals, exact)</span>
<span id="cb87-24"><a href="#cb87-24" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb87-25"><a href="#cb87-25" aria-hidden="true" tabindex="-1"></a>m05pdevdiff <span class="op">=</span> <span class="fu">pdevdiff</span>(m);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We begin with plots of the difference in the penalized deviance from its value at the conditional mode, <span class="math inline">\(\tilde{d}_j(u_j)-\tilde{d_j}(\tilde{u}_j)\)</span>, for <span class="math inline">\(j=1,\dots,5\)</span> in <a href="#fig-uscalepdev">Figure&nbsp;<span>C.3</span></a></p>
<div class="cell" data-execution_count="60">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (; zvals, inds, uvals, exact) <span class="op">=</span> m05pdevdiff,</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> <span class="fu">Figure</span>(; resolution<span class="op">=</span>(<span class="fl">800</span>, <span class="fl">450</span>)),</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> <span class="fu">Axis</span>(</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    fig[<span class="fl">1</span>, <span class="fl">1</span>];</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    xlabel<span class="op">=</span><span class="st">"u"</span>,</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"Change in penalized deviance"</span>,</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>  lins <span class="op">=</span> [</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines!</span>(ax, <span class="fu">view</span>(uvals, <span class="op">:</span>, j), <span class="fu">view</span>(exact, <span class="op">:</span>, j)) for</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>    j <span class="kw">in</span> <span class="fu">axes</span>(uvals, <span class="fl">2</span>)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Legend</span>(fig[<span class="fl">1</span>, <span class="fl">2</span>], lins, <span class="fu">string</span>.(inds))</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>  fig</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="61">
<div id="fig-uscalepdev" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-uscalepdev-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.3: Change in the penalized deviance contribution from that at the conditional mode, for each of the first 5 groups, in model com05, as a function of u.</figcaption>
</figure>
</div>
</div>
</div>
<p>then shift and scale the horizontal axis to the <span class="math inline">\(z\)</span> scale for this difference in the penalized deviance (from that at the conditional mode) in <a href="#fig-zscalepdev">Figure&nbsp;<span>C.4</span></a>.</p>
<div class="cell" data-execution_count="61">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (; zvals, inds, uvals, exact) <span class="op">=</span> m05pdevdiff,</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> <span class="fu">Figure</span>(; resolution<span class="op">=</span>(<span class="fl">800</span>, <span class="fl">450</span>)),</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> <span class="fu">Axis</span>(</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    fig[<span class="fl">1</span>, <span class="fl">1</span>];</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    xlabel<span class="op">=</span><span class="st">"z"</span>,</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"Change in penalized deviance"</span>,</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>  lins <span class="op">=</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    [<span class="fu">lines!</span>(ax, zvals, <span class="fu">view</span>(exact, <span class="op">:</span>, j)) for j <span class="kw">in</span> <span class="fu">axes</span>(uvals, <span class="fl">2</span>)]</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Legend</span>(fig[<span class="fl">1</span>, <span class="fl">2</span>], lins, <span class="fu">string</span>.(inds))</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>  fig</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="62">
<div id="fig-zscalepdev" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-zscalepdev-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.4: Change in the penalized deviance contribution from that at the conditional mode, for each of the first 5 groups, in model com05, as a function of z.</figcaption>
</figure>
</div>
</div>
</div>
<p>The next stage is to plot, on the <span class="math inline">\(z\)</span> scale, the difference between the penalized deviance and its quadratic approximation at <span class="math inline">\(z=0\)</span> in <a href="#fig-zpdevdiff">Figure&nbsp;<span>C.5</span></a></p>
<div class="cell" data-execution_count="62">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (; zvals, inds, uvals, exact) <span class="op">=</span> m05pdevdiff,</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> <span class="fu">Figure</span>(; resolution<span class="op">=</span>(<span class="fl">800</span>, <span class="fl">450</span>)),</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> <span class="fu">Axis</span>(</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    fig[<span class="fl">1</span>, <span class="fl">1</span>];</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    xlabel<span class="op">=</span><span class="st">"z"</span>,</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"Penalized deviance minus quadratic approx"</span>,</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>  lins <span class="op">=</span> [</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines!</span>(ax, zvals, <span class="fu">view</span>(exact, <span class="op">:</span>, j) <span class="op">.-</span> <span class="fu">abs2</span>.(zvals)) for</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>    j <span class="kw">in</span> <span class="fu">axes</span>(uvals, <span class="fl">2</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Legend</span>(fig[<span class="fl">1</span>, <span class="fl">2</span>], lins, <span class="fu">string</span>.(inds))</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>  fig</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="63">
<div id="fig-zpdevdiff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-zpdevdiff-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.5: The difference between the contribution to the penalized deviance and its quadratic approximation for each of first 5 groups in model com05 as a function of z.</figcaption>
</figure>
</div>
</div>
</div>
<p>and, finally, the exponential of negative half of this difference in <a href="#fig-zexpneghalfdiff">Figure&nbsp;<span>C.6</span></a></p>
<div class="cell" data-execution_count="63">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (; zvals, inds, uvals, exact) <span class="op">=</span> m05pdevdiff,</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> <span class="fu">Figure</span>(; resolution<span class="op">=</span>(<span class="fl">800</span>, <span class="fl">450</span>)),</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> <span class="fu">Axis</span>(</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    fig[<span class="fl">1</span>, <span class="fl">1</span>];</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    xlabel<span class="op">=</span><span class="st">"z"</span>,</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"Exp of half the quadratic minus penalized deviance"</span>,</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>  lins <span class="op">=</span> [</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines!</span>(</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>      ax,</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>      zvals,</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>.(<span class="fl">0.5</span> <span class="op">.*</span> (<span class="fu">abs2</span>.(zvals) <span class="op">.-</span> <span class="fu">view</span>(exact, <span class="op">:</span>, j))),</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>    ) for j <span class="kw">in</span> <span class="fu">axes</span>(uvals, <span class="fl">2</span>)</span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Legend</span>(fig[<span class="fl">1</span>, <span class="fl">2</span>], lins, <span class="fu">string</span>.(inds))</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>  fig</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="64">
<div id="fig-zexpneghalfdiff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="aGHQ_files/figure-html/fig-zexpneghalfdiff-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;C.6: Exponential of half the difference between the quadratic approximation and the contribution to the penalized deviance, for each of first 5 groups in model com05 as a function of z.</figcaption>
</figure>
</div>
</div>
</div>
<p>Writing the function shown in <a href="#fig-zexpneghalfdiff">Figure&nbsp;<span>C.6</span></a> — the exponential of negative half the difference between the penalized deviance and its quadratic approximation — as <span class="math display">\[
f_j(z_j)=\exp{\left(\frac{\tilde{d}_j(z_j/\ell_j+\tilde{u}_j)-\tilde{d}_j(\tilde{u}_j)-z_j^2}{-2}\right)}
\quad j=1,\dots,q
\]</span> we can modify the scalar version of Laplace’s approximation, <a href="#eq-scalarlaplace">Equation&nbsp;<span>C.10</span></a>, as <span id="eq-scalaraGHQ"><span class="math display">\[
\begin{multline*}
-2\log\int_{u_j}\frac{e^{-\tilde{d}_j(u_j)/2}}{\sqrt{2\pi}}\,du_j\\
=-2\log\int_{z_j}\frac{f_j(z_j)\,e^{-(\tilde{d}_j(\tilde{u}_j)+z_j^2)/2}}{\sqrt{2\pi}}\,\frac{dz_j}{\ell_j}\\
=\tilde{d}_j(\tilde{u}_j)+2\log(\ell_j)-2\log\int_{z_j}f_j(z_j)\frac{e^{-z_j^2/2}}{\sqrt{2\pi}}\,dz_j
\end{multline*}
\tag{C.14}\]</span></span></p>
<p>A <span class="math inline">\(K\)</span>th-order adaptive Gauss-Hermite quadrature approximation to the objective, negative twice the log-likelihood, for the GLMM model is Laplace’s approximation minus twice the logarithm of the <span class="math inline">\(K\)</span>th order normalized Gauss-Hermite quadrature rule applied to <span class="math inline">\(f_j(z_j)\)</span>. We use the <code>aGHQ</code> column of <code>m.utbl</code> to accumulate these contributions and to take the logarithm then multiply the result by -2.</p>
<div class="cell" data-execution_count="64">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">evalGHQ!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>; nGHQ<span class="op">::</span><span class="dt">Integer</span>=<span class="fl">9</span>)</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  (; ytbl, utbl, rtbl) <span class="op">=</span> m</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>  (; u, u0, Ldiag, pdev, pdev0, aGHQ) <span class="op">=</span> utbl</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>  ghqtbl <span class="op">=</span> <span class="fu">GHnorm</span>(nGHQ)</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pdevcomps!</span>(<span class="fu">pirls!</span>(m))  <span class="co"># ensure that u0 and pdev0 are current</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">copyto!</span>(pdev0, pdev)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fill!</span>(aGHQ, <span class="fl">0</span>)</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (z, w) <span class="kw">in</span> <span class="fu">zip</span>(ghqtbl.z, ghqtbl.w)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="fu">iszero</span>(z)         <span class="co"># exp term is one when z == 0</span></span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>      aGHQ <span class="op">.+=</span> w</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>      u <span class="op">.=</span> u0 <span class="op">.+</span> z <span class="op">./</span> Ldiag</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pdevcomps!</span>(<span class="fu">updatetbl!</span>(m))</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>      aGHQ <span class="op">.+=</span> w <span class="op">.*</span> <span class="fu">exp</span>.((<span class="fu">abs2</span>(z) <span class="op">.+</span> pdev0 <span class="op">.-</span> pdev) <span class="op">./</span> <span class="fl">2</span>)</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map!</span>(log, aGHQ, aGHQ)  <span class="co"># log.(aGHQ) in place</span></span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>  aGHQ <span class="op">.*=</span> <span class="op">-</span><span class="fl">2</span></span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">evalGHQ!</span>(m)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Table</span>(m.utbl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>Table with 6 columns and 102 rows:
      u         u0          Ldiag    pdev     pdev0    aGHQ
    ┌─────────────────────────────────────────────────────────────
 1  │ 0.888261  -1.02425    2.3596   98.9905  78.2322  -0.00503286
 2  │ 0.746346  -1.6554     1.87894  65.9282  41.917   -0.00602822
 3  │ 2.88235   -0.0432084  1.54253  42.7156  21.8681  -0.0077699
 4  │ 4.71226   0.500796    1.07154  22.5154  2.68642  -0.00332321
 5  │ 4.5948    1.10928     1.29471  26.5466  8.58305  -0.00560788
 6  │ 2.60588   -0.415844   1.49343  40.3098  18.6901  -0.00726535
 7  │ 4.26289   0.0305151   1.06624  21.5982  1.46897  -0.00232427
 8  │ 2.62803   0.216409    1.87125  67.5008  46.1746  -0.00639679
 9  │ 4.10316   0.433361    1.2297   28.6561  9.7717   -0.00680155
 10 │ 1.4908    -0.648279   2.10967  80.9664  58.417   -0.00583025
 11 │ 2.73092   -0.328134   1.47521  44.9692  23.5301  -0.00736271
 12 │ 4.72216   0.499976    1.06882  22.6241  2.74129  -0.00283963
 13 │ 2.60939   0.139717    1.82727  64.9152  43.6776  -0.00681333
 14 │ 4.25447   0.176548    1.10663  22.371   2.77502  -0.00457801
 15 │ 2.51322   -0.471723   1.51184  43.0725  21.2797  -0.00742932
 16 │ 2.85204   -0.757145   1.25035  29.6883  7.09335  -0.00309483
 17 │ 1.81302   -1.59799    1.32299  32.9677  8.74912  -0.00213836
 18 │ 3.48593   -0.2873     1.19599  28.7773  8.65057  -0.00590273
 19 │ 2.69754   -0.095961   1.61545  55.085   34.1614  -0.00779244
 20 │ 3.34752   -0.227454   1.26232  29.0427  8.98806  -0.0072417
 21 │ 3.56181   0.447541    1.44906  37.9855  17.716   -0.00763473
 22 │ 2.82988   1.22259     2.80768  146.8    128.155  -0.00360118
 23 │ 3.20095   0.123348    1.46632  44.1065  23.0924  -0.00745216
 ⋮  │    ⋮          ⋮          ⋮        ⋮        ⋮          ⋮</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extrema</span>(m.utbl.aGHQ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>(-0.008514109733813818, -0.000413268627218805)</code></pre>
</div>
</div>
<p>As we see, these “correction terms” relative to Laplace’s approximation are relatively small, compared to the contributions to the objective from each component of <span class="math inline">\({\mathbf{u}}\)</span>. Also, the corrections are all negative, in this case. Close examination of the individual curves in <a href="#fig-zpdevdiff">Figure&nbsp;<span>C.5</span></a> shows that these curves, which are <span class="math inline">\(-2\log(f_j(z))\)</span>, are more-or-less <a href="https://en.wikipedia.org/wiki/Even_and_odd_functions">odd functions</a>, in the sense that the value at <span class="math inline">\(-z\)</span> is approximately the negative of the value at <span class="math inline">\(z\)</span>. If we were integrating <span class="math inline">\(\log(f_j(z_j))\phi(z_j)\)</span> with a normalized Gauss-Hermite rule the negative and positive values would cancel out, for the most part, and some of the integrals would be positive while others would be negative.</p>
<p>When we consider <span class="math inline">\(f_j(z_j)\)</span>, shown in <a href="#fig-zexpneghalfdiff">Figure&nbsp;<span>C.6</span></a>, the exponential function converts from differences to ratios and stretches positive differences more than negative differences, resulting in values slightly greater than 1 for <span class="math inline">\(\int_z f_j(z)\phi(z) dz\)</span> and, after taking negative twice the logarithm, correction terms that are slightly less than zero.</p>
</section>
</section>
<section id="optimization-of-the-aghq-objective" class="level2" data-number="C.7">
<h2 data-number="C.7" class="anchored" data-anchor-id="optimization-of-the-aghq-objective"><span class="header-section-number">C.7</span> Optimization of the aGHQ objective</h2>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">fitGHQ!</span>(m<span class="op">::</span><span class="dt">BernoulliPIRLS</span>; nGHQ<span class="op">::</span><span class="dt">Integer</span>=<span class="fl">9</span>)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>  (; Ldiag, pdev0, aGHQ) <span class="op">=</span> m.utbl</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>  θβ <span class="op">=</span> m.θβ</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>  pp1 <span class="op">=</span> <span class="fu">length</span>(θβ)                <span class="co"># length(β) = p and length(θ) = 1</span></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>  opt <span class="op">=</span> <span class="fu">Opt</span>(<span class="op">:</span>LN_BOBYQA, pp1)</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>  mβ <span class="op">=</span> <span class="fu">view</span>(θβ, <span class="fl">2</span><span class="op">:</span>pp1)</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">obj</span>(x, g)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> !<span class="fu">isempty</span>(g)</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">throw</span>(<span class="fu">ArgumentError</span>(<span class="st">"gradient not provided, g must be empty"</span>))</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">copyto!</span>(θβ, x)</span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mul!</span>(m.ytbl.offset, m.X, mβ)</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">evalGHQ!</span>(m; nGHQ)</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">sum</span>(pdev0) <span class="op">+</span> <span class="fu">sum</span>(aGHQ) <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu">sum</span>(log, Ldiag)</span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end</span></span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true" tabindex="-1"></a>  opt.min_objective <span class="op">=</span> obj</span>
<span id="cb97-17"><a href="#cb97-17" aria-hidden="true" tabindex="-1"></a>  lb <span class="op">=</span> <span class="fu">fill!</span>(<span class="fu">similar</span>(θβ), <span class="op">-</span><span class="cn">Inf</span>)   <span class="co"># vector of lower bounds</span></span>
<span id="cb97-18"><a href="#cb97-18" aria-hidden="true" tabindex="-1"></a>  lb[<span class="fl">1</span>] <span class="op">=</span> <span class="fl">0</span>                       <span class="co"># scalar θ must be non-negative</span></span>
<span id="cb97-19"><a href="#cb97-19" aria-hidden="true" tabindex="-1"></a>  NLopt.<span class="fu">lower_bounds!</span>(opt, lb)</span>
<span id="cb97-20"><a href="#cb97-20" aria-hidden="true" tabindex="-1"></a>  minf, minx, ret <span class="op">=</span> <span class="fu">optimize</span>(opt, <span class="fu">copy</span>(θβ))</span>
<span id="cb97-21"><a href="#cb97-21" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@info</span> (; ret, fevals<span class="op">=</span>opt.numevals, minf)</span>
<span id="cb97-22"><a href="#cb97-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> m</span>
<span id="cb97-23"><a href="#cb97-23" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitGHQ!</span>(m)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">showcompact</span>(m.θβ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>┌ Warning: PIRLS iteration did not reduce penalized deviance
└ @ Main In[40]:11
┌ Warning: PIRLS iteration did not reduce penalized deviance
└ @ Main In[40]:11</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.576132, -0.341466, 0.393599, 0.606445, -0.0129097, 0.0332099, -0.00562461]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: (ret = :ROUNDOFF_LIMITED, fevals = 502, minf = 2353.8241975532205)</code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list" style="display: none">
<div id="ref-powell2009bobyqa" class="csl-entry" role="listitem">
Powell, M. J. (2009). The BOBYQA algorithm for bound constrained optimization without derivatives. <em>Cambridge NA Report NA2009/06, University of Cambridge, Cambridge</em>, <em>26</em>.
</div>
<div id="ref-TierneyKadane1986" class="csl-entry" role="listitem">
Tierney, L., &amp; Kadane, J. B. (1986). Accurate approximations for posterior moments and marginal densities. <em>Journal of the American Statistical Association</em>, <em>81</em>(393), 82–86. <a href="https://doi.org/10.1080/01621459.1986.10478240">https://doi.org/10.1080/01621459.1986.10478240</a>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./linalg.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Linear Algebra for Linear Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>