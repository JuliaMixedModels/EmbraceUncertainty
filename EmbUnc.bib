% Encoding: UTF-8

@Article{baayen.vasishth.etal:2017jml,
  author        = {Baayen, Harald and Vasishth, Shravan and Kliegl, Reinhold and Bates, Douglas},
  title         = {The cave of shadows: Addressing the human factor with generalized additive mixed models},
  doi           = {10.1016/j.jml.2016.11.006},
  pages         = {206--234},
  volume        = {94},
  abstract      = {Abstract Generalized additive mixed models are introduced as an extension of the generalized linear mixed model which makes it possible to deal with temporal autocorrelational structure in experimental data. This autocorrelational structure is likely to be a consequence of learning, fatigue, or the ebb and flow of attention within an experiment (the `human factor'). Unlike molecules or plots of barley, subjects in psycholinguistic experiments are intelligent beings that depend for their survival on constant adaptation to their environment, including the environment of an experiment. Three data sets illustrate that the human factor may interact with predictors of interest, both factorial and metric. We also show that, especially within the framework of the generalized additive model, in the nonlinear world, fitting maximally complex models that take every possible contingency into account is ill-advised as a modeling strategy. Alternative modeling strategies are discussed for both confirmatory and exploratory data analysis.},
  date-added    = {2020-03-24},
  date-modified = {2017-02-14 02:16:15 +0000},
  file          = {baayen.vasishth.etal\:2017jml - cave shadows_ Addressing.pdf:2017/baayen.vasishth.etal_2017jml - cave shadows_ Addressing.pdf:PDF},
  file2         = {/Documents/Papers/2017/baayen.vasishth.etal2017jml - The cave of shadows Addressing the human factor with generalized additive mixed modelsa.pdf},
  groups        = {Methods, GAMMs},
  journal       = {Journal of Memory and Language},
  keywords      = {Generalized additive mixed models, Within-experiment adaptation, Autocorrelation, Experimental time series, Confirmatory versus exploratory data analysis, Model selection},
  month         = jun,
  year          = {2017},
}

@Article{bates.kliegl.etal:2015a,
  author        = {Bates, Douglas and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald},
  title         = {Parsimonius Mixed Models},
  pages         = {1506.04967v1},
  date-added    = {2020-03-24},
  date-modified = {2015-06-25 03:21:03 +0000},
  file          = {bates.kliegl.etal\:2015a - Parsimonius Mixed Models.pdf:2015/bates.kliegl.etal_2015a - Parsimonius Mixed Models.pdf:PDF},
  journal       = {arXiv},
  year          = {2015},
}

@Article{bates.maechler.etal:2015,
  author        = {Bates, Douglas and Maechler, Martin and Bolker, Benjamin M. and Walker, Steven},
  title         = {Fitting Linear Mixed-Effects Models using lme4},
  doi           = {10.18637/jss.v067.i01},
  number        = {1},
  pages         = {1--48},
  volume        = {67},
  date-added    = {2020-03-24},
  date-modified = {2016-02-12 06:52:06 +0000},
  file          = {:2015/bates.maechler.etal_2015 - Fitting Linear Mixed.pdf:PDF},
  journal       = {Journal of Statistical Software},
  year          = {2015},
}

@Article{matuschek.kliegl.etal:2017jml,
  author        = {Matuschek, Hannes and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald and Bates, Douglas},
  title         = {Balancing Type I error and power in linear mixed models},
  doi           = {10.1016/j.jml.2017.01.001},
  pages         = {305--315},
  volume        = {94},
  abstract      = {Abstract Linear mixed-effects models have increasingly replaced mixed-model analyses of variance for statistical inference in factorial psycholinguistic experiments. Although LMMs have many advantages over ANOVA, like ANOVAs, setting them up for data analysis also requires some care. One simple option, when numerically possible, is to fit the full variance-covariance structure of random effects (the maximal model; Barr, Levy, Scheepers & Tily, 2013), presumably to keep Type I error down to the nominal α in the presence of random effects. Although it is true that fitting a model with only random intercepts may lead to higher Type I error, fitting a maximal model also has a cost: it can lead to a significant loss of power. We demonstrate this with simulations and suggest that for typical psychological and psycholinguistic data, higher power is achieved without inflating Type I error rate if a model selection criterion is used to select a random effect structure that is supported by the data.},
  date-added    = {2020-03-24},
  date-modified = {2017-02-14 02:15:14 +0000},
  file          = {matuschek.kliegl.etal\:2017jml - Balancing Type I.pdf:2017/matuschek.kliegl.etal_2017jml - Balancing Type I.pdf:PDF},
  journal       = {Journal of Memory and Language},
  keywords      = {Power, Linear mixed effect model, Hypothesis testing},
  month         = jun,
  year          = {2017},
}

@Book{pinheirobates2000a,
  author        = {Pinheiro, José C. and Bates, Douglas M.},
  title         = {Mixed-Effects Models in S and S-{PLUS}},
  doi           = {10.1007/b98882},
  isbn          = {0-387-98957-9},
  publisher     = {Springer-Verlag},
  url           = {https://books.google.de/books?id=3TVDAAAAQBAJ},
  bdsk-url-1    = {https://books.google.de/books?id=3TVDAAAAQBAJ},
  date-added    = {2020-03-24},
  date-modified = {2015-02-02 17:36:40 +0000},
  file          = {:2000/pinheirobates2000a - Mixed Effects Models.pdf:PDF},
  year          = {2000},
}

@Article{bates2019n,
  author     = {Bates, Douglas},
  title      = {Complexity in fitting Linear Mixed Models},
  doi        = {10.33016/nextjournal.100002},
  date-added = {2020-03-24},
  journal    = {Nextjournal},
  month      = {aug},
  publisher  = {Nextjournal},
  year       = {2019},
}

@Article{barr2013a,
  author        = {Barr, Dale J.},
  title         = {Random Effects Structure for Testing Interactions in Linear Mixed-effects Models},
  doi           = {10.3389/fpsyg.2013.00328},
  number        = {328},
  volume        = {4},
  date-added    = {2020-03-24},
  date-modified = {2015-02-06 17:10:55 +0000},
  file          = {barr2013a - Random Effects Structure.pdf:2013/barr2013a - Random Effects Structure.pdf:PDF},
  journal       = {Frontiers in Psychology},
  year          = {2013},
}

@Article{barrlevyscheepers2013a,
  author        = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  title         = {Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal},
  doi           = {10.1016/j.jml.2012.11.001},
  pages         = {255--278},
  volume        = {68},
  date-added    = {2020-03-24},
  date-modified = {2015-02-06 17:10:37 +0000},
  file          = {barrlevyscheepers2013a - Random Effects Structure.pdf:2013/barrlevyscheepers2013a - Random Effects Structure.pdf:PDF},
  journal       = {Journal of Memory and Language},
  keywords      = {mixed effects models},
  year          = {2013},
}

@Article{mb1,
  author       = {{ManyBabiesConsortium}},
  date         = {in press},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  title        = {Quantifying sources of variability in infancy research using the infant-directed speech preference},
  date-added   = {2020-03-24},
}

@Article{baayendavidsonbates2008a,
  author        = {Baayen, R. H. and Davidson, D. J. and Bates, D. M.},
  title         = {Mixed-effects Modeling with Crossed Random Effects for Subjects and Items},
  pages         = {390--412},
  volume        = {59},
  date-added    = {2020-03-24},
  date-modified = {2015-02-06 17:11:33 +0000},
  file          = {baayendavidsonbates2008a - Mixed effects Modeling.pdf:2008/baayendavidsonbates2008a - Mixed effects Modeling.pdf:PDF},
  journal       = {Journal of Memory and Language},
  keywords      = {statistics, mixed effects models},
  year          = {2008},
}

@Article{alday.etal:mixedmodels.jl,
  author       = {Alday, Phillip M. and Kleinschmidt, David and Kliegl, Reinhold and Bates, D.},
  date         = {in prep},
  journaltitle = {Journal of Statistical Software},
  title        = {An efficient derivation of the profiled log likelihood for linear mixed-effects models.},
  date-added   = {2020-03-25},
}

@WWW{frank.blog.maximal,
  author     = {Michael Frank},
  date       = {2019},
  title      = {Mixed effects models: Is it time to go Bayesian by default?},
  url        = {https://web.archive.org/web/20190601175639/https://babieslearninglanguage.blogspot.com/2019/05/its-random-effects-stupid.html},
  urldate    = {2019-06-01},
  date-added = {2020-03-29},
}

@WWW{frank.blog.bayes,
  author     = {Michael Frank},
  date       = {2018},
  title      = {It's the random effects, stupid!},
  url        = {https://web.archive.org/web/20190715193907/https://babieslearninglanguage.blogspot.com/2018/02/mixed-effects-models-is-it-time-to-go.html},
  urldate    = {2019-07-15},
  date-added = {2020-03-29},
}

@Comment{jabref-meta: databaseType:biblatex;}
