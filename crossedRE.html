<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Phillip Alday" />
  <meta name="author" content="Dave Kleinschmidt" />
  <meta name="author" content="Reinhold Kliegl" />
  <meta name="author" content="Douglas Bates" />
  <title>A Model With Crossed Random Effects - Embrace Uncertainty</title>
  <link rel="shortcut icon" type="image/png" href="/favicon.png"/>
  <link rel="stylesheet" href="/style.css"/>
    <script src="/mousetrap.min.js"></script>
    <!-- TODO: Add url_prefix. -->
  <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("/JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="/github.min.css">
<script src="/highlight.min.js"></script>
<script src="/julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        hljs.highlightElement(el);
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="/">Embrace Uncertainty</a>
</div><br />
<span class="books-subtitle">
Fitting Mixed-Effects Models with Julia
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="/ExamLMM"><b>1</b> A Simple, Linear, Mixed-..</a></li>
<li><a class="menu-level-2" href="/memod"><b>1.1</b> Mixed-effects models</a></li>
<li><a class="menu-level-2" href="/DyestuffData"><b>1.2</b> The dyestuff and dyest..</a></li>
<li><a class="menu-level-2" href="/FittingLMMs"><b>1.3</b> Fitting linear mixed m..</a></li>
<li><a class="menu-level-2" href="/Probability"><b>1.4</b> The linear mixed-effec..</a></li>
<li><a class="menu-level-2" href="/variability"><b>1.5</b> Assessing the variabil..</a></li>
<li><a class="menu-level-2" href="/assessRE"><b>1.6</b> Assessing the random e..</a></li>
<li><a class="menu-level-2" href="/ChIntroSummary"><b>1.7</b> Chapter summary</a></li>
<li><a class="menu-level-1" href="/Multiple"><b>2</b> Models With Multiple Ran..</a></li>
<li><a class="menu-level-2" href="/crossedRE"><b>2.1</b> A Model With Crossed R..</a></li>
<li><a class="menu-level-2" href="/NestedRE"><b>2.2</b> A Model With Nested Ra..</a></li>
<li><a class="menu-level-2" href="/partially"><b>2.3</b> A Model With Partially..</a></li>
<li><a class="menu-level-2" href="/MultSummary"><b>2.4</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/longitudinal"><b>3</b> # Models for Longitudina..</a></li>
<li><a class="menu-level-2" href="/sleep"><b>3.1</b> Data</a></li>
<li><a class="menu-level-2" href="/SleepMixed"><b>3.2</b> Data</a></li>
<li><a class="menu-level-2" href="/assess-prec-param"><b>3.3</b> Assessing the Precisio..</a></li>
<li><a class="menu-level-2" href="/fm07re"><b>3.4</b> Examining the Random E..</a></li>
<li><a class="menu-level-2" href="/chapter-summary"><b>3.5</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/computational"><b>4</b> Computational Methods fo..</a></li>
<li><a class="menu-level-2" href="/defnLMM"><b>4.1</b> Definitions and Basic ..</a></li>
<li><a class="menu-level-2" href="/conddistUgivenY"><b>4.2</b> </a></li>
<li><a class="menu-level-2" href="/IntegratingH"><b>4.3</b> in the Linear Mixed Mo..</a></li>
<li><a class="menu-level-2" href="/PLSsol"><b>4.4</b> </a></li>
<li><a class="menu-level-2" href="/REML"><b>4.5</b> The REML Criterion</a></li>
<li><a class="menu-level-2" href="/stepByStep"><b>4.6</b> Step-by-step Evaluatio..</a></li>
<li><a class="menu-level-2" href="/general"><b>4.7</b> Generalizing to Other ..</a></li>
<li><a class="menu-level-2" href="/lmmsummary"><b>4.8</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/GLMMbinomial"><b>5</b> Generalized Linear Mixed..</a></li>
<li><a class="menu-level-2" href="/contraception"><b>5.1</b> Artificial contracepti..</a></li>
<li><a class="menu-level-2" href="/GLMMlink"><b>5.2</b> Link functions and int..</a></li>
<li><a class="menu-level-1" href="/references"><b></b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="2.1" id="sec:crossedRE"><span class="header-section-number">2.1</span> A Model With Crossed Random Effects</h2>
<p>One of the areas in which the methods in the package for are particularly effective is in fitting models to cross-classified data where several factors have random effects associated with them. For example, in many experiments in psychology the reaction of each of a group of subjects to each of a group of stimuli or items is measured. If the subjects are considered to be a sample from a population of subjects and the items are a sample from a population of items, then it would make sense to associate random effects with both these factors.</p>
<p>In the past it was difficult to fit mixed models with multiple, crossed grouping factors to large, possibly unbalanced, data sets. The methods in the package are able to do this. To introduce the methods let us first consider a small, balanced data set with crossed grouping factors.</p>
<h3 data-number="2.1.1" id="sec:penicillin"><span class="header-section-number">2.1.1</span> The <em>penicillin</em> Data</h3>
<p>The data are derived from Table 6.6, p. 144 of <span class="citation" data-cites="davies72:_statis_method_in_resear_and_produc"><a href="/references#ref-davies72:_statis_method_in_resear_and_produc" role="doc-biblioref">Davies &amp; Goldsmith</a> (<a href="/references#ref-davies72:_statis_method_in_resear_and_produc" role="doc-biblioref">1972</a>)</span> where they are described as coming from an investigation to</p>
<blockquote>
<p>assess the variability between samples of penicillin by the <em>B. subtilis</em> method. In this test method a bulk-innoculated nutrient agar medium is poured into a Petri dish of approximately 90 mm. diameter, known as a plate. When the medium has set, six small hollow cylinders or pots (about 4 mm. in diameter) are cemented onto the surface at equally spaced intervals. A few drops of the penicillin solutions to be compared are placed in the respective cylinders, and the whole plate is placed in an incubator for a given time. Penicillin diffuses from the pots into the agar, and this produces a clear circular zone of inhibition of growth of the organisms, which can be readily measured. The diameter of the zone is related in a known way to the concentration of penicillin in the solution.</p>
</blockquote>
<p>As with the data, we examine the structure</p>
<pre class="language-julia"><code>penicillin = MixedModels.dataset(:penicillin)</code></pre>
<pre class="output"><code>Arrow.Table with 144 rows, 3 columns, and schema:
 :plate     String
 :sample    String
 :diameter  Int8</code></pre>
<p>and a summary</p>
<pre class="language-julia"><code>penicillin = DataFrame(penicillin)
describe(penicillin)</code></pre>
<table>
<caption>PenicillinisDataFrame penicillin describe penicillin . {#tbl:penicillinisDataFrame_penicillin describe_penicillin }</caption>
<thead>
<tr class="header">
<th style="text-align: right;">variable</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">median</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">nmissing</th>
<th style="text-align: right;">eltype</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">plate</td>
<td style="text-align: right;">nothing</td>
<td style="text-align: right;">a</td>
<td style="text-align: right;">nothing</td>
<td style="text-align: right;">x</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">String</td>
</tr>
<tr class="even">
<td style="text-align: right;">sample</td>
<td style="text-align: right;">nothing</td>
<td style="text-align: right;">A</td>
<td style="text-align: right;">nothing</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">String</td>
</tr>
<tr class="odd">
<td style="text-align: right;">diameter</td>
<td style="text-align: right;">22.97222222222222</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">23.0</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">Int8</td>
</tr>
</tbody>
</table>
<p>of the data, then plot it</p>
<p>The variation in the diameter is associated with the plates and with the samples. Because each plate is used only for the six samples shown here we are not interested in the contributions of specific plates as much as we are interested in the variation due to plates and in assessing the potency of the samples after accounting for this variation. Thus, we will use random effects for the factor. We will also use random effects for the factor because, as in the dyestuff example, we are more interested in the sample-to-sample variability in the penicillin samples than in the potency of a particular sample.</p>
<p>In this experiment each sample is used on each plate. We say that the and factors are <em>crossed</em>, as opposed to <em>nested</em> factors, which we will describe in the next section. By itself, the designation “crossed” just means that the factors are not nested. If we wish to be more specific, we could describe these factors as being <em>completely crossed</em>, which means that we have at least one observation for each combination of a level of and a level of . We can see this in Fig. <a href="#fig:Penicillindot" data-reference-type="ref" data-reference="fig:Penicillindot">[fig:Penicillindot]</a> and, because there are moderate numbers of levels in these factors, we can check it in a cross-tabulation</p>
<p>Like the data, the factors in the data are balanced. That is, there are exactly the same number of observations on each plate and for each sample and, furthermore, there is the same number of observations on each combination of levels. In this case there is exactly one observation for each combination of sample and plate. We would describe the configuration of these two factors as an unreplicated, completely balanced, crossed design.</p>
<p>In general, balance is a desirable but precarious property of a data set. We may be able to impose balance in a designed experiment but we typically cannot expect that data from an observation study will be balanced. Also, as anyone who analyzes real data soon finds out, expecting that balance in the design of an experiment will produce a balanced data set is contrary to “Murphy’s Law.” That’s why statisticians allow for missing data. Even when we apply each of the six samples to each of the 24 plates, something could go wrong for one of the samples on one of the plates, leaving us without a measurement for that combination of levels and thus an unbalanced data set.</p>
<h3 data-number="2.1.2" id="sec:PenicillinModel"><span class="header-section-number">2.1.2</span> A Model For the <em>penicillin</em> Data</h3>
<p>A model incorporating random effects for both the and the is straightforward to specify — we include simple, scalar random effects terms for both these factors.</p>
<pre class="language-julia"><code>m3 = fit(
    MixedModel,
    @formula(diameter ~ 1 + (1|plate) + (1|sample)),
    penicillin;
    thin=1,
    )</code></pre>
<pre class="language-plain"><code>Linear mixed model fit by maximum likelihood
 diameter ~ 1 + (1 | plate) + (1 | sample)
   logLik   -2 logLik     AIC       AICc        BIC    
  -166.0942   332.1883   340.1883   340.4761   352.0676

Variance components:
            Column   Variance Std.Dev. 
plate    (Intercept)  0.714980 0.845565
sample   (Intercept)  3.135193 1.770648
Residual              0.302426 0.549933
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  22.9722    0.744596  30.85    &lt;1e-99
─────────────────────────────────────────────────</code></pre>
<p>This model display indicates that the sample-to-sample variability has the greatest contribution, then plate-to-plate variability and finally the “residual” variability that cannot be attributed to either the sample or the plate. These conclusions are consistent with what we see in the data plot (Fig. <a href="#fig:Penicillindot" data-reference-type="ref" data-reference="fig:Penicillindot">[fig:Penicillindot]</a>).</p>
<p>The prediction intervals on the random effects (Fig. <a href="#fig:fm03ranef" data-reference-type="ref" data-reference="fig:fm03ranef">[fig:fm03ranef]</a>) confirm that the conditional distribution of the random effects for has much less variability than does the conditional distribution of the random effects for , in the sense that the dots in the bottom panel have less variability than those in the top panel. (Note the different horizontal axes for the two panels.) However, the conditional distribution of the random effect for a particular , say sample F, has less variability than the conditional distribution of the random effect for a particular plate, say plate m. That is, the lines in the bottom panel are wider than the lines in the top panel, even after taking the different axis scales into account. This is because the conditional distribution of the random effect for a particular sample depends on 24 responses while the conditional distribution of the random effect for a particular plate depends on only 6 responses.</p>
<p>In chapter <a href="#chap:ExamLMM" data-reference-type="ref" data-reference="chap:ExamLMM">[chap:ExamLMM]</a> we saw that a model with a single, simple, scalar random-effects term generated a random-effects model matrix, <span class="math inline">\(\mathbf{Z}\)</span>, that is the matrix of indicators of the levels of the grouping factor. When we have multiple, simple, scalar random-effects terms, as in model , each term generates a matrix of indicator columns and these sets of indicators are concatenated to form the model matrix <span class="math inline">\(\mathbf{Z}\)</span>. The transpose of this matrix, shown in Fig. <a href="#fig:fm03Ztimage" data-reference-type="ref" data-reference="fig:fm03Ztimage">[fig:fm03Ztimage]</a>, contains rows of indicators for each factor.</p>
<p>The relative covariance factor, <span class="math inline">\(\Lambda_\theta\)</span>, (Fig. <a href="#fig:fm03LambdaLimage" data-reference-type="ref" data-reference="fig:fm03LambdaLimage">[fig:fm03LambdaLimage]</a>, left panel) is no longer a multiple of the identity. It is now block diagonal, with two blocks, one of size 24 and one of size 6, each of which is a multiple of the identity. The diagonal elements of the two blocks are <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>, respectively. The numeric values of these parameters can be obtained as</p>
<p>The first parameter is the relative standard deviation of the random effects for , which has the value <span class="math inline">\(0.84671/0.54992=1.53968\)</span> at convergence, and the second is the relative standard deviation of the random effects for (<span class="math inline">\(1.93157/0.54992=3.512443\)</span>).</p>
<p>Because <span class="math inline">\(\Lambda_\theta\)</span> is diagonal, the pattern of non-zeros in <span class="math inline">\(\Lambda_\theta\trans\mathbf{Z}\trans\mathbf{Z}\Lambda_\theta+\mathbf{I}\)</span> will be the same as that in <span class="math inline">\(\mathbf{Z}\trans\mathbf{Z}\)</span>, shown in the middle panel of Fig. <a href="#fig:fm03LambdaLimage" data-reference-type="ref" data-reference="fig:fm03LambdaLimage">[fig:fm03LambdaLimage]</a>. The sparse Cholesky factor, <span class="math inline">\(\mathbf{L}\)</span>, shown in the right panel, is lower triangular and has non-zero elements in the lower right hand corner in positions where <span class="math inline">\(\mathbf{Z}\trans\mathbf{Z}\)</span> has systematic zeros. We say that “fill-in” has occurred when forming the sparse Cholesky decomposition. In this case there is a relatively minor amount of fill but in other cases there can be a substantial amount of fill and we shall take precautions so as to reduce this, because fill-in adds to the computational effort in determining the MLEs or the REML estimates.</p>
<p>A profile zeta plot (Fig. <a href="#fig:fm03prplot" data-reference-type="ref" data-reference="fig:fm03prplot">[fig:fm03prplot]</a>) for the parameters in model</p>
<p>leads to conclusions similar to those from Fig. <a href="#fig:fm01prof" data-reference-type="ref" data-reference="fig:fm01prof">[fig:fm01prof]</a> for model in the previous chapter. The fixed-effect parameter, <span class="math inline">\(\beta_0\)</span>, for the term has symmetric intervals and is over-dispersed relative to the normal distribution. The logarithm of <span class="math inline">\(\sigma\)</span> has a good normal approximation but the standard deviations of the random effects, <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span>, are skewed. The skewness for <span class="math inline">\(\sigma_2\)</span> is worse than that for <span class="math inline">\(\sigma_1\)</span>, because the estimate of <span class="math inline">\(\sigma_2\)</span> is less precise than that of <span class="math inline">\(\sigma_1\)</span>, in both absolute and relative senses. For an absolute comparison we compare the widths of the confidence intervals for these parameters.</p>
<p>In a relative comparison we examine the ratio of the endpoints of the interval divided by the estimate.</p>
<p>(We have switched from the REML estimates shown in the display of to the ML estimates of the standard deviations.)</p>
<p>The lack of precision in the estimate of <span class="math inline">\(\sigma_2\)</span> is a consequence of only having 6 distinct levels of the factor. The factor, on the other hand, has 24 distinct levels. In general it is more difficult to estimate a measure of spread, such as the standard deviation, than to estimate a measure of location, such as a mean, especially when the number of levels of the factor is small. Six levels are about the minimum number required for obtaining sensible estimates of standard deviations for simple, scalar random effects terms.</p>
<p>The profile pairs plot (Fig. <a href="#fig:fm03prpairs" data-reference-type="ref" data-reference="fig:fm03prpairs">[fig:fm03prpairs]</a>)</p>
<p>shows patterns similar to those in Fig. <a href="#fig:fm01profpair" data-reference-type="ref" data-reference="fig:fm01profpair">[fig:fm01profpair]</a> for pairs of parameters in model fit to the data. On the <span class="math inline">\(\zeta\)</span> scale (panels below the diagonal) the profile traces are nearly straight and orthogonal with the exception of the trace of <span class="math inline">\(\zeta(\sigma_2)\)</span> on <span class="math inline">\(\zeta(\beta_0)\)</span> (the horizontal trace for the panel in the <span class="math inline">\((4,2)\)</span> position). The pattern of this trace is similar to the pattern of the trace of <span class="math inline">\(\zeta(\sigma_1)\)</span> on <span class="math inline">\(\zeta(\beta_0)\)</span> in Fig. <a href="#fig:fm01profpair" data-reference-type="ref" data-reference="fig:fm01profpair">[fig:fm01profpair]</a>. Moving <span class="math inline">\(\beta_0\)</span> from its estimate, <span class="math inline">\(\widehat{\beta}_0\)</span>, in either direction will increase the residual sum of squares. The increase in the residual variability is reflected in an increase of one or more of the dispersion parameters. The balanced experimental design results in a fixed estimate of <span class="math inline">\(\sigma\)</span> and the extra apparent variability must be incorporated into <span class="math inline">\(\sigma_1\)</span> or <span class="math inline">\(\sigma_2\)</span>.</p>
<p>Contours in panels of parameter pairs on the original scales (i.e. panels above the diagonal) can show considerable distortion from the ideal elliptical shape. For example, contours in the <span class="math inline">\(\sigma_2\)</span> versus <span class="math inline">\(\sigma_1\)</span> panel (the <span class="math inline">\((1,2)\)</span> position) and the <span class="math inline">\(\log(\sigma)\)</span> versus <span class="math inline">\(\sigma_2\)</span> panel (in the <span class="math inline">\((2,3)\)</span> position) are dramatically non-elliptical. However, the distortion of the contours is not due to these parameter estimates depending strongly on each other. It is almost entirely due to the choice of scale for <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span>. When we plot the contours on the scale of <span class="math inline">\(\log(\sigma_1)\)</span> and <span class="math inline">\(\log(\sigma_2)\)</span> instead (Fig. <a href="#fig:fm03lprpairs" data-reference-type="ref" data-reference="fig:fm03lprpairs">[fig:fm03lprpairs]</a>)</p>
<p>they are much closer to the elliptical pattern.</p>
<p>Conversely, if we tried to plot contours on the scale of <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span> (not shown), they would be hideously distorted.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-1" href="/Multiple"><b>2</b> Models With Multiple Ran..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="/NestedRE"><b>2.2</b> A Model With Nested Ra..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Phillip Alday, Dave Kleinschmidt, Reinhold Kliegl, Douglas Bates
</div>
</div>
</div>
</body>
</html>