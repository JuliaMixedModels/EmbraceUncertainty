<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Phillip Alday" />
  <meta name="author" content="Dave Kleinschmidt" />
  <meta name="author" content="Reinhold Kliegl" />
  <meta name="author" content="Douglas Bates" />
  <title>Data - Embrace Uncertainty</title>
  <link rel="shortcut icon" type="image/png" href="/favicon.png"/>
  <link rel="stylesheet" href="/style.css"/>
    <script src="/mousetrap.min.js"></script>
    <!-- TODO: Add url_prefix. -->
  <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("/JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="/github.min.css">
<script src="/highlight.min.js"></script>
<script src="/julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        hljs.highlightElement(el);
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="/">Embrace Uncertainty</a>
</div><br />
<span class="books-subtitle">
Fitting Mixed-Effects Models with Julia
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="/ExamLMM"><b>1</b> A Simple, Linear, Mixed-..</a></li>
<li><a class="menu-level-2" href="/memod"><b>1.1</b> Mixed-effects models</a></li>
<li><a class="menu-level-2" href="/DyestuffData"><b>1.2</b> The dyestuff and dyest..</a></li>
<li><a class="menu-level-2" href="/FittingLMMs"><b>1.3</b> Fitting linear mixed m..</a></li>
<li><a class="menu-level-2" href="/Probability"><b>1.4</b> The linear mixed-effec..</a></li>
<li><a class="menu-level-2" href="/variability"><b>1.5</b> Assessing the variabil..</a></li>
<li><a class="menu-level-2" href="/assessRE"><b>1.6</b> Assessing the random e..</a></li>
<li><a class="menu-level-2" href="/ChIntroSummary"><b>1.7</b> Chapter summary</a></li>
<li><a class="menu-level-1" href="/Multiple"><b>2</b> Models With Multiple Ran..</a></li>
<li><a class="menu-level-2" href="/crossedRE"><b>2.1</b> A Model With Crossed R..</a></li>
<li><a class="menu-level-2" href="/NestedRE"><b>2.2</b> A Model With Nested Ra..</a></li>
<li><a class="menu-level-2" href="/partially"><b>2.3</b> A Model With Partially..</a></li>
<li><a class="menu-level-2" href="/MultSummary"><b>2.4</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/longitudinal"><b>3</b> # Models for Longitudina..</a></li>
<li><a class="menu-level-2" href="/sleep"><b>3.1</b> Data</a></li>
<li><a class="menu-level-2" href="/SleepMixed"><b>3.2</b> Data</a></li>
<li><a class="menu-level-2" href="/assess-prec-param"><b>3.3</b> Assessing the Precisio..</a></li>
<li><a class="menu-level-2" href="/fm07re"><b>3.4</b> Examining the Random E..</a></li>
<li><a class="menu-level-2" href="/chapter-summary"><b>3.5</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/computational"><b>4</b> Computational Methods fo..</a></li>
<li><a class="menu-level-2" href="/defnLMM"><b>4.1</b> Definitions and Basic ..</a></li>
<li><a class="menu-level-2" href="/conddistUgivenY"><b>4.2</b> </a></li>
<li><a class="menu-level-2" href="/IntegratingH"><b>4.3</b> in the Linear Mixed Mo..</a></li>
<li><a class="menu-level-2" href="/PLSsol"><b>4.4</b> </a></li>
<li><a class="menu-level-2" href="/REML"><b>4.5</b> The REML Criterion</a></li>
<li><a class="menu-level-2" href="/stepByStep"><b>4.6</b> Step-by-step Evaluatio..</a></li>
<li><a class="menu-level-2" href="/general"><b>4.7</b> Generalizing to Other ..</a></li>
<li><a class="menu-level-2" href="/lmmsummary"><b>4.8</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/GLMMbinomial"><b>5</b> Generalized Linear Mixed..</a></li>
<li><a class="menu-level-2" href="/contraception"><b>5.1</b> Artificial contracepti..</a></li>
<li><a class="menu-level-2" href="/GLMMlink"><b>5.2</b> Link functions and int..</a></li>
<li><a class="menu-level-1" href="/references"><b></b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="3.2" id="sec:SleepMixed"><span class="header-section-number">3.2</span> Mixed-effects models For the <em>sleepstudy</em> Data</h2>
<p>Based on our preliminary graphical exploration of these data, we fit a mixed-effects model with two fixed-effects parameters, the intercept and slope of the linear time trend for the population, and two random effects for each subject. The random effects for a particular subject are the deviations in intercept and slope of that subject’s time trend from the population values.</p>
<p>We will fit two linear mixed models to these data. One model, <code>m11</code>, allows for correlation (in the unconditional distribution) of the random effects for the same subject. That is, we allow for the possibility that, for example, subjects with higher initial reaction times may, on average, be more strongly affected by sleep deprivation. The second model. <code>m12</code>, provides independent (again, in the unconditional distribution) random effects for intercept and slope for each subject.</p>
<h3 data-number="3.2.1" id="sec:correlatedre"><span class="header-section-number">3.2.1</span> A Model With Correlated Random Effects</h3>
<p>The first model is fit as</p>
<pre class="language-julia"><code>m11 = fit(
    MixedModel,
    @formula(reaction ~ 1 + days + (1+days|subj)),
    MixedModels.dataset(:sleepstudy);
    thin=1,
)</code></pre>
<pre class="language-plain"><code>Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -875.9697  1751.9393  1763.9393  1764.4249  1783.0971

Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  565.51066 23.78047
         days          32.68212  5.71683 +0.08
Residual              654.94145 25.59182
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.63226  37.91    &lt;1e-99
days          10.4673     1.50224   6.97    &lt;1e-11
──────────────────────────────────────────────────</code></pre>
<p>From the display we see that this model incorporates both an intercept and a slope (with respect to ) in the fixed effects and in the random effects. Extracting the conditional modes of the random effects</p>
<pre class="language-julia"><code>first(m11.b)</code></pre>
<pre class="output"><code>2×18 Matrix{Float64}:
 2.81582  -40.0484   -38.4331  22.8321   21.5498    8.81554   16.4419    -6.99667   -1.03759  34.6663   -24.558    -12.3345    4.274    20.6222   3.25854   -24.7101   0.723262  12.1189
 9.07551   -8.64408   -5.5134  -4.65872  -2.94449  -0.235201  -0.158809   1.03273  -10.5994    8.63238    1.06438    6.47168  -2.95533   3.56171  0.871711    4.6597  -0.971053   1.3107</code></pre>
<p>confirms that these are <em>vector-valued</em> random effects. There are a total of <span class="math inline">\(q=36\)</span> random effects, two for each of the 18 subjects.</p>
<p>The random effects section of the model display,</p>
<pre class="language-julia"><code>VarCorr(m11)</code></pre>
<pre class="output"><code>Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  565.51066 23.78047
         days          32.68212  5.71683 +0.08
Residual              654.94145 25.59182
</code></pre>
<p>indicates that there will be a random effect for the intercept and a random effect for the slope with respect to at each level of and, furthermore, the unconditional distribution of these random effects, <span class="math inline">\(\mathcal{B}\sim\mathcal{N}(\mathbf{0},\Sigma)\)</span>, allows for correlation of the random effects for the same subject.</p>
<p>We can confirm the potential for correlation of random effects within subject in the images of <span class="math inline">\(\Lambda\)</span>, <span class="math inline">\(\Sigma\)</span> and <span class="math inline">\(\mathbf{L}\)</span> for this model</p>
<pre class="language-julia"><code>only(m11.reterms).λ</code></pre>
<pre class="output"><code>2×2 LinearAlgebra.LowerTriangular{Float64, Matrix{Float64}}:
 0.929221    ⋅ 
 0.0181684  0.222645</code></pre>
<p>The matrix <span class="math inline">\(\Lambda\)</span> has 18 triangular blocks of size 2 along the diagonal, generating 18 square, symmetric blocks of size 2 along the diagonal of <span class="math inline">\(\Sigma\)</span>. The 18 symmetric blocks on the diagonal of <span class="math inline">\(\Sigma\)</span> are identical. Overall we estimate two standard deviations and a correlation for a vector-valued random effect of size 2, as shown in the model summary.</p>
<p>Often the variances and the covariance of random effects are quoted, rather than the standard deviations and the correlation shown here. We have already seen that the variance of a random effect is a poor scale on which to quote the estimate because confidence intervals on the variance are so badly skewed. It is more sensible to assess the estimates of the standard deviations of random effects or, possibly, the logarithms of the standard deviations if we can be confident that 0 is outside the region of interest. We do display the estimates of the variances of the random effects but mostly so that the user can compare these estimates to those from other software or for cases where an estimate of a variance is expected (sometimes even required) to be given when reporting a mixed model fit.</p>
<p>We do not quote estimates of covariances of vector-valued random effects because the covariance is a difficult scale to interpret, whereas a correlation has a fixed scale. A correlation must be between <span class="math inline">\(-1\)</span> and <span class="math inline">\(1\)</span>, allowing us to conclude that a correlation estimate close to those extremes indicates that <span class="math inline">\(\Sigma\)</span> is close to singular and the model is not well formulated.</p>
<p>The estimates of the fixed effects parameters are <span class="math inline">\(\widehat{\beta}=(251.41,10.467)\trans\)</span>. These represent a typical initial reaction time (i.e. without sleep deprivation) in the population of about 250 milliseconds, or 1/4 sec., and a typical increase in reaction time of a little more than 10 milliseconds per day of sleep deprivation.</p>
<p>The estimated subject-to-subject variation in the intercept corresponds to a standard deviation of about 25 ms. A 95% prediction interval on this random variable would be approximately <span class="math inline">\(\pm 50\)</span> ms. Combining this range with a population estimated intercept of 250 ms. indicates that we should not be surprised by intercepts as low as 200 ms. or as high as 300 ms. This range is consistent with the reference lines shown in <!-- @fig:sleepxyplot --> .</p>
<p>Similarly, the estimated subject-to-subject variation in the slope corresponds to a standard deviation of about 5.7 ms./day so we would not be surprised by slopes as low as <span class="math inline">\(10.5 - 2\cdot 5.7=-0.9\)</span> ms./day or as high as <span class="math inline">\(10.5 + 2\cdot 5.7=21.9\)</span> ms./day. Again, the conclusions from these rough, “back of the envelope” calculations are consistent with our observations from <!-- @fig:sleepxyplot --> .</p>
<p>The estimated residual standard deviation is about 25 ms. leading us to expect a scatter around the fitted lines for each subject of up to <span class="math inline">\(\pm 50\)</span> ms. From <!-- @fig:sleepxyplot --> we can see that some subjects (<code>S309</code>, <code>S372</code>, and <code>S337</code>) appear to have less variation than <span class="math inline">\(\pm 50\)</span> ms. about their within-subject fit but others (<code>S308</code>, <code>S332</code>, and <code>S331</code>) may have more.</p>
<p>Finally, we see the estimated within-subject correlation of the random effect for the intercept and the random effect for the slope is very low, <span class="math inline">\(0.081\)</span>, confirming our impression that there is little evidence of a systematic relationship between these quantities. In other words, observing a subject’s initial reaction time does not give us much information for predicting whether their reaction time will be strongly affected by each day of sleep deprivation or not. It seems reasonable that we could get nearly as good a fit from a model that does not allow for correlation, which we describe next.</p>
<h3 data-number="3.2.2" id="sec:uncorrelatedre"><span class="header-section-number">3.2.2</span> A Model With uncorrelated random effects</h3>
<p>In a model with uncorrelated random effects we have <span class="math inline">\(\mathcal{B}\sim\mathcal{N}(\mathbf{0},\Sigma)\)</span> where <span class="math inline">\(\Sigma\)</span> is diagonal. We have seen models like this in previous chapters but those models had simple scalar random effects for all the grouping factors. Here we want to have a simple scalar random effect for and a random effect for the slope with respect to <code>days</code>, also indexed by <code>subj</code>. We accomplish this by specifying two random-effects terms. The first, <code>(1|subj)</code>, is a simple scalar term. The second has <code>days</code> on the left hand side of the vertical bar.</p>
<p>It may seem that the model formula we want should be</p>
<pre><code>reaction ~ 1 + days + (1|subj) + (days|subj)</code></pre>
<p>but it is not. Because the intercept is implicit in linear models, the second random effects term is equivalent to <code>(1+days|subj)</code> and will, by itself, produce correlated, vector-valued random effects.</p>
<p>We must suppress the implicit intercept in the second random-effects term, which we do by writing it as <code>(0+days|subj)</code>, read as “no intercept and <code>days</code> by <code>subj</code>.” Using the first form we have</p>
<pre class="language-julia"><code>m12 = fit(
    MixedModel,
    @formula(reaction ~ 1 + days + (1|subj) + (0+days|subj)),
    sleepstudy;
    thin=1,
)</code></pre>
<pre class="language-plain"><code>Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 | subj) + (0 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -876.0016  1752.0033  1762.0033  1762.3481  1777.9680

Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  584.25897 24.17145
         days          33.63281  5.79938   .  
Residual              653.11578 25.55613
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.70771  37.48    &lt;1e-99
days          10.4673     1.51931   6.89    &lt;1e-11
──────────────────────────────────────────────────</code></pre>
<p>As in model <code>m11</code>, there are two random effects for each subject</p>
<pre class="language-julia"><code>only(m12.b)</code></pre>
<pre class="output"><code>2×18 Matrix{Float64}:
 1.85472  -40.0225   -38.7233   23.9034  22.3964    9.05203   16.8513    -7.28022    0.138478  34.5136   -25.2632   -13.3612    4.71054  20.7096  3.23735  -25.8262    0.850485  12.2589
 9.23642   -8.61744   -5.43435  -4.8582  -3.10485  -0.282165  -0.241021   1.08627  -10.7982     8.63143    1.20307    6.65547  -3.03272   3.5309  0.87278    4.86824  -0.993202   1.27755</code></pre>
<p>but no correlation has been estimated</p>
<pre class="language-julia"><code>VarCorr(m12)</code></pre>
<pre class="output"><code>Variance components:
            Column    Variance Std.Dev.   Corr.
subj     (Intercept)  584.25897 24.17145
         days          33.63281  5.79938   .  
Residual              653.11578 25.55613
</code></pre>
<p>Images of the matrices <span class="math inline">\(\Lambda\)</span>, <span class="math inline">\(\Sigma\)</span> and <span class="math inline">\(\mathbf{L}\)</span> show that <span class="math inline">\(\Sigma\)</span> is indeed diagonal.</p>
<p>Images of <span class="math inline">\(\mathbf{Z}&#39;\)</span> for these two models</p>
<pre class="language-julia"><code>only(m11.reterms).adjA</code></pre>
<pre class="output"><code>36×180 SparseArrays.SparseMatrixCSC{Float64, Int32} with 360 stored entries:
⠉⠉⠓⠒⠢⠤⢤⣀⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠛⠛⠷⠶⠦⠤⢤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠓⠒⠲⠶⢶⣤⣤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠉⠉⠓⠒⠢⠤⢤⣀⣀</code></pre>
<pre class="language-julia"><code>only(m12.reterms).adjA</code></pre>
<pre class="output"><code>36×180 SparseArrays.SparseMatrixCSC{Float64, Int32} with 360 stored entries:
⠉⠉⠓⠒⠢⠤⢤⣀⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠛⠛⠷⠶⠦⠤⢤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠓⠒⠲⠶⢶⣤⣤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠉⠉⠓⠒⠢⠤⢤⣀⣀</code></pre>
<p>shows that the columns of <span class="math inline">\(\mathbf{Z}\)</span> (rows of <span class="math inline">\(\mathbf{Z}\trans\)</span>) from one model are the same those from the other model.</p>
<h3 data-number="3.2.3" id="sec:GeneratingZLambda"><span class="header-section-number">3.2.3</span> Generating <span class="math inline">\(\mathbf{Z}\)</span> and <span class="math inline">\(\Lambda\)</span> From random-effects terms</h3>
<p>The non-zero values in the model matrix <span class="math inline">\(\mathbf{Z}\)</span> for model are the same as those for model but the columns are in a different order. Pairs of columns associated with the same level of the grouping factor are adjacent. One way to think of the process of generating these columns is to extend the idea of an interaction between a single covariate and the grouping factor to generating an “interaction” of a model matrix and the levels of the grouping factor. In other words, we begin with the two columns of the model matrix for the expression and the 18 columns of indicators for the factor. The result will have 36 columns that we regard as 18 adjacent pairs. The values within each of these pairs of columns are the values of the columns, when the indicator is 1, otherwise they are zero.</p>
<p>We can now describe the general process of creating the model matrix, <span class="math inline">\(\mathbf{Z}\)</span>, and the relative covariance factor, <span class="math inline">\(\Lambda\)</span> from the random-effects terms in the model formula. Each random-effects term is of the form <code>(A|F)</code>. The expression <code>A</code> is evaluated as a linear model formula, producing a model matrix with <span class="math inline">\(s\)</span> columns. The expression <code>F</code> is evaluated as a factor. Let <span class="math inline">\(k\)</span> be the number of levels in this factor, after eliminating unused levels, if any. The <span class="math inline">\(i\)</span>th term generates <span class="math inline">\(s_ik_i\)</span> columns in the model matrix, <span class="math inline">\(\mathbf{Z}\)</span>, and a diagonal block of size <span class="math inline">\(s_ik_i\)</span> in the relative covariance factor, <span class="math inline">\(\Lambda\)</span>. The <span class="math inline">\(s_ik_i\)</span> columns in <span class="math inline">\(\mathbf{Z}\)</span> have the pattern of the interaction of the <span class="math inline">\(s_i\)</span> columns from the <span class="math inline">\(i\)</span>th with the <span class="math inline">\(k_i\)</span> indicator columns for the <span class="math inline">\(i\)</span>th grouping factor <code>F</code>. The diagonal block in <span class="math inline">\(\Lambda\)</span> is itself block diagonal, consisting of <span class="math inline">\(k_i\)</span> blocks, each a lower triangular matrix of size <span class="math inline">\(s_i\)</span>. In fact, these inner blocks are repetitions of the same lower triangular <span class="math inline">\(s_i\times s_i\)</span> matrix. The <span class="math inline">\(i\)</span> term contributes <span class="math inline">\(s_i(s_i+1)/2\)</span> elements to the variance-component parameter, <span class="math inline">\(\vec\theta\)</span>, and these are the elements in the lower triangle of this <span class="math inline">\(s_i\times s_i\)</span> template matrix.</p>
<p>Note that when counting the columns in a model matrix we must take into account the implicit intercept term. For example, we could write the formula for model as</p>
<pre><code>reaction ~ days + (days|subj)</code></pre>
<p>realizing that the linear model expression, <code>days</code>, actually generates two columns because of the implicit intercept.</p>
<p>Whether or not to include an explicit intercept term in a model formula is a matter of personal taste. Many people prefer to write the intercept explicitly so as to emphasize the relationship between terms in the formula and coefficients or random effects in the model. Others omit these implicit terms so as to economize on the amount of typing required. Either approach can be used. The important point to remember is that the intercept must be explicitly suppressed when you don’t want it in a term.</p>
<p>Also, the intercept term must be explicit when it is the only term in the expression. That is, a simple, scalar random-effects term must be written as <code>(1|F)</code> because a term like <code>(|F)</code> is not syntactically correct. However, we can omit the intercept from the fixed-effects part of the model formula if we have any random-effects terms. That is, we could write the formula for model in Chap. <a href="#chap:ExamLMM" data-reference-type="ref" data-reference="chap:ExamLMM">[chap:ExamLMM]</a> as</p>
<p>or even</p>
<p>although omitting the parentheses around a random-effects term is risky. Because of operator precedence, the vertical bar operator, , takes essentially everything in the expression to the left of it as its first operand. It is advisable always to enclose such terms in parentheses so the scope of the operands to the operator is clearly defined.</p>
<h3 data-number="3.2.4" id="sec:comparingfm06fm07"><span class="header-section-number">3.2.4</span> Comparing Models <em>m11</em> and <em>m12</em></h3>
<p>Returning to models <code>m11</code> and <code>m12</code> for the data, it is easy to see that these are nested models because <code>m11</code> is reduced to <code>m12</code> by constraining the within-group correlation of random effects to be zero (which is equivalent to constraining the element below the diagonal in the <span class="math inline">\(2\times 2\)</span> lower triangular <span class="math inline">\(\lambda\)</span> to be zero).</p>
<p>We can use a likelihood ratio test to compare these fitted models.</p>
<pre class="language-julia"><code>MixedModels.likelihoodratiotest(m12, m11)</code></pre>
<pre class="output"><code>Model Formulae
1: reaction ~ 1 + days + (1 | subj) + (0 + days | subj)
2: reaction ~ 1 + days + (1 + days | subj)
─────────────────────────────────────────────────
     model-dof  -2 logLik      χ²  χ²-dof  P(&gt;χ²)
─────────────────────────────────────────────────
[1]          5  1752.0033                        
[2]          6  1751.9393  0.0639       1  0.8004
─────────────────────────────────────────────────</code></pre>
<p>The value of the <span class="math inline">\(\chi^2\)</span> statistic, <span class="math inline">\(0.0639\)</span>, is very small, corresponding to a p-value of <span class="math inline">\(0.80\)</span> and indicating that the extra parameter in model relative to does not produce a significantly better fit. By the principal of parsimony we prefer the reduced model, <code>m12</code>.</p>
<p>This conclusion is consistent with the visual impression provided by <!-- @fig:sleepxyplot -->. There does not appear to be a strong relationship between a subject’s initial reaction time and the extent to which his or her reaction time is affected by sleep deprivation.</p>
<p>In this likelihood ratio test the value of the parameter being tested, a correlation of zero, is not on the boundary of the parameter space. We can be confident that the p-value from the LRT adequately reflects the underlying situation.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="/sleep"><b>3.1</b> Data</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="/assess-prec-param"><b>3.3</b> Assessing the Precisio..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Phillip Alday, Dave Kleinschmidt, Reinhold Kliegl, Douglas Bates
</div>
</div>
</div>
</body>
</html>