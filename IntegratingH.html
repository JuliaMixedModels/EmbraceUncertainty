<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Phillip Alday" />
  <meta name="author" content="Dave Kleinschmidt" />
  <meta name="author" content="Reinhold Kliegl" />
  <meta name="author" content="Douglas Bates" />
  <title>in the Linear Mixed Model - Embrace Uncertainty</title>
  <link rel="shortcut icon" type="image/png" href="/favicon.png"/>
  <link rel="stylesheet" href="/style.css"/>
    <script src="/mousetrap.min.js"></script>
    <!-- TODO: Add url_prefix. -->
  <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("/JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="/github.min.css">
<script src="/highlight.min.js"></script>
<script src="/julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        hljs.highlightElement(el);
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="/">Embrace Uncertainty</a>
</div><br />
<span class="books-subtitle">
Fitting Mixed-Effects Models with Julia
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="/ExamLMM"><b>1</b> A Simple, Linear, Mixed-..</a></li>
<li><a class="menu-level-2" href="/memod"><b>1.1</b> Mixed-effects models</a></li>
<li><a class="menu-level-2" href="/DyestuffData"><b>1.2</b> The dyestuff and dyest..</a></li>
<li><a class="menu-level-2" href="/FittingLMMs"><b>1.3</b> Fitting linear mixed m..</a></li>
<li><a class="menu-level-2" href="/Probability"><b>1.4</b> The linear mixed-effec..</a></li>
<li><a class="menu-level-2" href="/variability"><b>1.5</b> Assessing the variabil..</a></li>
<li><a class="menu-level-2" href="/assessRE"><b>1.6</b> Assessing the random e..</a></li>
<li><a class="menu-level-2" href="/ChIntroSummary"><b>1.7</b> Chapter summary</a></li>
<li><a class="menu-level-1" href="/Multiple"><b>2</b> Models With Multiple Ran..</a></li>
<li><a class="menu-level-2" href="/crossedRE"><b>2.1</b> A Model With Crossed R..</a></li>
<li><a class="menu-level-2" href="/NestedRE"><b>2.2</b> A Model With Nested Ra..</a></li>
<li><a class="menu-level-2" href="/partially"><b>2.3</b> A Model With Partially..</a></li>
<li><a class="menu-level-2" href="/MultSummary"><b>2.4</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/longitudinal"><b>3</b> # Models for Longitudina..</a></li>
<li><a class="menu-level-2" href="/sleep"><b>3.1</b> Data</a></li>
<li><a class="menu-level-2" href="/SleepMixed"><b>3.2</b> Data</a></li>
<li><a class="menu-level-2" href="/assess-prec-param"><b>3.3</b> Assessing the Precisio..</a></li>
<li><a class="menu-level-2" href="/fm07re"><b>3.4</b> Examining the Random E..</a></li>
<li><a class="menu-level-2" href="/chapter-summary"><b>3.5</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/computational"><b>4</b> Computational Methods fo..</a></li>
<li><a class="menu-level-2" href="/defnLMM"><b>4.1</b> Definitions and Basic ..</a></li>
<li><a class="menu-level-2" href="/conddistUgivenY"><b>4.2</b> </a></li>
<li><a class="menu-level-2" href="/IntegratingH"><b>4.3</b> in the Linear Mixed Mo..</a></li>
<li><a class="menu-level-2" href="/PLSsol"><b>4.4</b> </a></li>
<li><a class="menu-level-2" href="/REML"><b>4.5</b> The REML Criterion</a></li>
<li><a class="menu-level-2" href="/stepByStep"><b>4.6</b> Step-by-step Evaluatio..</a></li>
<li><a class="menu-level-2" href="/general"><b>4.7</b> Generalizing to Other ..</a></li>
<li><a class="menu-level-2" href="/lmmsummary"><b>4.8</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/GLMMbinomial"><b>5</b> Generalized Linear Mixed..</a></li>
<li><a class="menu-level-2" href="/contraception"><b>5.1</b> Artificial contracepti..</a></li>
<li><a class="menu-level-2" href="/GLMMlink"><b>5.2</b> Link functions and int..</a></li>
<li><a class="menu-level-1" href="/references"><b></b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="4.3" id="sec:IntegratingH"><span class="header-section-number">4.3</span> Integrating <span class="math inline">\(h(\mathbf{u})\)</span> in the Linear Mixed Model</h2>
<p>The integral defining the likelihood in (<a href="#eq:LMMlikelihood" data-reference-type="ref" data-reference="eq:LMMlikelihood">[eq:LMMlikelihood]</a>) has a closed form in the case of a linear mixed model but not for some of the more general forms of mixed models. To motivate methods for approximating the likelihood in more general situations, we describe in some detail how the integral can be evaluated using the sparse Cholesky factor, <span class="math inline">\(\mathbf{L}_\theta\)</span>, and the conditional mode, <span class="math display">\[\label{eq:condMode}
  \tilde{\mathbf{u}}=\arg\max_{\mathbf{u}} f_{\mathcal{U}|\mathcal{Y}}(\mathbf{u}|\mathbf{y}_{\text{obs}})=
  \arg\max_{\mathbf{u}} h(\mathbf{u}) = \arg\max_{\mathbf{u}}
  f_{\mathcal{Y}|\mathcal{U}}(\mathbf{y}_{\text{obs}}|\mathbf{u})\,f_{\mathcal{U}}(\mathbf{u}).
\]</span> The notation <span class="math inline">\(\arg\max_{\mathbf{u}}\)</span> means that <span class="math inline">\(\tilde{\mathbf{u}}\)</span> is the value of <span class="math inline">\(\mathbf{u}\)</span> that maximizes the expression that follows.</p>
<p>In general, the <em>mode</em> of a continuous distribution is the value of the random variable that maximizes the density. The value <span class="math inline">\(\tilde{\mathbf{u}}\)</span> is called the conditional mode of <span class="math inline">\(\mathbf{u}\)</span>, given <span class="math inline">\(\mathcal{Y}=\mathbf{y}_{\text{obs}}\)</span>, because <span class="math inline">\(\tilde{\mathbf{u}}\)</span> maximizes the conditional density of <span class="math inline">\(\mathcal{U}\)</span> given <span class="math inline">\(\mathcal{Y}=\mathbf{y}_{\text{obs}}\)</span>. The location of the maximum can be determined by maximizing the unnormalized conditional density because <span class="math inline">\(h(\mathbf{u})\)</span> is just a constant multiple of <span class="math inline">\(f_{\mathcal{U}|\mathcal{Y}}(\mathbf{u}|\mathbf{y}_{\text{obs}})\)</span>. The last part of (<a href="#eq:condMode" data-reference-type="ref" data-reference="eq:condMode">[eq:condMode]</a>) is simply a re-expression of <span class="math inline">\(h(\mathbf{u})\)</span> as the product of <span class="math inline">\(f_{\mathcal{Y}|\mathcal{U}}(\mathbf{y}_{\text{obs}}|\mathbf{u})\)</span> and <span class="math inline">\(f_{\mathcal{U}}(\mathbf{u})\)</span>. For a linear mixed model these densities are <span class="math display">\[
\begin{aligned}
  \label{eq:densYgivenUandU}
  f_{\mathcal{Y}|\mathcal{U}}(\mathbf{y}|\mathbf{u})&amp;=
  \frac{1}{\left(2\pi\sigma^2\right)^{n/2}}
  \exp\left(-\frac{\left\|\mathbf{y}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2}{2\sigma^2}\right)\\
  f_{\mathcal{U}}(\mathbf{u})&amp;=
  \frac{1}{\left(2\pi\sigma^2\right)^{q/2}}\exp\left(-\frac{\|\mathbf{u}\|^2}
    {2\sigma^2}\right)
\end{aligned}
\]</span> with product <span class="math display">\[\label{eq:hudef}
  h(\mathbf{u})=\frac{1}{\left(2\pi\sigma^2\right)^{(n+q)/2}}
  \exp\left(-\frac{\left\|\mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2+\|\mathbf{u}\|^2}{2\sigma^2}\right) .
\]</span> On the deviance scale we have <span class="math display">\[\label{eq:devh}
  -2\log\left(h(\mathbf{u})\right)=(n+q)\log(2\pi\sigma^2)
  +\frac{\left\|\mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2+\|\mathbf{u}\|^2}{\sigma^2} .
\]</span> Because (<a href="#eq:devh" data-reference-type="ref" data-reference="eq:devh">[eq:devh]</a>) describes the negative log density, <span class="math inline">\(\tilde{\mathbf{u}}\)</span> will be the value of <span class="math inline">\(\mathbf{u}\)</span> that minimizes the expression on the right hand side of (<a href="#eq:devh" data-reference-type="ref" data-reference="eq:devh">[eq:devh]</a>).</p>
<p>The only part of the right hand side of (<a href="#eq:devh" data-reference-type="ref" data-reference="eq:devh">[eq:devh]</a>) that depends on <span class="math inline">\(\mathbf{u}\)</span> is the numerator of the second term. Thus <span class="math display">\[\label{eq:PLSsol}
  \tilde{\mathbf{u}}=\arg\min_{\mathbf{u}} \left\|
    \mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2+
  \|\mathbf{u}\|^2.
\]</span> The expression to be minimized, called the <em>objective function</em>, is described as a <em>penalized residual sum of squares</em> (PRSS) and the minimizer, <span class="math inline">\(\tilde{\mathbf{u}}\)</span>, is called the <em>penalized least squares</em> (PLS) solution. They are given these names because the first term in the objective, <span class="math inline">\(\left\| \mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2\)</span>, is a sum of squared residuals, and the second term, <span class="math inline">\(\|\mathbf{u}\|^2\)</span>, is a penalty on the length, <span class="math inline">\(\|\mathbf{u}\|\)</span>, of <span class="math inline">\(\mathbf{u}\)</span>. Larger values of <span class="math inline">\(\mathbf{u}\)</span> (in the sense of greater lengths as vectors) incur a higher penalty.</p>
<p>The PRSS criterion determining the conditional mode balances fidelity to the observed data (i.e. producing a small residual sum of squares) against simplicity of the model (small <span class="math inline">\(\|\mathbf{u}\|\)</span>). We refer to this type of criterion as a smoothing objective, in the sense that it seeks to smooth out the fitted response by reducing model complexity while still retaining reasonable fidelity to the observed data.</p>
<p>For the purpose of evaluating the likelihood we will regard the PRSS criterion as a function of the parameters, given the data, and write its minimum value as <span class="math display">\[\label{eq:r2thetabeta}
  r^2_{\theta,\beta}=\min_{\mathbf{u}} \left\|
    \mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2+ \|\mathbf{u}\|^2.
\]</span> Notice that <span class="math inline">\(\mathbf{\beta}\)</span> only enters the right hand side of (<a href="#eq:r2thetabeta" data-reference-type="ref" data-reference="eq:r2thetabeta">[eq:r2thetabeta]</a>) through the linear predictor expression. We will see that <span class="math inline">\(\tilde{\mathbf{u}}\)</span> can be determined by a direct (i.e. non-iterative) calculation and, in fact, we can minimize the PRSS criterion with respect to <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{\beta}\)</span> simultaneously without iterating. We write this minimum value as <span class="math display">\[\label{eq:r2theta}
  r^2_\theta=\min_{\mathbf{u},\mathbf{\beta}} \left\|
    \mathbf{y}_{\text{obs}}-\mathbf{X}\mathbf{\beta}-\mathbf{Z}\Lambda_\theta\mathbf{u}\right\|^2+ \|\mathbf{u}\|^2.
\]</span> The value of <span class="math inline">\(\mathbf{\beta}\)</span> at the minimum is called the conditional estimate of <span class="math inline">\(\mathbf{\beta}\)</span> given <span class="math inline">\(\mathbf{\theta}\)</span>, written <span class="math inline">\(\widehat{\mathbf{\beta}}_\theta\)</span>.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="/conddistUgivenY"><b>4.2</b> </a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="/PLSsol"><b>4.4</b> </a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Phillip Alday, Dave Kleinschmidt, Reinhold Kliegl, Douglas Bates
</div>
</div>
</div>
</body>
</html>