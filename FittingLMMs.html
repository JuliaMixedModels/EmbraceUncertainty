<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Phillip Alday" />
  <meta name="author" content="Dave Kleinschmidt" />
  <meta name="author" content="Reinhold Kliegl" />
  <meta name="author" content="Douglas Bates" />
  <title>Fitting linear mixed models - Embrace Uncertainty</title>
  <link rel="shortcut icon" type="image/png" href="/favicon.png"/>
  <link rel="stylesheet" href="/style.css"/>
    <script src="/mousetrap.min.js"></script>
    <!-- TODO: Add url_prefix. -->
  <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("/JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="/github.min.css">
<script src="/highlight.min.js"></script>
<script src="/julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        hljs.highlightElement(el);
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="/">Embrace Uncertainty</a>
</div><br />
<span class="books-subtitle">
Fitting Mixed-Effects Models with Julia
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="/ExamLMM"><b>1</b> A Simple, Linear, Mixed-..</a></li>
<li><a class="menu-level-2" href="/memod"><b>1.1</b> Mixed-effects models</a></li>
<li><a class="menu-level-2" href="/DyestuffData"><b>1.2</b> The dyestuff and dyest..</a></li>
<li><a class="menu-level-2" href="/FittingLMMs"><b>1.3</b> Fitting linear mixed m..</a></li>
<li><a class="menu-level-2" href="/Probability"><b>1.4</b> The linear mixed-effec..</a></li>
<li><a class="menu-level-2" href="/variability"><b>1.5</b> Assessing the variabil..</a></li>
<li><a class="menu-level-2" href="/assessRE"><b>1.6</b> Assessing the random e..</a></li>
<li><a class="menu-level-2" href="/ChIntroSummary"><b>1.7</b> Chapter summary</a></li>
<li><a class="menu-level-1" href="/Multiple"><b>2</b> Models With Multiple Ran..</a></li>
<li><a class="menu-level-2" href="/crossedRE"><b>2.1</b> A Model With Crossed R..</a></li>
<li><a class="menu-level-2" href="/NestedRE"><b>2.2</b> A Model With Nested Ra..</a></li>
<li><a class="menu-level-2" href="/partially"><b>2.3</b> A Model With Partially..</a></li>
<li><a class="menu-level-2" href="/MultSummary"><b>2.4</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/longitudinal"><b>3</b> # Models for Longitudina..</a></li>
<li><a class="menu-level-2" href="/sleep"><b>3.1</b> Data</a></li>
<li><a class="menu-level-2" href="/SleepMixed"><b>3.2</b> Data</a></li>
<li><a class="menu-level-2" href="/assess-prec-param"><b>3.3</b> Assessing the Precisio..</a></li>
<li><a class="menu-level-2" href="/fm07re"><b>3.4</b> Examining the Random E..</a></li>
<li><a class="menu-level-2" href="/chapter-summary"><b>3.5</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/computational"><b>4</b> Computational Methods fo..</a></li>
<li><a class="menu-level-2" href="/defnLMM"><b>4.1</b> Definitions and Basic ..</a></li>
<li><a class="menu-level-2" href="/conddistUgivenY"><b>4.2</b> </a></li>
<li><a class="menu-level-2" href="/IntegratingH"><b>4.3</b> in the Linear Mixed Mo..</a></li>
<li><a class="menu-level-2" href="/PLSsol"><b>4.4</b> </a></li>
<li><a class="menu-level-2" href="/REML"><b>4.5</b> The REML Criterion</a></li>
<li><a class="menu-level-2" href="/stepByStep"><b>4.6</b> Step-by-step Evaluatio..</a></li>
<li><a class="menu-level-2" href="/general"><b>4.7</b> Generalizing to Other ..</a></li>
<li><a class="menu-level-2" href="/lmmsummary"><b>4.8</b> Chapter Summary</a></li>
<li><a class="menu-level-1" href="/GLMMbinomial"><b>5</b> Generalized Linear Mixed..</a></li>
<li><a class="menu-level-2" href="/contraception"><b>5.1</b> Artificial contracepti..</a></li>
<li><a class="menu-level-2" href="/GLMMlink"><b>5.2</b> Link functions and int..</a></li>
<li><a class="menu-level-1" href="/references"><b></b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="1.3" id="sec:FittingLMMs"><span class="header-section-number">1.3</span> Fitting linear mixed models</h2>
<p>Before we formally define a linear mixed model, let’s go ahead and fit models to these data sets using <code>MixedModels</code>. The simplest way to do this is to use the generic <code>fit</code> function with arguments describing the type of model to be fit (i.e. <code>MixedModel</code>), a <em>formula</em> specifying the model and the <em>data</em> on which to evaluate the formula.</p>
<p>We will explain the structure of the formula after we have considered an example.</p>
<h3 data-number="1.3.1" id="sec:dyestuffLMM"><span class="header-section-number">1.3.1</span> A model for the dyestuff data</h3>
<p>We fit a model to the data allowing for an overall level of the <code>yield</code> and for an additive random effect for each level of <code>batch</code>.</p>
<pre class="language-julia"><code>m1 = fit(MixedModel, @formula(yield ~ 1 + (1|batch)), dyestuff)</code></pre>
<pre class="language-plain"><code>Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
  -163.6635   327.3271   333.3271   334.2501   337.5307

Variance components:
            Column    Variance Std.Dev.
batch    (Intercept)  1388.3332 37.2603
Residual              2451.2501 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     17.6946  86.33    &lt;1e-99
────────────────────────────────────────────────</code></pre>
<p>The call to <code>fit</code> constructs a <code>LinearMixedModel</code> object, evaluates the <em>maximum likelihood</em> parameter estimates, assigns the results to the name <code>m1</code>, and displays a summary of the fitted model.</p>
<h4 data-number="1.3.1.1" id="details-of-the-printed-display"><span class="header-section-number">1.3.1.1</span> Details of the printed display</h4>
<p>The display of the fitted model has four major sections:</p>
<ol type="1">
<li>a description of the model that was fit</li>
<li>some statistics characterizing the model fit</li>
<li>a summary of properties of the random effects and</li>
<li>a summary of the fixed-effects parameter estimates.</li>
</ol>
<p>We consider each of these sections in turn.</p>
<p>The description section states that this is a linear mixed model in which the parameters have been estimate by maximum likelihood (ML). The formula argument is displayed for later reference.</p>
<p>The display of a model fit by maximum likelihood (ML) provides several other model-fit statistics such as Akaike’s Information Criterion <span class="citation" data-cites="saka:ishi:kita:1986">(<a href="/references#ref-saka:ishi:kita:1986" role="doc-biblioref">Sakamoto et al., 1986</a>)</span>, Schwarz’s Bayesian Information Criterion <span class="citation" data-cites="schw:1978">(<a href="/references#ref-schw:1978" role="doc-biblioref">Schwarz, 1978</a>)</span>, the log-likelihood at the parameter estimates, and negative twice the log-likelihood, which is the estimation criterion transformed to the scale of the <em>deviance</em>. For linear mixed models we refer to <code>-2 loglik</code> as the value of the <em>objective</em> because this is the value that is minimized during the optimization phase of fitting the model. To evaluate the <em>deviance</em> we should subtract the value of this criterion at a <em>saturated</em> or baseline model but it is not clear how to define such a baseline model in these cases.</p>
<p>However, it is still possible to perform <em>likelihood ratio tests</em> of different models fit to the same data using the difference in the minimized objectives, because it is the same as the difference in the deviances. (Recall that the objective is negative twice the log-likelihood, hence a ratio of likelihoods corresponds to the difference in objectives.)</p>
<p>The third section is the table of estimates of parameters associated with the random effects. There are two sources of variability in the model we have fit, a batch-to-batch variability in the level of the response and the residual or per-observation variability — also called the within-batch variability. The name “residual” is used in statistical modeling to denote the part of the variability that cannot be explained or modeled with the other terms. It is the variation in the observed data that is “left over” after we have determined the estimates of the parameters in the other parts of the model.</p>
<p>Some of the variability in the response is associated with the fixed-effects terms. In this model there is only one such term, labeled as the <code>(Intercept)</code>. The name “intercept,” which is better suited to models based on straight lines written in a slope/intercept form, should be understood to represent an overall “typical” or mean level of the response in this case. (In case you are wondering about the parentheses around the name <code>(Intercept)</code>, they are included so that you can’t accidentally create a variable with a name that conflicts with this name.) The line labeled <code>batch</code> in the random effects table shows that the random effects added to the term, one for each level of the factor <code>batch</code>, are modeled as random variables whose unconditional variance is estimated as 1388.33 g<span class="math inline">\(^2\)</span> in the ML fit. The corresponding standard deviation is 37.26 g.</p>
<p>Note that the last column in the random effects summary table is the estimate of the variability expressed as a standard deviation rather than as a variance. These values are provided because it is usually easier to visualize standard deviations, which are on the scale of the response, than it is to visualize the magnitude of a variance. The values in this column are a simple re-expression (the square root) of the estimated variances. Do not confuse them with the standard errors of the variance estimators, which are not given here. In <code>add-section-reference-here</code> we explain why we do not provide standard errors of variance estimates.</p>
<p>The line labeled <code>Residual</code> in this table gives the estimate of the variance of the residuals (also in g<span class="math inline">\(^2\)</span>) and its corresponding standard deviation. The estimated standard deviation of the residuals is 49.5 g.</p>
<p>The last line in the random effects table states the number of observations to which the model was fit and the number of levels of any “grouping factors” for the random effects. In this case we have a single random effects term, <code>(1|batch)</code>, in the model formula and the grouping factor for that term is <code>batch</code>. There will be a total of six random effects, one for each level of <code>batch</code>.</p>
<p>The final part of the printed display gives the estimates and standard errors of any fixed-effects parameters in the model. The only fixed-effects term in the model formula is the <code>1</code>, denoting a constant which, as explained above, is labeled as <code>(Intercept)</code>. The estimate of this parameter is 1527.5 g, which happens to be the mean yield across all the data.</p>
<h3 data-number="1.3.2" id="sec:Dyestuff2LMM"><span class="header-section-number">1.3.2</span> A model for the dyestuff2 data</h3>
<p>Fitting a similar model to the data produces an estimate <span class="math inline">\(\widehat{\sigma}_1=0\)</span>.</p>
<pre class="language-julia"><code>m2 = fit(MixedModel, @formula(yield ~ 1 + (1|batch)), dyestuff2)</code></pre>
<pre class="language-plain"><code>Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
   -81.4365   162.8730   168.8730   169.7961   173.0766

Variance components:
            Column   Variance Std.Dev.
batch    (Intercept)   0.00000 0.00000
Residual              13.34610 3.65323
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
───────────────────────────────────────────────
              Coef.  Std. Error     z  Pr(&gt;|z|)
───────────────────────────────────────────────
(Intercept)  5.6656    0.666986  8.49    &lt;1e-16
───────────────────────────────────────────────</code></pre>
<p>An estimate of <span class="math inline">\(0\)</span> for <span class="math inline">\(\sigma_1\)</span> does not mean that there is no variation between the groups. Indeed Figure <a href="#fig:dyestuff2data">2</a> shows that there is some small amount of variability between the groups. The estimate, <span class="math inline">\(\widehat{\sigma}_1=0\)</span>, simply indicates that the level of “between-group” variability is not sufficient to warrant incorporating random effects in the model.</p>
<p>The important point to take away from this example is that we must allow for the estimates of variance components to be zero. We describe such a model as being degenerate, in the sense that it corresponds to a linear model in which we have removed the random effects associated with <code>batch</code>. Degenerate models can and do occur in practice. Even when the final fitted model is not degenerate, we must allow for such models when determining the parameter estimates through numerical optimization.</p>
<p>To reiterate, the model corresponds to the linear model because the random effects are inert, in the sense that they have a variance of zero, and hence can be removed.</p>
<p>Notice that the estimate of <span class="math inline">\(\sigma\)</span> from the linear model (called the in the summary) corresponds to the estimate in the REML fit () but not that from the ML fit (). The fact that the REML estimates of variance components in mixed models generalize the estimate of the variance used in linear models, in the sense that these estimates coincide in the degenerate case, is part of the motivation for the use of the REML criterion for fitting mixed-effects models.</p>
<h3 data-number="1.3.3" id="sec:furtherassess"><span class="header-section-number">1.3.3</span> Further Assessment of the Fitted Models</h3>
<p>The parameter estimates in a statistical model represent our “best guess” at the unknown values of the model parameters and, as such, are important results in statistical modeling. However, they are not the whole story. Statistical models characterize the variability in the data and we must assess the effect of this variability on the parameter estimates and on the precision of predictions made from the model.</p>
<p>In we introduce a method of assessing variability in parameter estimates using the “profiled deviance” and in we show methods of characterizing the conditional distribution of the random effects given the data. Before we get to these sections, however, we should state in some detail the probability model for linear mixed-effects and establish some definitions and notation. In particular, before we can discuss profiling the deviance, we should define the deviance. We do that in the next section.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="/DyestuffData"><b>1.2</b> The dyestuff and dyest..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="/Probability"><b>1.4</b> The linear mixed-effec..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Phillip Alday, Dave Kleinschmidt, Reinhold Kliegl, Douglas Bates
</div>
</div>
</div>
</body>
</html>